Oro Runtime · LLMS Pack
======================

This file concatenates the full Oro Runtime documentation hosted on this website,
so an LLM can answer questions using the same source of truth as readers.

Generated: 2026-01-27T13:09:29+00:00

How to link:
- Docs: /runtime/docs/?p=<id>

Table of contents
-----------------

Runtime Docs
- Start
  - start — Oro Runtime Documentation — /runtime/docs/?p=start
- Architecture
  - RUNTIME_ARCHITECTURE — Oro Runtime Architecture — /runtime/docs/?p=RUNTIME_ARCHITECTURE
  - NAVIGATOR_MOUNTS — Navigator Mounts — /runtime/docs/?p=NAVIGATOR_MOUNTS
  - CONDUIT — Conduit Transport — /runtime/docs/?p=CONDUIT
- APIs
  - TAR_API — Tar Archive API (`oro:tar`) — /runtime/docs/?p=TAR_API
- Platform
  - WINDOW_MANAGEMENT — Window Management — /runtime/docs/?p=WINDOW_MANAGEMENT
  - ANDROID_STORAGE — Android Storage Defaults — /runtime/docs/?p=ANDROID_STORAGE
  - background-services — Background Services Architecture — /runtime/docs/?p=background-services
- Security
  - SECURE_STORAGE — Secure Storage — /runtime/docs/?p=SECURE_STORAGE
  - SANDBOX_HELPER — Sandbox Helper Implementation Plan — /runtime/docs/?p=SANDBOX_HELPER
- Networking
  - TLS_QUICKSTART — TLS Quickstart (Experimental) — /runtime/docs/?p=TLS_QUICKSTART
  - TLS_TESTING — TLS Testing Guide — /runtime/docs/?p=TLS_TESTING
  - WEBVIEW_TLS_PINS — WebView TLS Pins — /runtime/docs/?p=WEBVIEW_TLS_PINS
- Web Platform
  - WEB_BLUETOOTH_STATUS — Web Bluetooth Runtime Status — /runtime/docs/?p=WEB_BLUETOOTH_STATUS
  - WEB_OTP — Web OTP Support — /runtime/docs/?p=WEB_OTP
  - WEB_HID_STATUS — WebHID Runtime Status — /runtime/docs/?p=WEB_HID_STATUS
  - webusb — WebUSB in Oro Runtime — /runtime/docs/?p=webusb
- MCP
  - MCP — MCP Server Configuration — /runtime/docs/?p=MCP
  - mcp/2025-06-18/INDEX — MCP Specification (2025-06-18) — /runtime/docs/?p=mcp/2025-06-18/INDEX
- AI
  - AI_SERVER — Embedded LLaMA Server (AI, OpenAI-compatible) — /runtime/docs/?p=AI_SERVER
  - AI_TOOL_CALLING — Tool-Calling (Stub) Behavior — /runtime/docs/?p=AI_TOOL_CALLING
  - AI_WHISPER — Whisper Speech Integration — /runtime/docs/?p=AI_WHISPER
- Release
  - APPLICATION_UPDATE_PROTOCOL — Oro Application Update Protocol (OUP) — /runtime/docs/?p=APPLICATION_UPDATE_PROTOCOL
  - release/ORO_RELEASE_AUTOMATION — Oro Runtime Release Automation (npm packages) — /runtime/docs/?p=release/ORO_RELEASE_AUTOMATION
  - CI_MATRIX — Oro Runtime CI/CD Matrix — /runtime/docs/?p=CI_MATRIX
  - ORO_ARTIFACT_NAMING — Oro Runtime Artifact Naming — /runtime/docs/?p=ORO_ARTIFACT_NAMING
- Governance
  - GOVERNANCE — Oro Runtime Governance Overview — /runtime/docs/?p=GOVERNANCE
  - ENGINEERING_SCOPING — Engineering Note: Scoped State, Metrics, and Limits — /runtime/docs/?p=ENGINEERING_SCOPING
- Debugging
  - CDP — CDP (Chrome DevTools Protocol) — /runtime/docs/?p=CDP

==============================================================================
DOCS: Oro Runtime Documentation (start)
URL: /runtime/docs/?p=start
==============================================================================

# Oro Runtime Documentation

Oro Runtime embeds the platform WebView and exposes native capabilities to JavaScript via high-level `oro:*` APIs.

These docs are the reference for the runtime’s architecture, subsystems, and integration surfaces (TLS, storage,
windowing, MCP, AI, and more). Use the sidebar to browse, or search for a specific concept.

## Recommended reading path

1. Architecture: [Oro Runtime Architecture](?p=RUNTIME_ARCHITECTURE)
2. Resource loading: [Navigator mounts](?p=NAVIGATOR_MOUNTS) and [Conduit](?p=CONDUIT)
3. Platform behavior: [Window management](?p=WINDOW_MANAGEMENT) and [Android storage](?p=ANDROID_STORAGE)
4. Security: [Secure storage](?p=SECURE_STORAGE) and [Sandbox helper](?p=SANDBOX_HELPER)
5. Networking: [TLS quickstart](?p=TLS_QUICKSTART), [TLS testing](?p=TLS_TESTING), and [WebView TLS pins](?p=WEBVIEW_TLS_PINS)
6. Web platform surfaces: [WebUSB](?p=webusb), [Web Bluetooth](?p=WEB_BLUETOOTH_STATUS), [Web HID](?p=WEB_HID_STATUS), [Web OTP](?p=WEB_OTP)
7. Agent integrations: [MCP server configuration](?p=MCP) and [Embedded LLaMA server](?p=AI_SERVER)

## Contributing and source code

Runtime development happens in the `oro-computer/oro-runtime` repository on GitHub.

==============================================================================
DOCS: Oro Runtime Architecture (RUNTIME_ARCHITECTURE)
URL: /runtime/docs/?p=RUNTIME_ARCHITECTURE
==============================================================================

# Oro Runtime Architecture

This document provides a detailed view of the Oro Runtime internals (with notes for legacy Socket compatibility), including its threading model, IPC pipeline, services layer, resource loading, lifecycle, and security boundaries. It is intended for contributors and advanced users integrating or extending the native runtime.

Contents

- Goals and topology
- Diagram index
- Component map
- Threading and event loops
- IPC routing and flows
- IPC types (class diagram)
- Services architecture
- Windows/WebView integration
- Resource loading and Service Worker
- Lifecycle model
- Window states (state diagram)
- Security and configuration
- Performance and reliability
- Extension points
- Directory map and anchors
- Known gaps and future work

See also: `start.md`, `CONDUIT.md`, `NAVIGATOR_MOUNTS.md`, `TLS_QUICKSTART.md`, `TLS_TESTING.md`, `WEBVIEW_TLS_PINS.md`

## Goals

- Unified, lean native runtime powering cross‑platform desktop and mobile.
- Rich JS APIs via custom schemes and a resilient IPC bridge.
- Deterministic dispatching: isolate UI/main thread work from loop work.
- Modular native services with feature gating and explicit lifecycles.
- Safe defaults: scheme isolation, optional filesystem sandbox, CORS/CSP knobs.

## Component Map

```mermaid
graph LR
  subgraph JS[JS Layer (ESM APIs)]
    A1[api/bootstrap.js]
    A2[api/ipc.js]
    A3[api/fs/*]
    A4[api/dgram.js]
    A5[api/window.js]
  end

  subgraph WV[WebView]
    B1[Preload Hooks]
    B2[window <-> bridge]
  end

  subgraph BR[Bridge]
    C1[SchemeHandlers
      - ipc:
      - oro:
      - node:]
    C2[Router]
    C3[Navigator + Mounts]
  end

  subgraph RT[Runtime Core]
    D1[loop::Loop (libuv)]
    D2[context::Dispatcher]
    D3[context::RuntimeContext]
    D4[core::Services]
    D5[window::Manager]
    D6[serviceworker::Server/Container]
  end

  JS -- fetch ipc:// --> C1
  JS -- import oro:/node: --> C1
  C1 -- route --> C2
  C2 -- invoke --> D4
  D4 -- callbacks --> C2
  C2 -- reply (send/eval) --> B2
  B2 --> JS

  D5 <--> WV
  D2 -. UI/Main thread dispatch .-> WV
  D1 -. uv_async / loop thread .-> D4
  C3 -- resolve() --> C1

  C1 <-- dev/prod resources --> C3
  C3 --> D6
```

## Diagram Index

- Component Map: overview of JS, WebView, Bridge, Runtime, Services
- Threading Model: UI/main vs loop thread dispatch
- IPC Request/Response: standard request path
- IPC Streaming: SSE/chunked flows
- IPC Types: class diagram for key IPC types
- Oro Scheme Resolution: end-to-end request path with Service Worker fallback
- Permissions/Event Emission: system event propagation to JS
- Runtime Lifecycle: high-level runtime state machine
- Window States: window manager status transitions

## Rendering Diagrams

- Preview in Markdown: most editors (VS Code with Mermaid) render ```mermaid blocks inline.
- Export SVG locally: `npm run docs:diagrams` (writes to `build/diagrams`).
- Export PNG locally: `npm run docs:diagrams:png`.
- CI artifacts: a GitHub workflow renders diagrams on pushes/PRs touching docs and uploads them as an artifact named `runtime-diagrams`.

## Threading and Event Loops

The runtime separates concerns between:

- loop thread: libuv‑based work, timers, IO; runs callbacks enqueued via `Loop::dispatch()`.
- UI/main thread: platform WebView and windowing; accessed via `context::Dispatcher`.
- background threads: optional worker threads spawned by services (e.g., process, UDP) and platform internals.

Key primitives

- `src/runtime/loop/loop.cc`: backing libuv loop, `uv_async_t` for dispatch, platform integration.
- `src/runtime/context/dispatch.cc`: platform‑specific marshaling to UI/main thread.

```mermaid
flowchart LR
  subgraph UI[UI/Main Thread]
    U1[WebView + Window]
    U2[Dispatcher::dispatch(cb)]
  end
  subgraph UV[Loop Thread]
    L1[Loop::dispatch(cb)]
    L2[uv_async_t]
    L3[Run Queue]
  end
  U1 <-- synchronous UI work --> U2
  L1 --> L2 --> L3 --> U1
  U2 -->|platform invoke| U1

  classDef main fill:#eef,stroke:#88f
  classDef loop fill:#efe,stroke:#8b8
  class U1,U2 main
  class L1,L2,L3 loop
```

Platform specifics

- Linux: integrates `uv_backend_fd` with GTK main loop via `GSource` (prepare/check/dispatch); see `src/runtime/loop/loop.cc`.
- Apple: loop may run on a dedicated thread; UI work is `dispatch_sync` onto main queue.
- Windows: dispatcher uses `WM_APP` posts targeting the captured main thread; queued until `notifyReady()`; see `src/runtime/context/dispatch.cc`.
- Android: posts through the JVM/Looper to the activity thread.

Loop states

- `None → Init → Idle ↔ Polling → Paused/Stopped → Shutdown`.
- `Loop::dispatch()` transitions to Polling while draining queue; resumes Idle afterward.

## IPC Routing and Flows

The bridge installs custom scheme handlers in the WebView. The JS layer performs IPC by issuing HTTP‑like requests to `ipc://` with a JSON body; results are sent back via `evaluateJavaScript()` or streamed via queued responses.

Main types

- `src/runtime/ipc.hh`: `ipc::Message`, `ipc::Result`, `ipc::Router`.
- `src/runtime/bridge/bridge.cc`: scheme handlers, coalesced SSE/chunk writes, JavaScript resolution.

Basic request/response

```mermaid
sequenceDiagram
  participant JS as JS (api/ipc.js)
  participant WV as WebView (ipc:)
  participant BR as Bridge::Router
  participant SV as Service

  JS->>WV: fetch("ipc://service.method?seq=123", body)
  WV->>BR: SchemeHandlers::Request
  BR->>BR: parse Message(uri)
  BR->>SV: router.invoke(message, body, cb)
  SV-->>BR: Result(Data|Err)
  BR-->>WV: Response 200/4xx with JSON
  WV-->>JS: Promise resolve/reject
```

Queued responses and streaming

- Queued body: service sets `QueuedResponse{body,length,headers}`, bridge serializes minimal JS to resolve client when the renderer pulls the queue.
- SSE: `QueuedResponse::eventStreamCallback` emits `text/event-stream` events; bridge coalesces small writes for efficiency.
- Chunked: `QueuedResponse::chunkStreamCallback` emits chunked transfer; bridge buffers to 16KB threshold before writes.

```mermaid
sequenceDiagram
  participant JS as JS (EventSource)
  participant WV as WebView (ipc:)
  participant BR as Bridge
  participant SV as Service

  JS->>WV: GET ipc://events (Accept: text/event-stream)
  WV->>BR: Request
  BR->>SV: router.invoke(...)
  SV-->>BR: Result{ queuedResponse.eventStreamCallback }
  BR-->>WV: 200 + headers (SSE)
  loop Until finished
    SV-->>BR: event(name,data,false)
    BR-->>WV: write SSE frame (coalesced)
  end
  SV-->>BR: event(_,_,true)
  BR-->>WV: finalize
```

Oro scheme resolution (detailed)

```mermaid
sequenceDiagram
  participant WV as WebView (oro:)
  participant BR as Bridge.oro-handler
  participant SW as ServiceWorker Container
  participant NV as Navigator.resolve()
  participant FS as Filesystem Resource

  WV->>BR: GET oro://<bundle>/path
  alt SW registered and allowed
    BR->>SW: container.fetch(req)
    SW-->>BR: response (200/other)
    BR-->>WV: send response
  else No SW match or 404
    BR->>NV: resolve(path, resourcesDir)
    alt Redirect
      BR-->>WV: 302 Location
    else Mount
      NV-->>BR: mount filename
      BR->>FS: read file
      FS-->>BR: data + mime
      BR-->>WV: 200 + headers + body
    else Resource
      NV-->>BR: app resource
      BR->>FS: read file
      FS-->>BR: data + mime
      BR-->>WV: 200 + headers + body
    end
  end
```

Cancellation

- WebView cancels pending requests (navigation, network abort); `SchemeHandlers::RequestCallbacks.cancel` triggers `MessageCancellation` if provided.

Windows note

- WebView2 may buffer custom‑scheme bodies; incremental delivery of SSE/chunked responses is not guaranteed.

## Services Architecture

Services expose native capabilities and map IPC routes to API semantics.

Key pieces

- `src/runtime/core/services.hh`: registry and lifecycle.
- Service examples: FS, DNS, Timers, UDP, OS, Process, SQLite, NetworkStatus, Notifications, MediaDevices, Geolocation, TLS, Diagnostics, AI.
- SQLite depends on the amalgamation staged at `build/sqlite/sqlite3.c`; `bin/install.sh` (and CI bootstrap) should run `bin/fetch-sqlite.sh` or set `SQLITE_SOURCE_DIR` before building.
- Each service gets `context`, `dispatcher`, `loop`, and manages its own handles and observers.

Lifecycle

- `core::Services::start()`/`stop()` called by `runtime::Runtime` on resume/pause/stop.
- Feature gating enables/disables specific services by build/user config.

Concurrency patterns

- Long‑running or blocking operations are scheduled on the loop thread.
- UI‑bound work (dialogs, permission prompts) marshaled via `dispatcher.dispatch()`.
- libuv handles must be closed explicitly; prefer `uv_close(handle, cb)` where state needs cleaning.

## Windows and WebView Integration

Window lifecycle and lookup

- `src/runtime/window/manager.cc`: indexed manager tracks windows and their status transitions (`NONE → CREATED → SHOWN/HIDDEN → CLOSING → EXITING`).
- Each window owns a `bridge::Bridge`, which owns `Navigator` and `SchemeHandlers`.
- Manager can resolve windows by bridge, webview, or client id.

Bridge responsibilities

- `src/runtime/bridge/bridge.cc`:
  - inject preload, set up scheme handlers (ipc, oro, node)
  - route IPC to services; marshal results to JS (resolve/emit)
  - coalesce SSE and chunked writes
  - integrate Service Worker proxying for `oro:` origin

WebView custom schemes (`src/runtime/webview.hh`)

- `SchemeHandlers::Request/Response` wrap platform handles and headers/body.
- Platform typedefs unify Apple/Linux/Windows/Android request/response types.
- `Navigator` maintains origin, mounts, resolution logic and can block/allow navigation.

## Resource Loading and Service Worker

Module and asset delivery paths

- `oro:` scheme
  - Serves packaged app assets or dev resources directory.
  - Honors `webview_default_index` fallback when resolving.
  - Supports SPA fallback when enabled via `webview_allow_any_route = true` (unmatched routes fall back to the default index, typically `/index.html`).
  - Integrates with Service Worker Server when registration exists for origin.
- `node:` scheme
  - Proxies allowed Node core module imports to packaged shims `/oro/<module>.js`.
  - Produces an ESM proxy module ensuring a canonical module instance URL.

```mermaid
flowchart TB
  WV[WebView] -- oro://<bundle>/... --> BR[Bridge]
  BR --> SW{Service Worker registered?}
  SW -- yes --> SWC[serviceworker::Container.fetch]
  SW -- no  --> RES[Resolve to resource/mount]
  SWC --> RSP[Response]
  RES --> RSP
  RSP --> WV
```

Permissions and event emission

```mermaid
sequenceDiagram
  participant OS as OS/Platform Permission
  participant SV as Service (e.g., Notifications)
  participant BR as Bridge
  participant WV as WebView
  participant JS as JS (window)

  OS-->>SV: permission change / event
  SV-->>BR: observer callback(JSON)
  BR->>WV: evaluateJavaScript(emit(name, data))
  WV-->>JS: dispatch event in page
```

Service Worker Server

- `src/runtime/serviceworker/server.cc` creates a hidden headless window per origin when needed; toggled by `ORO_SERVICE_WORKER_DEBUG` env.
- Streams and fetch path are coordinated via bridge maps (`swPending*`, `swActive*`).

## Lifecycle Model

High‑level app events are emitted to windows via `window::Manager.emit()` and bridged to JS (mirrors host window activation/minimize).

```mermaid
stateDiagram-v2
  [*] --> Init
  Init --> Idle: start()
  Idle --> Polling: loop work
  Idle --> Paused: pause()
  Paused --> Init: resume()
  Idle --> Stopped: stop()
  Stopped --> Shutdown: destroy()
```

## Window States (state diagram)

```mermaid
stateDiagram-v2
  [*] --> WINDOW_NONE
  WINDOW_NONE --> WINDOW_CREATED: createWindow()
  WINDOW_CREATED --> WINDOW_SHOWN: show()
  WINDOW_CREATED --> WINDOW_HIDDEN: headless
  WINDOW_SHOWN --> WINDOW_HIDDEN: hide()
  WINDOW_HIDDEN --> WINDOW_SHOWN: show()
  WINDOW_SHOWN --> WINDOW_CLOSING: close()
  WINDOW_CLOSING --> WINDOW_CLOSED
  WINDOW_CLOSED --> WINDOW_EXITING: exit(code)
  WINDOW_CLOSED --> WINDOW_KILLING: kill()
  WINDOW_EXITING --> WINDOW_EXITED
  WINDOW_KILLING --> WINDOW_KILLED
```

Platform mapping summary

- iOS/macOS/Android/Windows/Linux map activation/background/terminate to `applicationpause`/`applicationresume`/`applicationstop` events. On desktop, native pause/resume is opt‑in (`lifecycle_desktop_always_running = false`).
- File watchers are stopped on pause; recreate on `applicationresume` as needed.

## Security and Configuration

Boundaries

- Scheme isolation: only registered schemes are allowed; `node:` restricts module list.
- JS only gains native capabilities through IPC routes, which consult permissions/config.
- Optional filesystem sandbox and symlink restrictions.

Key config (oro.toml or env overrides)

- Filesystem sandbox: `filesystem_sandbox_enabled`, `FS_SANDBOX=1`.
- No‑follow symlinks: `filesystem_no_follow_symlinks`, `FS_NOFOLLOW=1`.
- WebView headers: `webview_csp`, `webview_referrer_policy`, `webview_cors_*`.
- Lifecycle desktop behavior: `lifecycle_desktop_always_running`.
- Service Worker debug: `ORO_SERVICE_WORKER_DEBUG`.

## Performance and Reliability

Event/write coalescing

- SSE: coalesce small events before flush to reduce per‑frame overhead.
- Chunked: buffer chunks to 16KB before write to reduce syscall pressure.

Libuv loop shutdown (`src/runtime/loop/loop.cc`)

- Ensure `uv_stop` + `uv_run(NOWAIT)`, close async handle, repeatedly try `uv_loop_close`, walk/close remaining handles, retry, with small sleeps to yield; avoids leaks/hangs on shutdown.

Dispatch correctness

- UI work must go through `context::Dispatcher` to avoid thread affinity bugs.
- On Windows, dispatcher captures main thread id, posts `WM_APP` messages, and queues until `notifyReady()`.

Handle lifecycle

- Prefer `uv_close(handle, callback)` when state updates are needed; avoid relying on nulling pointers.

## Extension Points

Add a new service

1. Create `src/runtime/core/services/<name>.hh/.cc` exposing IPC‑level methods with signatures `(const ipc::Message::Seq&, Params..., Callback)`.
2. Register routes in `src/runtime/ipc/routes.cc` mapping `"<service>.<method>"` to service calls.
3. Add feature flag in `core::Services::Features` and include in lifecycle `start()/stop()`.
4. Expose JS surface under `api/` (and update `api/index.d.ts`).

Add an IPC route

- Map in `ipc::Router::map(name, callback)` or via `routes.cc`. Use `dispatcher` for UI‑bound actions and `loop.dispatch` for loop‑bound work.

Serve custom content

- Register a new scheme via `SchemeHandlers.registerSchemeHandler("myscheme", handler)` in the bridge (or extend platform registration if needed).

Integrate a Service Worker behavior

- Extend `serviceworker::Container` and fetch handling; use bridge `swPending*` and `swActive*` maps for streaming coordination.

## Directory Map and Anchors

- Loop and Dispatch
  - src/runtime/loop/loop.cc
  - src/runtime/context/dispatch.cc
- Bridge and IPC
  - src/runtime/bridge.hh
  - src/runtime/bridge/bridge.cc
  - src/runtime/ipc.hh
  - src/runtime/ipc/message.cc
  - src/runtime/ipc/router.cc
  - src/runtime/ipc/routes.cc
- WebView and Windowing
  - src/runtime/webview.hh
  - src/runtime/window/manager.cc
  - src/runtime/window/\*.cc|.mm|.kt|.cc (platforms)
- Services
  - src/runtime/core/services.hh
  - src/runtime/core/services/\*.cc|.hh
- Service Worker
  - src/runtime/serviceworker/server.cc
  - src/runtime/serviceworker/\*.cc
- Runtime Container
  - src/runtime/runtime.hh

JS surface (ESM proxies and APIs)

- api/_.js and api/_.d.ts
- api/ipc.js (IPC client), api/\* for service surfaces

## Known Gaps and Future Work

- Tighten timers ownership and ensure consistent `uv_close` semantics across services.
- Validate Windows dispatcher end‑to‑end scenarios and lifecycle edge cases.
- Audit window manager read locks and enumerations for thread safety.
- Recreate FS watchers on resume with helper utilities.
- Windows WebView2 buffering: evaluate alternative strategies for streaming (e.g., WebSocket/SSE polyfills) when the custom `oro:` scheme is buffered.

## Appendix: Example Sequence Annotations

Queued response script injection

- `src/runtime/context/context.cc` creates a small JS program that notifies the renderer of queued response IDs so the JS side can fetch payloads/bodies lazily.

Node core module proxying

- `src/runtime/bridge/bridge.cc` generates an ESM proxy to the canonical `oro://.../oro/<module>.js` path to ensure a single module instance across import URLs.

Service Worker server window

- `src/runtime/serviceworker/server.cc` spawns a hidden window per origin; toggled by env; ensures consistent SW lifecycle and debugging hooks.

## IPC Types (class diagram)

```mermaid
classDiagram
  class ipc::Message {
    +bytes::BufferQueue buffer
    +Client client
    +URL uri
    +String seq
    +bool isHTTP
  }

  class QueuedResponse {
    +ID id
    +uint64_t ttl
    +SharedPtr<byte[]> body
    +size_t length
    +http::Headers headers
    +EventStreamCallback*
    +ChunkStreamCallback*
  }

  class ipc::Result {
    +Message message
    +String seq
    +JSON::Any value
    +http::Headers headers
    +QueuedResponse queuedResponse
  }

  class ipc::Router {
    +map(name, cb)
    +invoke(Message, body, cb)
    +listen(name, cb)
    +unlisten(name, token)
  }

  class bridge::Bridge {
    +SchemeHandlers schemeHandlers
    +Navigator navigator
    +ipc::Router router
    +bool send(seq, json, qr)
    +bool emit(name, json)
  }

  class webview::SchemeHandlers {
    +registerSchemeHandler(scheme, handler)
    +handleRequest(Request, cb)
  }

  class webview::Navigator {
    +Location location
    +configureWebView(wv)
    +resolve(path, dir)
  }

  ipc::Router <-- bridge::Bridge
  webview::SchemeHandlers <-- bridge::Bridge
  webview::Navigator <-- bridge::Bridge
  ipc::Result --> QueuedResponse
  ipc::Result --> ipc::Message
```

==============================================================================
DOCS: Navigator Mounts (NAVIGATOR_MOUNTS)
URL: /runtime/docs/?p=NAVIGATOR_MOUNTS
==============================================================================

# Navigator Mounts

The navigator mounting system lets you expose host file system directories to the webview so that `fetch`, `<img>`, `<video>`, navigation, and other URL-based requests can read live files without bundling them into the application. Each mount maps a host directory to a virtual root under the app's `oro://<bundle id>` origin, so in-page navigation behaves like a regular static file server while still honouring the runtime's security policies.

## Configuration

Mounts are declared in `oro.toml` under `[webview.navigator.mounts]`. Each entry takes the form `<host path> = <navigator base path>`.

```ini
[webview.navigator.mounts]
$HOST_HOME/.oro/navigator/example = /navigator
linux_/srv/shared/assets = /shared
mac_$HOST_CONTAINER/Resources = /app-bundle
```

**Key conventions**

- Host aliases: `$HOST_HOME`, `$HOST_CONTAINER`, `$HOST_PROCESS_WORKING_DIRECTORY`, `~`, and `$HOME` expand to platform-specific directories.
- Platform targeting: Prefix a key with `mac_`, `win_`, `linux_`, `ios_`, or `android_` to enable the mount only on that platform. The prefix is removed after matching the current platform.
- Navigator paths should begin with `/` and may omit the trailing slash. They are compared against incoming request paths using a simple prefix test.
- Aliases are resolved before the path is canonicalised, so you can point at network shares or other absolute paths once expanded.

Changes to `src/cli/templates.hh` sync into `api/CONFIG.md` via `npm run gen`.

## URL Resolution Semantics

When a webview requests `oro://<bundle-id>/navigator/foo`, the runtime resolves the path using the following rules (mirroring how bundled resources behave):

1. Check for an explicit file (`foo`).
2. Check for a directory containing `index.html`; requesting `/navigator/foo` will redirect to `/navigator/foo/` for `GET` requests if that index exists.
3. As a convenience, resolve `foo.html` if present.

If the request matches a mount, the resolved host file path is served. Otherwise the runtime falls back to packaged resources (`/index.html`, `default_index`, or SPA fallback when `allow_any_route` is enabled) after giving registered service workers a chance to respond.

## Security Model

Navigator mounts participate in the runtime's sandbox and entitlements:

- `filesystem::Resource::isMountedPath` whitelists mounted directories so they can be opened without triggering macOS security-scoped bookmarks.
- When the macOS sandbox is enabled (`mac_sandbox != false`), any `$HOST_HOME`-based mounts are added to the generated entitlements automatically.
- On Linux, each mount is injected into the WebKit sandbox via `webkit_web_context_add_path_to_sandbox` so the renderer can read mounted files directly.
- The filesystem sandbox (`filesystem_sandbox_enabled`) still applies: requests are denied with `SecurityError` if they escape the declared mount roots or recognised well-known paths.

## Behavioural Notes

- Mount resolution is case-sensitive on Unix-like systems and case-preserving on Windows—follow the host file system's semantics when authoring URLs.
- Service workers see the mounted responses exactly as if they were bundled resources, so they can cache or intercept them as usual.
- Mounted directories are read-only from the webview's perspective; write operations must use the runtime `fs` APIs and target the host path directly.

## Example Workflow

1. Create a host directory and initial content:
   ```bash
   mkdir -p "$HOME/.oro/navigator/example"
   echo "Hello from host" > "$HOME/.oro/navigator/example/hello.txt"
   ```
2. Declare the mount in `oro.toml`:
   ```ini
   [webview.navigator.mounts]
   $HOST_HOME/.oro/navigator/example = /navigator
   ```
3. Reference it from the webview:
   ```html
   <img src="/navigator/hello.txt" alt="Mounted content" />
   ```

## Repository Example

The `examples/navigator-mounts` demo scaffolds a mount at `$HOST_HOME/.oro/navigator-mounts` and shows how to:

- Populate the host directory using the runtime's `fs` module when bootstrapping the app.
- List mounted files and stream their contents through `fetch`.
- Toggle between bundled assets and mounted assets to compare behaviours.

Build the examples bundle and run the `navigator-mounts` entry to try it out:

```bash
npm run relink
oroc build examples
oroc run examples --entry navigator-mounts/index.html
```

(Replace `oroc build`/`oroc run` with your usual workflow if you already have the examples app linked.)

==============================================================================
DOCS: Conduit Transport (CONDUIT)
URL: /runtime/docs/?p=CONDUIT
==============================================================================

# Conduit Transport

Conduit is the Oro Runtime-managed binary channel used for high-frequency or low-latency communication between JavaScript and the native services. It complements the request/response style `ipc://` bridge by exposing a WebSocket endpoint that stays open across the runtime lifetime, reuses a single framing format, and avoids work on the UI thread whenever possible.

The transport is implemented in `runtime::core::services::Conduit` and surfaced to JavaScript through the `oro:conduit` module (`api/conduit.js`). Modules such as UDP, TLS, AI streaming, and future high-throughput features should attempt to use Conduit first, falling back to `ipc.send`/`ipc.write` only when the socket is unavailable.

## Lifecycle

- When the runtime boots, the Conduit service launches a local WebSocket server bound to an ephemeral port. The port, hostname, and optional shared key are exported to JavaScript via `globalThis.__args.conduit`.
- `Conduit.port` tracks the current server port. The helpers `Conduit.status()` and `Conduit.waitForActiveState()` let code query or await activation.
- Instances (`new Conduit({ id })`) register themselves in an internal pool. The pool is used when the application is paused or resumed:
  - `hooks.onApplicationPause` stops the server and marks every client inactive.
  - `hooks.onApplicationResume` restarts the server, updates the known port, and calls `reconnect()` on clients that opted in (`shouldReconnect = true`).
- The WebSocket URL is `ws://localhost:<port>/<client-id>/<top-window-id>?key=<sharedKey>`. The shared key is optional and can be updated at runtime via `Conduit.setSharedKey()`.
- Conduit emits standard DOM events (`open`, `message`, `error`, `close`). Reconnects dispatch a synthetic `reopen` event so higher layers can resume subscriptions after the socket returns.

## Message Framing

All messages are binary `Uint8Array` payloads with a compact header section.

```
┌──────────────┬─────────────────────────────┐
│ Byte Offset  │ Meaning                     │
├──────────────┼─────────────────────────────┤
│ 0            │ Number of headers (uint8)   │
│ 1..n         │ Repeated header entries     │
│              │   - key length (uint8)      │
│              │   - key bytes (UTF-8)       │
│              │   - value length (uint16 BE)│
│              │   - value bytes (UTF-8)     │
│ n+1..n+2     │ Payload length (uint16 BE)  │
│ rest         │ Payload bytes               │
└──────────────┴─────────────────────────────┘
```

Values in the header section are decoded back into JavaScript primitives. Strings matching `true`, `false`, or `null` return the corresponding primitive; decimal strings are converted to numbers. The payload is exposed as a `Uint8Array` and is left untouched.

Recommended header keys include `route` (identifies the native handler), `port`, `address`, and any other domain-specific metadata consumers need to interpret the payload.

## JavaScript API Overview

Static helpers:

- `Conduit.status()` → `{ port, isActive, sharedKey }`
- `Conduit.diagnostics()` → runtime level stats (active handles, count)
- `Conduit.waitForActiveState({ maxQueriesForStatus })` → resolves when the server reports `isActive`.
- `Conduit.getSharedKey()` / `Conduit.setSharedKey()`

Instance methods and patterns:

- `new Conduit({ id, sharedKey })` immediately attempts to connect. Instances keep themselves alive with GC finalizers; call `close()` to opt out and prevent reconnects.
- `connect(callback)` establishes the WebSocket and resolves once the `open` event fires. The callback receives an `Error` if the attempt fails.
- `reconnect({ retries, timeout })` wraps `connect()` in an exponential backoff loop (default: 32 retries, capped at 30s delay). A successful reconnection dispatches a `reopen` event.
- `receive(handler)` registers a message callback (`handler(error | null, { options, payload })`). Only one receive handler is active at a time; calling `receive` replaces the previous hooks.
- `send(options, payload?)` frames the provided metadata and optional payload. It returns `false` when the socket is paused, disconnected, or otherwise unusable. Callers should treat a `false` return as a signal to enter their fallback path and trigger `reconnect()`.
- `close()` prevents further reconnects, removes event listeners, and severs the WebSocket if one is active.

## Integration Guidelines

1. **Prefer Conduit for streaming workloads.** For example, UDP uses it to start/stop reads and deliver datagrams without blocking `ipc://` handlers.
2. **Set up `receive` before issuing commands.** In modules that expect inbound data (`message` events, AI streaming segments, etc.), register the `receive` handler immediately after constructing the Conduit instance.
3. **Gracefully degrade.** If `send()` returns `false`, log the failure, invoke any module-specific fallback (`ipc.send`/`ipc.write`), and call `conduit.reconnect().catch(() => {})` to restore the preferred transport in the background.
4. **Handle `reopen`.** When the transport reconnects the runtime dispatches a `reopen` event. Reissue any outstanding subscriptions (e.g., `udp.readStart`) inside this handler so delivery resumes without requiring user action.
5. **Pause/Resume aware.** During application pause events the transport is torn down intentionally. Modules should expect a burst of `error`/`close` events and rely on the `reopen` path to restart delivery when the app resumes.
6. **Keep IDs stable.** The `id` passed to `new Conduit({ id })` is part of the WebSocket routing path and is used server-side to demultiplex clients. Reusing the same ID across reconnects allows the native side to resume stateful streams cleanly.

## Diagnostics and Troubleshooting

- Enable `DEBUG=conduit` to surface verbose logs during development. The transport logs connection attempts, retries, and failures.
- `Conduit.diagnostics()` aggregates runtime statistics, including active handles and the IDs currently subscribed.
- Use `internal.conduit.status`/`stop`/`start` (via `ipc.request`) for low-level testing or when running in headless environments.
- A `false` return from `send()` indicates the WebSocket is not open. Check whether the application is paused (`hooks.onApplicationPause` currently sets a global flag) or whether the shared key is out of sync.

## Related Reading

- `api/conduit.js` – JavaScript implementation and hooks.
- `src/runtime/core/services/conduit.cc` – native service and client management.
- `api/dgram.js` – example of a module that mixes Conduit and IPC pathways for resilience.

==============================================================================
DOCS: Tar Archive API (`oro:tar`) (TAR_API)
URL: /runtime/docs/?p=TAR_API
==============================================================================

# Tar Archive API (`oro:tar`)

The `oro:tar` module exposes a small, robust API for working with tar
archives from JavaScript. It is designed for very large archives, supports
random access, and can be backed either by files on disk (optionally
`mmap`-backed on supported platforms) or in-memory buffers.

At a high level:

- Archives on disk are opened via the native tar service and indexed once.
- Individual entries are read on demand via range reads (streaming decode).
- New archives are written entry-by-entry via chunked body writes (streaming encode).
- In-memory archives are backed by a single buffer and use the same reader/index.

## Importing

```js
import * as tar from 'oro:tar'
// or:
// import { TarArchive, open, create, fromBuffer } from 'oro:tar'
```

## Opening archives

- `tar.open(path, options?)`  
  Opens an existing archive on disk.

- `tar.create(path, options?)`  
  Creates (or truncates) an archive for writing.

- `tar.fromBuffer(buffer)`  
  Opens a read‑only archive backed by a `Buffer`, `Uint8Array`, or `ArrayBuffer`.

All helpers return a `TarArchive` instance.

```js
const archive = await tar.open('./assets.tar', { mmap: true })
const entries = await archive.entries()
const logo = await archive.read('images/logo.png')
```

`TarOpenOptions`:

- `writable?: boolean` – set `true` to open a file for writing (implied by `create`).
- `mmap?: boolean` – hint that the runtime may `mmap` very large archives when
  opening them read‑only on supported platforms.
- `uid?: number` – optional global uid metadata for writers.
- `gid?: number` – optional global gid metadata for writers.
- `uname?: string` – optional global uname metadata for writers.
- `gname?: string` – optional global gname metadata for writers.
- `mtime?: number` – optional global mtime metadata for writers (seconds since UNIX epoch).

## `TarArchive`

`TarArchive` represents an open archive descriptor in the runtime:

- `TarArchive.open(path, options?)`
- `TarArchive.create(path, options?)`
- `TarArchive.fromBuffer(buffer)`
- Properties:
  - `id: string` – stable descriptor id (for IPC only).
  - `path: string` – resolved path for file‑backed archives (empty for buffers).
  - `writable: boolean` – whether the archive was opened for writing.
  - `mmap: boolean` – whether the runtime was asked to use `mmap`.
  - `size: number` – total archive size in bytes (for indexed archives).
  - `entryCount: number` – number of indexed entries.
  - `closed: boolean` – `true` after `close()` succeeds.
  - `finalized: boolean` – `true` after `finalize()` succeeds (writers only).

### Metadata and random access

- `archive.entries(): Promise<TarEntryStat[]>`  
  Returns metadata for all indexed entries in the archive.

- `archive.stat(path: string): Promise<TarEntryStat>`  
  Returns metadata for a single entry, or throws if not found.

`TarEntryStat`:

- `path: string`
- `linkpath?: string` – present for symlink/hardlink entries.
- `devmajor?: number` – present for char/block device entries.
- `devminor?: number` – present for char/block device entries.
- `sparse?: { offset: number, length: number }[]` – present for sparse file entries (data regions only).
- `size: number`
- `mode: number`
- `mtime: number` (seconds since UNIX epoch)
- `uid: number`
- `gid: number`
- `uname?: string`
- `gname?: string`
- `kind: 'file' | 'directory' | 'symlink' | 'hardlink' | 'block-device' | 'char-device' | 'fifo' | 'other'`
- `isFile: boolean`
- `isDirectory: boolean`

The native reader builds an in‑memory index at open time for random access.
For very large archives with many entries, this trades O(entryCount) memory
for O(1) lookups by `path`.

The reader supports PAX (`x`/`g`), GNU longname/longlink (`L`/`K`), and GNU
sparse entries (old GNU `S` format, plus PAX `GNU.sparse.*` variants).

### Reading

- `archive.read(path, options?): Promise<Buffer>`  
  Reads a slice of an entry into a single `Buffer`.

- `archive.readStream(path, options?): AsyncIterableIterator<Buffer>`  
  Provides a streaming view over an entry, yielding chunks as `Buffer`s.

`TarReadOptions`:

- `offset?: number` – starting byte offset (default `0`).
- `length?: number` – number of bytes to read (defaults to `size - offset`).
- `signal?: AbortSignal`
- `timeout?: number` – per‑request timeout in milliseconds.

`TarReadStreamOptions`:

- `highWaterMark?: number` – max chunk size in bytes (default `65536`).
- `start?: number` – starting byte offset (default `0`).
- `end?: number` – inclusive end offset (defaults to `entry.size - 1`).
- `signal?: AbortSignal`
- `timeout?: number`

Example (streaming decode):

```js
const chunks = []
for await (const buf of archive.readStream('dir/streamed.txt', {
  highWaterMark: 64 * 1024
})) {
  chunks.push(buf)
}

const full = Buffer.concat(chunks)
```

Attempting to read a directory entry will throw an error with code `EISDIR`.
Sparse file holes are synthesized as zero bytes when reading or streaming.
When extracting sparse files to disk, the runtime attempts to preserve holes by
writing only the sparse data regions.

### Writing

Writing is only allowed for archives opened with `create` (or `open` with
`{ writable: true }`):

- `archive.append(header, body, options?): Promise<void>`
- `archive.finalize(): Promise<void>`

`TarEntryHeader`:

- `path: string` – entry path within the archive.
- `linkpath?: string` – required when `kind` is `'symlink'` or `'hardlink'`.
- `devmajor?: number` – required when `kind` is `'char-device'` or `'block-device'`.
- `devminor?: number` – required when `kind` is `'char-device'` or `'block-device'`.
- `size?: number` – total body size in bytes; required when `body` is an async iterable.
- `sparse?: { offset: number, length: number }[]` – sparse data regions for sparse file entries (sorted, non-overlapping).
- `sparseSize?: number` – logical size of the sparse file entry (defaults to the end of the last region).
- `mode?: number` – file mode (defaults to `0o644` for files and `0o755` for directories).
- `mtime?: number` – modification time in seconds (defaults to the archive global mtime if set, otherwise current time).
- `uid?: number` – optional uid metadata (overrides archive global uid for this entry).
- `gid?: number` – optional gid metadata (overrides archive global gid for this entry).
- `uname?: string` – optional uname metadata (overrides archive global uname for this entry).
- `gname?: string` – optional gname metadata (overrides archive global gname for this entry).
- `kind?: TarEntryKind` – entry type (defaults to `'file'`).

Bodies can be:

- `Buffer`
- `Uint8Array`
- `ArrayBuffer`
- `AsyncIterable<Buffer | Uint8Array>`

For link entries (`kind: 'symlink' | 'hardlink'`), `linkpath` must be provided
and the entry body must be empty (pass `null` or an empty buffer).

For non-file entries (`kind: 'directory' | 'symlink' | 'hardlink' | 'fifo' | 'char-device' | 'block-device'`),
the entry body must be empty and `header.size` (if provided) must be `0`.

For device entries (`kind: 'char-device' | 'block-device'`), `devmajor` and
`devminor` must be provided.

When using an async iterable, `header.size` **must** be provided and match the
total number of bytes yielded; otherwise the append is rejected. For non‑stream
bodies (`Buffer`/`Uint8Array`/`ArrayBuffer`), if `header.size` is provided it
must match the body length; mismatches are rejected rather than padded or
truncated implicitly.

Sparse file entries can be written by providing `header.sparse`. The entry body
must contain only the stored data regions (concatenated in order), and
`header.size`/body length must equal the sum of region lengths. The resulting
entry reports `size === sparseSize` when read back.

All sizes and offsets are JavaScript numbers and must be safe integers
(<= `2^53 - 1`). Sparse maps are capped to 16384 regions to keep PAX metadata
within supported limits.

`TarWriteOptions`:

- `signal?: AbortSignal`
- `timeout?: number`

Example (single buffer):

```js
await archive.append(
  { path: 'foo.txt', mode: 0o644 },
  Buffer.from('hello world')
)
```

Example (streaming encode):

```js
async function* body() {
  yield Buffer.from('chunk-1-')
  yield Buffer.from('chunk-2')
}

await archive.append(
  { path: 'dir/streamed.txt', size: 15 },
  body()
)

await archive.finalize()
```

`finalize()` writes the terminating tar blocks and flushes the underlying
sink. After finalization, the archive descriptor remains open, but additional
writes should not be attempted.

### Extracting entries

`TarArchive` exposes convenience helpers for writing entry contents to disk
using a streaming pipeline:

- `archive.extract(path, destPath, options?): Promise<void>`

This method:

- Resolves `path` within the archive.
- For file entries, streams contents via `TarArchive.readStream` and writes to
  `destPath` using `fs.createWriteStream`, handling backpressure and respecting
  `signal`/`timeout` when provided.
- For directory entries, creates `destPath` as a directory.
- For symlink entries, creates a symlink at `destPath` pointing to the entry's `linkpath`.
- For hardlink entries, creates a hardlink at `destPath` pointing to the entry's `linkpath`
  when the target is available at the computed destination root.
- Other special entries (`'fifo'`, `'char-device'`, `'block-device'`) are not
  materialized by this helper.
- Attempts to preserve `mode` and `mtime` metadata when supported by the
  underlying platform/filesystem. When requested, it will also attempt to
  preserve owner metadata and special mode bits.

Example:

```js
const archive = await tar.open('./assets.tar')
await archive.extract('images/logo.png', './out/logo.png')
await archive.close()
```

To extract all file and directory entries into a directory:

```js
const archive = await tar.open('./assets.tar')
await archive.extractAll('./out/assets')
await archive.close()
```

`extractAll` accepts an optional `filter(entry)` callback which can be used to
select which entries to materialize. Directory entries are created explicitly
when present in the archive so empty directories can be preserved.

By default `extractAll` only materializes file and directory entries. To also
extract symlink and hardlink entries, pass `{ preserveLinks: true }`.
Other special entries (`'fifo'`, `'char-device'`, `'block-device'`) are skipped.

`extractAll` and `extract` refuse to traverse existing symlinks within the
destination directory tree when creating output paths.

`extractAll` and `extract` options:

- `preserveOwner?: boolean` – attempt to apply uid/gid via `chown`/`lchown` (may require privileges; may be ignored by platform).
- `preserveSpecialModes?: boolean` – when `true`, preserves mode bits beyond `0o777` (setuid/setgid/sticky) when supported.

### In-memory archives

`TarArchive.fromBuffer` and the top‑level `tar.fromBuffer` helper open a
read‑only archive backed by an in‑memory buffer:

```js
const raw = await fs.promises.readFile('./assets.tar')
const archive = await tar.fromBuffer(raw)
const logo = await archive.read('images/logo.png')
await archive.close()
```

Buffers are not copied when already a `Buffer`. `Uint8Array` and
`ArrayBuffer` inputs are coerced to a `Buffer` once up front; the native
service then holds a shared reference for the lifetime of the archive
descriptor.

This path is useful for:

- Update artifacts downloaded into memory (see `APPLICATION_UPDATE_PROTOCOL.md`).
- Embedding asset bundles in higher‑level protocols without touching disk.

Writable in-memory archives can be created via `tar.createInMemory(options)`.
These archives behave like any other writable `TarArchive` instance (they
support `append`, `finalize`, `entries`, `stat`, `read`, etc.) but their
contents are kept in memory and can be retrieved as a `Buffer` using
`archive.toBuffer()`:

```js
const archive = await tar.createInMemory({ uid: 1000, uname: 'alice' })
await archive.append({ path: 'mem.txt' }, Buffer.from('in-memory tar payload'))
const buf = await archive.toBuffer()

// buf now contains a complete tar archive; it can be persisted or
// reopened via tar.fromBuffer(buf)
```

## Large archives and `mmap`

For file‑backed archives:

- The native reader uses 64‑bit offsets internally and can index very large
  archives (subject to platform limits and available memory).
- When `mmap: true` is passed and supported, the runtime may map the entire
  archive into memory and satisfy reads via simple `memcpy`, avoiding
  repeated `pread` calls.
- Entry headers and payloads are validated so that header + body + padding
  never exceed the underlying archive size; malformed archives are rejected.
- Very large entry sizes that do not fit in the standard octal field are
  encoded and decoded using the base‑256 extension supported by many tar
  implementations.

Random access is implemented via a per‑archive index:

- `TarArchive.open`/`fromBuffer` build an index of `path -> entry` mappings.
- Reads (`read`/`readStream`) use the index to locate the entry and issue
  a single range read for each requested slice.

For extremely large archives with many entries, this index will dominate
memory usage. In those cases, prefer:

- Streaming decode via `readStream` for individual entries.
- Keeping a single long‑lived `TarArchive` open instead of repeatedly opening
  and closing the same file.

## Conduit and streaming

The tar service uses standard IPC routes:

- `tar.open`, `tar.openBuffer`, `tar.createBuffer`, `tar.close`
- `tar.list`, `tar.stat`, `tar.read`
- `tar.write.begin`, `tar.write.data`, `tar.finalize`
- `tar.buffer`

The `oro:tar` module wraps these routes and uses the shared IPC helpers
(`ipc.request`, `ipc.write`) so it works seamlessly with Conduit‑backed
transports. Callers should use the high‑level `TarArchive` API rather than
invoking the routes directly unless they are implementing lower‑level tools.

==============================================================================
DOCS: Window Management (WINDOW_MANAGEMENT)
URL: /runtime/docs/?p=WINDOW_MANAGEMENT
==============================================================================

# Window Management

This guide covers common window operations available in Oro Runtime across desktop and mobile platforms (legacy Socket terminology is noted where users may still encounter it).

APIs live under `oro:window` and are typically used via an `ApplicationWindow` instance returned from `oro:application` helpers.

Quick Start

- Get current window: `const win = await application.getCurrentWindow()`
- Focus/Blur (desktop/mobile): `await win.focus()` / `await win.blur()`
- Always On Top (desktop):
  - `await win.setAlwaysOnTop(true)`
  - `const onTop = await win.isAlwaysOnTop()`
- Context Menu (native, desktop): `await win.setContextMenu({ value: 'Menu:\n  Foo: f;' })`

Examples

- Focus and blur current window

```
import application from 'oro:application'

const win = await application.getCurrentWindow()
await win.blur()
await win.focus()
```

- Always on top (desktop)

```
import application from 'oro:application'

const win = await application.getCurrentWindow()
await win.setAlwaysOnTop(true)
console.log(await win.isAlwaysOnTop()) // -> true
await win.setAlwaysOnTop(false)
```

- Targeted context menu for a specific window (desktop)

```
import application from 'oro:application'

const child = await application.createWindow({ index: 2, path: 'examples/window/secondary.html', title: 'Secondary' })
await child.setContextMenu({ value: 'Menu:\n  Foo: f;', targetWindowIndex: child.index })
```

Platform Notes

- Desktop: `focus`, `blur`, and `Always On Top` map to native window manager features.
- Mobile: `focus`/`blur` map to `show`/`hide`; `Always On Top` is not supported.

See also

- `api/window.js` (ApplicationWindow)
- `api/application.js` (createWindow, getWindow(s))
- `examples/kitchen-sink` (interactive demo)

==============================================================================
DOCS: Android Storage Defaults (ANDROID_STORAGE)
URL: /runtime/docs/?p=ANDROID_STORAGE
==============================================================================

# Android Storage Defaults

Oro Runtime scopes all Android file access to the app’s private storage (legacy Socket behavior is still honored during the transition) unless
you explicitly broker additional locations. The native bootstrap wires the
following directories when the activity starts:

- **Root directory** – `Context.getExternalFilesDir(null)`; falls back to
  `Context.getFilesDir()` when the scoped “external” directory is unavailable.
- **Cache directory** – `Context.getExternalCacheDir()` with an internal cache
  fallback.
- **Media directory** – `Context.getExternalMediaDirs().first()` when present,
  otherwise `externalFilesDir/media`.
- **Temporary directory** – subdirectory of the scoped cache:
  `externalCacheDir/__BUNDLE_IDENTIFIER__`.

All directories are created eagerly so IPC consumers can assume they exist.

### Implications

- Path lookups that historically resolved to `/sdcard/...` now land inside the
  app sandbox (`~/` maps to the scoped root above). Code that needs to expose
  files outside the sandbox must go through the Storage Access Framework (SAF)
  or an explicit document tree grant.
- Build scripts and tests should avoid hardcoding `/sdcard` paths; rely on
  `App.getRootDirectory()` or the well-known directories exposed by the runtime.
- No additional runtime permissions are required for these scoped locations on
  Android 10+; broader media access still depends on the config-driven
  `READ_MEDIA_*`/`READ_EXTERNAL_STORAGE` permissions.

==============================================================================
DOCS: Background Services Architecture (background-services)
URL: /runtime/docs/?p=background-services
==============================================================================

# Background Services Architecture

## Overview

Applications need to run JavaScript work while the UI is suspended or the process is in the background. This document proposes a cross-platform background service subsystem that gives developers a worker-like JavaScript context hosted by platform-native primitives:

- **Android** — Android `Service` (foreground optional) driven by WorkManager jobs.
- **iOS / iPadOS** — `BGTaskScheduler` (`BGProcessingTask`/`BGAppRefreshTask`) runners.
- **Desktop** — headless webview contexts owned by the runtime.

The goal is a single JavaScript surface that hides platform differences while still exposing enough scheduling controls to satisfy entitlement-driven flows (notably iOS).

## Goals

- Provide a simple JS API for defining one-off or long-lived background services.
- Ensure service lifecycle can be managed from configuration (`oro.toml`) so iOS static declarations are respected.
- Allow services to communicate with the foreground runtime via existing IPC primitives.
- Minimise platform-specific code duplication and reuse the existing runtime service infrastructure.
- Support graceful degradation when a platform does not allow persistent execution.

## Non-Goals

- Replace existing `ServiceWorker`/`SharedWorker` APIs.
- Guarantee infinite background execution on platforms with strict limits (iOS).
- Provide UI surfaces; background services are headless.

## JavaScript API

### Module

New module `api/background.js` exposing:

```js
import background from 'oro:background'

await background.register({
  id: 'sync-notifications',
  entry: 'background/notifications.js',
  trigger: {
    type: 'interval',
    minimumInterval: 15 * 60 * 1000,
  },
  keepAlive: false,
  permissions: ['notifications', 'network'],
})

await background.schedule('sync-notifications')
```

API surface:

- `register(options)` — declare a background service. Persists definition in runtime state.
- `schedule(id, overrides?)` — request execution respecting platform rules.
- `cancel(id)` — cancel pending runs.
- `status(id)` — retrieve last run metadata.

Background scripts behave like dedicated workers:

- Use `self.postMessage`, `self.addEventListener('message', ...)`.
- Access to a restricted API surface identical to worker threads plus any explicitly granted permissions.
- Receive lifecycle events (`activate`, `run`, `abort`, `complete`) dispatched via `runtime:events`.

### IPC Integration

- `api/background.js` communicates over `ipc.request('background:*')`.
- The runtime service translates registration into platform-specific schedulers.
- Foreground contexts can subscribe to background events via `ipc.subscribe('background:events')`.

## Configuration

Extend `oro.toml` with a `[background]` namespace. Example:

```
[background]
enabled = true
default_entry = background/index.js

[background.service.sync_notifications]
entry = background/notifications.js
required = ios
trigger.type = interval
trigger.minimum_interval = 900000
keep_alive = false
permissions = notifications,network
```

Key points:

- `enabled` gates the entire subsystem.
- `default_entry` used when JS registers without an explicit `entry`.
- Each `[background.service.<id>]` block pre-declares a service (needed for iOS so `BGTaskScheduler` identifiers exist at build time).
- `required = ios` enforces that builds targeting that platform must provide the service (fails fast during build).
- Additional platform-specific overrides live under `[background.service.<id>.platform.<platform>]`.

`npm run gen` will surface typings for the JS API; configuration changes require updates to the config parser (new slice `config.background`).

## Runtime Architecture

### Core Service

- Add `core::BackgroundService` to `src/runtime/core/services.cc`.
- Responsibilities:
  - Persist registered services in `core::state`.
  - Coordinate scheduling requests across platforms.
  - Launch headless JavaScript isolates using the existing bridge (`Runtime::dispatcher` and `javascript::createJavaScript`).
  - Route `postMessage` traffic (background ↔ foreground).
  - Emit service lifecycle events to JS observers.

### Execution Model

- Each run creates a `BackgroundExecution` instance:
  - Owns a libuv loop pinned to the runtime loop (desktop) or platform thread (Android/iOS).
  - Bootstraps with `background/runtime.js` to patch the worker environment.
  - Applies permission gating before exposing modules (leveraging existing `Services` toggles).
  - Enforces run timeout (configurable default 30 minutes; platform-specific minimums apply).

- Background runs reuse the existing `queued-response` infrastructure (`runtime/context/context.cc`) for IPC serialization.

### State Management

- Extend `core::state` storage with `background-service/<id>.json` entries storing metadata (triggers, last run, failure counts).
- Synchronise with config overrides on boot; runtime rejects registrations not whitelisted by config when `required` is set.

## Platform Notes

### Android

- Implement `BackgroundService` extending `android.app.Service`.
- Use `WorkManager` for deferred/scheduled work; `ForegroundService` when `keepAlive = true`.
- Spin up a headless runtime via existing bootstrap (`Runtime::Options` with hidden window manager).
- Tie lifecycle to `onStartCommand`; completion stops service unless scheduling recurring work.
- Respect Doze/App Standby by marking network requests as `NetworkType.CONNECTED` when needed.

### iOS / iPadOS

- Register task identifiers from config during app launch (`BGTaskScheduler.shared.register`).
- Support two trigger types:
  - `processing` → `BGProcessingTaskRequest`.
  - `refresh` → `BGAppRefreshTaskRequest`.
- Background execution spins up a lightweight runtime inside the app process (no separate extension). The headless webview (`WKWebView`) loads `oro:background`.
- Provide helper in `bin/generate-plist` to inject `PermittedBackgroundTaskSchedulerIdentifiers`.
- Enforce configuration: if a service is marked `required = ios` and not scheduled, warn during build.

### Desktop (macOS, Windows, Linux)

- Add `HeadlessWebView` to `src/runtime/window` for hidden contexts.
- Background executions hosted in that headless view, sharing the same process and IPC loop.
- Scheduling:
  - `interval` triggers emulate timers via existing `timers` service.
  - `on-demand` runs triggered only when JS calls `schedule`.
  - Persisted alarms survive restarts via `core::state`.

### Shared Behaviour

- `postMessage` and `message` events mirrored through the dispatcher.
- Graceful cancellation when foreground requests `cancel`.
- Debug logging gated by `debug_background` config.
- Metrics recorded via `diagnostics` (success/failure counters).

## Implementation Phases

1. **Scaffolding**
   - Add config parser support and runtime service skeleton.
   - Implement JS module stubs returning `Unimplemented` errors on unsupported platforms.

2. **Desktop Headless Runner**
   - Introduce headless webview execution and IPC.
   - Provide integration tests under `test/src/background`.

3. **Android Service Integration**
   - Implement Android service/WorkManager binding.
   - Validate with instrumentation tests (`npm run test:android`).

4. **iOS Background Tasks**
   - Hook BGTaskScheduler, update build scripts for plist generation.
   - Add simulator coverage (`npm run test:ios-simulator` scenario).

5. **Developer Experience**
   - Ensure `npm run gen` produces typings and docs.

6. **Polish**
   - Add metrics, logging, timeout handling.
   - Harden permission gating and failure retries.

## Testing Strategy

- **Unit**: new runtime service tests covering registration validation and state persistence.
- **Integration**: Oro runner suites verifying message passing and timeout behaviours (legacy Socket suites still run until the deprecation window closes).
- **Platform**:
  - Android instrumentation verifying WorkManager scheduling and service restart.
  - iOS simulator tests using `BGTaskScheduler` debug APIs.
  - Desktop headless tests ensuring timers survive pause/resume.
- **Manual**: sample app demonstrating notifications sync in the background.

## Open Questions

- Should background services share the same JS bundle cache as foreground windows?
- How aggressively should we retry failed runs on iOS where background time is scarce?
- Do we expose platform-specific scheduling hints (e.g., `requiresExternalPower`) directly, or keep them in config only?

==============================================================================
DOCS: Secure Storage (SECURE_STORAGE)
URL: /runtime/docs/?p=SECURE_STORAGE
==============================================================================

# Secure Storage

Oro Runtime provides a cross-platform secure storage service that keeps key/value
pairs in the native credential stores. Data written through this API is backed
by the platform keystore (Keychain on Apple platforms, Credential Manager on
Windows, libsecret on Linux, and the Android Keystore).

```js
import { setItem, getItem, removeItem, clear, keys } from 'oro:secure-storage'

const scope = 'oro://com.example.my-app'

// Store sensitive data
await setItem('refresh-token', 'secret', { scope })

const token = await getItem('refresh-token', { scope })

// Enumerate known keys for the scope
const storedKeys = await keys({ scope })

// Remove data when it is no longer needed
await removeItem('refresh-token', { scope })

// Or clear the scope entirely
await clear({ scope })
```

### Scopes

Keys live inside a _scope_ which should be an origin-style string (for example
`oro://com.example.app`). When no scope is provided the runtime uses the
default origin of the current application window.

### Encodings

`setItem` accepts strings, `Uint8Array`, `ArrayBuffer`, or `Buffer` instances.
`getItem` returns strings by default and can return binary data when
`{ encoding: 'buffer' }` is supplied.

### Platform notes

- Linux backends depend on `libsecret-1`; if the library is unavailable the API
  will reject with an informative error.
- Android values are encrypted with an AES-GCM key stored in the platform
  keystore and then persisted using app-private shared preferences.

==============================================================================
DOCS: Sandbox Helper Implementation Plan (SANDBOX_HELPER)
URL: /runtime/docs/?p=SANDBOX_HELPER
==============================================================================

# Sandbox Helper Implementation Plan

## Goals & Scope

- Allow Oro Runtime apps to access USB and other privileged resources without running as root.
- Provide a reusable, least-privilege service that works across all desktop targets (Linux, macOS, Windows).
- Mirror Chromium’s security posture: central privileged broker + sandboxed child processes with per-user permissions.
- Support multiple apps concurrently, with policy controls that can restrict per-app capabilities when needed.
- Ship with tooling that keeps developer ergonomics: once installed, `oroc build -r` (and similar flows) just work.

## High-Level Architecture

1. **Privileged Helper Binary (`oro-helper`)**
   - Installed system-wide, owned by root (or platform equivalent).
   - Responsible for opening privileged resources, managing policy, and spawning sandboxed child processes.
2. **Zygote Process**
   - A long-lived child of the helper that preloads runtime code and listens for spawn requests from user-facing tools.
   - Forks lightweight sandboxed processes for each launched app.
3. **IPC Layer**
   - UNIX domain sockets (Linux/macOS) and named pipes (Windows) for communication between CLI/runtime and helper.
   - Uses authenticated, versioned messages (CBOR/JSON/Protocol Buffers) plus descriptor passing where available.
4. **Policy & Capability Engine**
   - Defines which device classes, VID/PIDs, network ports, or filesystem paths are permitted.
   - Future-ready for per-app manifests or signed capability tokens.
5. **Logging & Observability**
   - Helper writes to system log (journald, Unified Logging, Windows Event Log).
   - Optional structured audit trail for privileged operations.

## Client Entry Points & Authentication

- Shared bootstrap shim is linked into the runtime so `oroc build -r`, `oroc run`, and directly-invoked packaged apps all follow the same handshake before touching privileged APIs.
- Helper publishes one IPC endpoint per user/session. Filesystem ACLs gate access, and the helper verifies peer identity (`SO_PEERCRED` on Linux, `audit_token_t` on macOS, `ImpersonateNamedPipeClient` or `GetNamedPipeClientProcessId` on Windows) before servicing requests.
- Clients send an app identifier (bundle ID or executable hash) during handshake so per-app policy can be enforced independent of launch path.
- Developer mode (opt-in via local policy) relaxes signing checks for unsigned builds while still enforcing UID/SID verification.

## Shared Implementation Phases

1. **Research & Prototype (Milestone A)**
   - Verify descriptor passing for libusb on each platform.
   - Spike a minimal helper that opens a USB node and echoes data from an unprivileged client.
2. **Helper Core (Milestone B)**
   - Implement helper binary with argument parsing, privilege drop, policy hooks, logging skeleton.
   - Define IPC protocol (`OpenDevice`, `SpawnProcess`, `ReleaseHandle`, `Quit`).
3. **Zygote & Sandbox (Milestone C)**
   - Embed runtime bootstrap: helper forks zygote, zygote preloads runtime libs, forks per-app processes.
   - Apply sandboxing (namespaces/seccomp, posix_spawnattr, Windows Job Objects).
4. **Platform Services Integration (Milestone D)**
   - Linux: setuid helper packaging, udev rule install, `oro-helper --ensure` bootstrap integration.
   - macOS: launchd plist, SMJobBless installer, entitlement management.
   - Windows: service registration, installer scripts (MSI/Inno), service control shim.
5. **CLI & Runtime Adaptation (Milestone E)**
   - Extend `oroc` CLI to detect helper status, auto-start services, and request capabilities.
   - Update runtime IPC layer to request USB descriptors via helper before initializing libusb.
6. **Security Review & Hardening (Milestone F)**
   - Threat modeling, code audit, fuzzing IPC parser, privilege-dropping verification.
   - Document escalation paths and incident response.
7. **Developer Experience & Testing (Milestone G)**
   - Automated integration tests for helper lifecycle.
   - End-to-end tests for USB enumeration via helper on each platform.
   - Docs, troubleshooting guides, and logging instructions.

Subsequent phases can iteratively add other privileged capabilities (low-number ports, system config writes, etc.) once USB support is stable.

## Descriptor Passing Fallback Strategy

- Prefer native descriptor/handle passing (`libusb_wrap_sys_device`, macOS IOKit connections, Windows `DuplicateHandle`).
- If descriptor passing fails, transparently downgrade to a brokered transfer API where the helper executes `ControlTransfer`, `BulkTransfer`, `InterruptTransfer`, and hotplug notifications on behalf of the client, using correlation IDs to pair responses.
- Handshake records which mode is active; clients emit telemetry so we can track fallback usage.
- Integration tests should exercise both code paths to prevent regressions.

## Linux Plan

### Permissions Model

- Ship a udev rule (e.g., `/lib/udev/rules.d/80-oro-usb.rules`) tagging supported device classes:
  ```
  SUBSYSTEM=="usb", MODE="0660", TAG+="uaccess", TAG+="seat", GROUP="orousb"
  ```
- `TAG+="uaccess"` allows systemd-logind to grant per-session ACLs automatically.
- Optional group (`orousb`) provides compatibility for non-systemd environments; helper’s installer creates the group and adds users on request.

### Helper Deployment

- Install helper binary at `/usr/lib/oro/oro-helper` with mode `4755` (setuid root).
- Installation script:
  - Copies helper, bootstrap shim, and supporting configs.
  - Creates runtime directories (`/run/oro-helper`), noting they live on tmpfs and may be recreated at boot.
  - Installs udev rule, reloads via `udevadm control --reload`.
  - Optionally adds user to `orousb` group for non-logind hosts.
- No systemd unit is required; the helper is invoked on demand by CLI or app bootstrap. A lightweight `oro-helper --ensure` command can daemonize a broker if we want it resident.

### Helper Runtime

On invocation, helper:

1. Verifies it is running as setuid root and performs self-integrity checks (hash/signature).
2. Ensures `/run/oro-helper` exists (recreating it on tmpfs as needed) and that a per-user broker process is running; if not, forks a small root-owned parent (`oro-helperd`) that stays resident and opens privileged resources (udev monitor, libusb context).
3. Parent drops all ambient capabilities except the minimal set required for device I/O (target: `CAP_DAC_READ_SEARCH` + `CAP_DAC_OVERRIDE`, pending validation during Milestone A/B) and sets `PR_SET_NO_NEW_PRIVS`.
4. Parent spawns/refreshes a per-user zygote process (running as the calling user) and creates `/run/oro-helper/<uid>.sock` (mode `0600`, owned by user).
5. Subsequent invocations short-circuit to a control message (`oro-helper --ping`) that confirms broker health.

Descriptor passing:

- Root broker opens `/dev/bus/usb/<bus>/<dev>` with `O_RDWR`.
- Uses `sendmsg` + `SCM_RIGHTS` to hand the fd to the requesting child process through the per-user socket.
- Child wraps the fd in libusb via `libusb_wrap_sys_device`.

### Sandbox & Process Lifecycle

- Use user and mount namespaces, PID namespace when possible.
- Apply seccomp filter allowing required syscalls (dup, read, write, ioctl, etc.).
- Child processes run under original user UID/GID, not helper UID.
- Broker tracks all outstanding descriptors; on disconnect, closes fd and notifies clients.

### CLI Integration

- `oroc build -r`:
  1. Executes `oro-helper --ensure` (via bootstrap shim) to spawn/refresh the broker and zygote for the current user.
  2. Connects to `/run/oro-helper/<uid>.sock`; if handshake fails, prints actionable remediation.
  3. Uses IPC `SpawnProcess` to launch or attach to the app’s runtime process after the bootstrap shim connects.
- `oroc helper status`:
  - Invokes `oro-helper --status` to query broker version, uptime, loaded policy.
- Standalone apps ship with the same shim and automatically call `oro-helper --ensure` on startup.

### Testing & Diagnostics

- Unit tests for IPC message parsing and policy evaluation (run as part of `npm run test:runtime-core`).
- Integration tests may use `systemd-run --user` (when available) or `setsid`/custom launchers to simulate clean sessions.
- Troubleshooting doc: helper logs to syslog/journald with the `oro-helperd` ident, so `journalctl -t oro-helperd` (or `/var/log/oro-helperd.log` if rsyslog writes there); additionally `getfacl /dev/bus/usb/*`, `oroc helper doctor`.

## macOS Plan

### Helper Deployment

- Use `SMJobBless` to install a privileged helper at `/Library/PrivilegedHelperTools/com.oro.helper`.
- Launchd plist (`/Library/LaunchDaemons/com.oro.helper.plist`) starts the helper on demand.
- CLI `oroc helper install` triggers `SMJobBless`, requiring an admin consent prompt (standard macOS UX).

### Helper Runtime

- Helper listens on launchd-managed UNIX socket (`/var/run/oro-helper/<uid>.sock`).
- After accepting a connection:
  - Reads the client `audit_token_t` to confirm the caller UID matches the launch session.
  - Validates code signature (`SecCodeCopyGuestWithAttributes`) against the Oro Runtime maintainer certificates; developer mode (toggled via local policy) allows unsigned builds while still checking the caller UID.
  - Uses `AuthorizationExternalForm` to ensure the caller is the logged-in user.
- Zygote uses `posix_spawn` with `posix_spawnattr_setflags` to enter sandbox profiles (Seatbelt). Profiles live under `/Library/Application Support/Oro/runtime-sandbox.sb`.

### Testing & Diagnostics

- Integration tests using `launchctl kickstart -k system/com.oro.helper`.
- Debug command: `log show --predicate 'subsystem == \"com.oro.helper\"' --last 1h`.

## Windows Plan

### Permissions Model

- Install a Windows Service (`OroHelperService`) running as `LocalSystem`.
- Service keeps device DACLs locked down and relies on brokered handles so only approved processes can touch devices.
- Maintain per-session named pipe endpoints (`\\\\.\\pipe\\oro-helper-<SessionId>`).

### Helper Deployment

- Provide MSI/Inno installer performing:
  - Copy of helper binaries to `%ProgramFiles%\\Oro\\helper`.
  - Service registration (`sc create OroHelperService binPath= ... start= auto`).
  - Installation of WinUSB drivers if required (`pnputil /add-driver`).
  - Firewall rule adjustments if helper exposes network diagnostics.
- CLI `oroc helper install` uses `Start-Process -Verb RunAs` to trigger installer or leverages `elevate.exe`.

### Logging & Diagnostics

- Service logs to Windows Event Log under `Application` source `OroHelper`.
- Provide `oroc helper status` that queries service state with `QueryServiceStatusEx`.
- Troubleshooting: `Get-WinEvent -LogName Application | where ProviderName -eq 'OroHelper'`.

## Policy & Configuration

- Policy file (`/etc/oro/policy.json`, `%ProgramData%\\Oro\\policy.json`, `/Library/Application Support/Oro/policy.json`).
- Schema:
  ```json
  {
    "version": 1,
    "capabilities": {
      "usb": {
        "allow": [{ "vid": "0x1234", "pid": "*" }, { "class": "cdc" }]
      },
      "ports": { "allow": [22, 443] },
      "fs": { "allow": ["/var/lib/oro/runtime"] }
    }
  }
  ```
- Helper loads policy at startup, reloads on SIGHUP / platform equivalent.
- CLI commands to manage policy (`oroc helper policy add-usb --vid 0x1234 --pid 0x0001`).

## Developer Workflow

- Prerequisite: run `sudo oroc helper install` on Linux, `oroc helper install` with admin prompt (macOS/Windows).
- During development:
  - `oroc build -r` connects to helper, spawns sandboxed process, and requests USB descriptors.
  - Logs accessible via `oroc helper logs --follow` (wraps platform log readers).
  - For hot reload, zygote keeps runtime libs warm; rebuilds only restart child process.
- Packaged apps launched directly (outside the CLI) rely on the same bootstrap shim: on startup the binary finds the user IPC endpoint, performs the handshake, and either requests a fresh sandboxed process or binds to an existing one as dictated by policy.

## Open Questions & Follow-Ups

- Confirm libusb descriptor wrapping works on macOS/Windows helper → child handoff, or plan for proxying calls.
- Determine per-app trust model (signed manifests vs. user prompts).
- Evaluate need for GUI prompts when new devices are accessed.
- Assess integration with mobile runtimes (Android/iOS) for parity.

This plan should be revised after Milestone A prototypes validate descriptor passing and sandbox mechanics on each platform.

==============================================================================
DOCS: TLS Quickstart (Experimental) (TLS_QUICKSTART)
URL: /runtime/docs/?p=TLS_QUICKSTART
==============================================================================

# TLS Quickstart (Experimental)


- Linux desktop defaults to the vendored **mbedTLS** backend (built by `bin/install.sh`).
- The **OpenSSL** backend is an optional build-time alternative (desktop only).
- Other targets currently build with no TLS provider unless you opt into OpenSSL (or provide a dynamic provider module).
- **GnuTLS**, **SecureTransport**, and platform **Android** TLS providers are not implemented in this repository yet.

## Enabling TLS

1. Build-time provider selection:
   - Linux desktop defaults to **mbedTLS**.
   - To build with **OpenSSL** instead, set `ORO_TLS_BUILD_PROVIDER=openssl` (or `ORO_TLS_ENABLE_OPENSSL=1`) when building the runtime.
   - `ORO_TLS_BUILD_PROVIDER=gnutls` is currently rejected because there is no backend implementation under `src/runtime/tls`.

2. Runtime selection:
   - `ORO_TLS_PROVIDER` can select a provider at runtime when multiple providers are available (e.g., via dynamic provider modules).
   - With the current single-provider build model, `ORO_TLS_PROVIDER` must match the compiled provider (or `tls.connect` will return `NOT_IMPLEMENTED`).

```
export ORO_TLS_PROVIDER=mbedtls        # or: openssl
```

You can confirm the active provider at runtime from JavaScript:

```js
import * as tls from 'oro:tls'

const { provider } = await tls.getTlsProvider()
console.log('TLS provider:', provider)
```

3. Manual OpenSSL flags (when `pkg-config` is unavailable):

```
export ORO_TLS_CFLAGS="-I/path/to/include"
export ORO_TLS_LDFLAGS="-L/path/to/lib -lssl -lcrypto"
```

## Client API (oro:tls)

```
import { connect } from 'oro:tls'

const socket = connect({
  host: 'example.com',
  port: 443,
  servername: 'example.com',          // SNI/hostname (defaults to host)
  rejectUnauthorized: true,           // default true
  alpnProtocols: ['h2', 'http/1.1'],  // optional
  minVersion: 'TLSv1.2',              // optional
  maxVersion: 'TLSv1.3'               // optional
})

socket.on('secureConnect', () => {
  socket.write('GET / HTTP/1.1\r\nHost: example.com\r\n\r\n')
})

socket.on('data', (buf) => {
  console.log(Buffer.from(buf).toString('utf8'))
})

socket.on('error', (err) => console.error('TLS error:', err))
```

## Trust and Verification

- `rejectUnauthorized` defaults to `true`. When enabled:
  - If `ca` PEM is provided, it is used as the trust store.
  - Otherwise, the runtime attempts to load the system CA bundle on Linux; if unavailable, verification fails.
  - Hostname (SNI) is set to `servername || host` and must match the certificate.
- On verification failure, the error will include a `code` with a canonical value such as:
  - `HOSTNAME_MISMATCH`
  - `CERT_UNTRUSTED`
  - `CERT_UNTRUSTED_ROOT`
  - `CERT_EXPIRED`
  - `CERT_NOT_TIME_VALID`
  - `CERT_REVOKED`
  - `CRL_EXPIRED`
  - `CRL_UNTRUSTED`
  - `CERT_NOT_PERMITTED`
  - `CERT_BAD_SIGNATURE_ALG`
  - `CERT_BAD_SIGNATURE`
  - `CERT_BAD_PUBLIC_KEY`
  - `CERT_BAD_KEY`
  - or `CERTIFICATE_VERIFY_FAILED`

## TLS Pinning (Runtime TLS)

The runtime TLS service supports strict leaf-certificate pinning via the `tls_pins` configuration key and the `oro:tls` JavaScript API.

Pins are evaluated **after** the TLS handshake completes:

- If pins are configured for a host, the connection succeeds only when the peer leaf certificate’s SHA‑256 digest matches one of the configured pins.
- Pinning is enforced even when `rejectUnauthorized: false`.
- When `rejectUnauthorized: true` (default), both certificate verification **and** pin matching must succeed.

### Configuration (`oro.toml`)

Pins are declared as a newline‑separated list of entries:

```toml
[tls]
pins = """
example.com sha256/BASE64_DIGEST
api.example.test sha256/OTHER_BASE64_DIGEST
"""
```

Alternatively, in TOML you can use a string array:

```toml
[tls]
pins = [
  "example.com sha256/BASE64_DIGEST",
  "api.example.test sha256/OTHER_BASE64_DIGEST",
]
```

Each non-empty, non-comment line has the form:

- `<host> <pin> [<pin>...]`
- `<host>` may be a hostname, `hostname:port`, `[ipv6]:port`, or a URL; any scheme/path/query/fragment is ignored and any `:port` suffix is normalised away (pins apply to the host, not a specific port).
- `<pin>` is either `sha256/<base64>` or just `<base64>` (always interpreted as SHA‑256).
- `<base64>` may be standard Base64 or Base64URL (using `-` and `_`), with or without padding.
- Hosts are matched case-insensitively.
- Lines may include comments starting with `#` or `;` (trailing content is ignored).

### Computing a pin

From a remote server (uses OpenSSL):

```sh
HOST=example.com
PORT=443

openssl s_client -connect "${HOST}:${PORT}" -servername "${HOST}" </dev/null 2>/dev/null \
  | openssl x509 -outform der \
  | openssl dgst -sha256 -binary \
  | openssl base64 -A
```

Or from JavaScript (DER or PEM):

```js
import * as tls from 'oro:tls'

// await tls.createTlsPinFromCertificateDer(derBytes)
// await tls.createTlsPinFromCertificatePem(pemString)
```

### Runtime API

```js
import * as tls from 'oro:tls'

await tls.setTlsPins(
  [
    'example.com sha256/BASE64_DIGEST',
    'api.example.test sha256/OTHER_BASE64_DIGEST',
  ],
  { mode: 'append' } // or 'replace'
)

const { value } = await tls.getTlsPins()
console.log(value)
```

`setTlsPins()` validates entries and throws when the host or pin tokens are invalid.
If you use IPC directly (`tls.setPins`), invalid entries are rejected with `err.code = TLS_PINS_INVALID`.

#### Per-host helpers

If you want to manage pins for a single host without rewriting the entire config string:

```js
import * as tls from 'oro:tls'

await tls.setTlsPinsForHost('example.com', ['sha256/BASE64_DIGEST'])
await tls.addTlsPinsForHost('example.com', ['sha256/NEXT_BASE64_DIGEST'])
await tls.removeTlsPinsForHost('example.com', ['sha256/OLD_BASE64_DIGEST'])

// Remove the host entry entirely:
await tls.removeTlsPinsForHost('example.com')

const { configured, pins } = await tls.getTlsPinsForHost('example.com')
console.log({ configured, pins })
```

### Per-connection pins

`connect()` also accepts per-connection pin overrides:

```js
import { connect } from 'oro:tls'

connect({
  host: 'example.com',
  port: 443,
  // pins can be a list of pin tokens (auto-associated with servername||host),
  // or full '<host> <pin>' lines.
  pins: ['sha256/BASE64_DIGEST'],
  // 'append' (default) merges with global tls_pins; 'replace' uses only pins above.
  // If `pins` is omitted/blank, global tls_pins still apply.
  pinsMode: 'replace',
  // rejectUnauthorized: false, // optional: rely on pins without CA validation
})
```

Invalid `pins` input throws a `TypeError` before any network I/O occurs.
With `pinsMode: 'replace'`, `pins` must include at least one pin that applies to `servername || host`.

On pin failure, the error includes:

- `code`: `PIN_MISCONFIGURED` | `PIN_UNAVAILABLE` | `PIN_MISMATCH`
- `provider`: `mbedtls` | `openssl` | `schannel` | `auto`
- `peerPin`: `sha256/<base64>` (when available)
- `expectedPins`: string[]

On success, the `secureConnect` event payload also includes `peerPin` (when available) and `provider`, which is useful for logging and pin rotation.

## Mutual TLS

Provide `cert` and `key` in PEM format to enable client authentication.
If the private key is encrypted, pass `keyPassphrase` (or `passphrase`) alongside `key`;
this is supported for both `connect()` and `createServer()`.

## ALPN, Versions, and Ciphers

- `alpnProtocols`: e.g., `['h2', 'http/1.1']` (order matters)
- `minVersion`, `maxVersion`: `'TLSv1.2' | 'TLSv1.3'` (if supported by the provider)
- `ciphers`: numeric cipher IDs as hex strings (e.g., `['0x1301']`)

## Notes

- Handshake and record I/O are non-blocking and integrated with libuv; both client and server APIs are available via `oro:tls`.
- Builds that do not compile a TLS provider will surface `NOT_IMPLEMENTED` errors from the IPC routes.
- For WebView TLS certificate pinning (WebKit/WebView/WebView2), see `docs/WEBVIEW_TLS_PINS.md`.

==============================================================================
DOCS: TLS Testing Guide (TLS_TESTING)
URL: /runtime/docs/?p=TLS_TESTING
==============================================================================

# TLS Testing Guide

This guide shows how to run the experimental TLS tests (examples use Linux tooling) with either the OpenSSL or mbedTLS provider, and how to decrypt captures in Wireshark using the key‑log file. The same environment variables apply on macOS/Windows; supply platform-specific compiler/linker flags as needed.

Prerequisites

- Build toolchain: gcc/g++ (C++20), make, pkg-config
- Libraries (Ubuntu/Debian names):
  - Core GUI/runtime: libwebkit2gtk-4.1-dev, libgtk-3-dev, libdbus-1-dev, libsoup-3.0-dev
  - TLS provider (choose one):
    - OpenSSL: libssl-dev
    - mbedTLS: libmbedtls-dev
  - Optional: xvfb (for CI headless runs), wireshark (for capture/decrypt)

Install example (Ubuntu):

```
sudo apt-get update
sudo apt-get install -y \
  build-essential pkg-config \
  libwebkit2gtk-4.1-dev libgtk-3-dev libdbus-1-dev libsoup-3.0-dev \
  libssl-dev # or: libmbedtls-dev
```

Environment

- Enable TLS and pick a provider:

```
export ORO_ENABLE_TLS=1
export ORO_TLS_PROVIDER=openssl   # or: mbedtls
```

- On macOS/Windows/mobile targets, provide build flags if `pkg-config` is unavailable:

```
export ORO_TLS_CFLAGS="-I/path/to/include"
export ORO_TLS_LDFLAGS="-L/path/to/lib -lssl -lcrypto"   # adjust for your TLS provider
```

- Optional: write TLS key log lines for Wireshark decryption:

```
export ORO_TLS_KEYLOG=/tmp/sslkeys.txt
## or, per invocation:
##   oroc run --tls-keylog=/tmp/sslkeys.txt --test=…
##   oroc build --tls-keylog=/tmp/sslkeys.txt …
```

- When using encrypted private keys in tests, pass the matching `keyPassphrase` (or `passphrase`) field alongside the PEM.

Run the tests

1. Echo + ALPN + mTLS

```
oroc run --test=test/src/tls/echo.js
```

2. Negative scenarios

```
oroc run --test=test/src/tls/negative.js
```

Expected results

- echo.js
  - Self-signed echo succeeds when `rejectUnauthorized:false` and negotiates `alpnProtocol: 'http/1.1'`.
  - CA-trusted echo succeeds with `rejectUnauthorized:true` and negotiates `alpnProtocol: 'http/1.1'`.
  - mTLS echo succeeds when server `requestCert:true` and client supplies `cert`/`key`.
- negative.js
  - Missing CA path fails; error may include `code` such as `CERT_UNTRUSTED` or `CERTIFICATE_VERIFY_FAILED`.
  - Hostname mismatch fails (`HOSTNAME_MISMATCH` or `CERTIFICATE_VERIFY_FAILED`).
  - Server requires client cert, client omits it → handshake fails.

Wireshark decryption (OpenSSL provider)

1. Ensure `ORO_TLS_KEYLOG` is set to a writable path (see Environment above).
2. In Wireshark: Preferences → Protocols → TLS → set “(Pre)-Master-Secret log filename” to the keylog path.
3. Capture filters (ports used by tests):

```
tcp port 30443 or tcp port 30444 or tcp port 30445 or tcp port 30446 or tcp port 30447 or tcp port 30448
```

4. Display filter examples: `tls` or `tcp.stream eq 0`.

Troubleshooting

- If you see linker errors for WebKitGTK or GTK, ensure `libwebkit2gtk-4.1-dev` and `libgtk-3-dev` are installed.
- In CI/headless environments, you may need `xvfb-run` to provide a display server.
- To skip building the desktop extension in constrained Linux CI, set `ORO_TEST_SKIP_DESKTOP_EXTENSION=1`.

==============================================================================
DOCS: WebView TLS Pins (WEBVIEW_TLS_PINS)
URL: /runtime/docs/?p=WEBVIEW_TLS_PINS
==============================================================================

# WebView TLS Pins

The `webview_tls_pins` configuration key lets you pin server certificates for HTTPS requests made by the embedded WebViews. When no pins are configured for a host, the platform’s default certificate validation behaviour is preserved.

## Configuration

Pins are declared in `oro.toml` as a newline‑separated list of entries:

```toml
[webview]
tls_pins = """
example.com sha256/BASE64_DIGEST
api.example.test sha256/OTHER_BASE64_DIGEST
"""
```

Each non‑empty, non‑comment line has the form:

- `<host> <pin> [<pin>...]`
- `<host>` may be a hostname, `hostname:port`, `[ipv6]:port`, or a URL; any scheme/path/query/fragment is ignored and any `:port` suffix is normalised away (pins apply to the host, not a specific port).
- `<pin>` is either `sha256/<base64>` or just `<base64>` (the digest is always interpreted as SHA‑256).
- `<base64>` may be standard Base64 or Base64URL (using `-` and `_`), with or without padding.
- Hosts are matched case‑insensitively.
- Lines may include comments starting with `#` or `;` (trailing content is ignored).

The digest is the SHA‑256 of the server certificate (not the entire chain), encoded as standard Base64.

## Computing a Pin

The pin value is the Base64-encoded SHA-256 digest of the leaf certificate’s DER bytes.

From a remote server (uses OpenSSL):

```sh
HOST=example.com
PORT=443

openssl s_client -connect "${HOST}:${PORT}" -servername "${HOST}" </dev/null 2>/dev/null \
  | openssl x509 -outform der \
  | openssl dgst -sha256 -binary \
  | openssl base64 -A
```

From a local PEM file:

```sh
openssl x509 -in server.pem -outform der \
  | openssl dgst -sha256 -binary \
  | openssl base64 -A
```

Then configure:

```
example.com sha256/<PASTE_OUTPUT_HERE>
```

## Runtime Updates

In addition to static configuration, you can update pins at runtime via IPC:

```js
import ipc from 'oro:ipc'

await ipc.request('application.setWebviewTlsPins', {
  value: `
example.com sha256/BASE64_DIGEST
api.example.test sha256/OTHER_BASE64_DIGEST
`,
  // mode: 'append' (default) to extend existing pins,
  // or 'replace' to overwrite them entirely.
  mode: 'append',
})
```

Invalid entries are rejected with `err.code = WEBVIEW_TLS_PINS_INVALID`.

Or from JavaScript via the TLS module:

```js
import * as tls from 'oro:tls'

await tls.setWebViewTlsPins(
  [
    'example.com sha256/BASE64_DIGEST',
    'api.example.test sha256/OTHER_BASE64_DIGEST',
  ],
  { mode: 'append' }
)

// Clear pins:
await tls.clearWebViewTlsPins()
```

Per-host helpers are also available:

```js
import * as tls from 'oro:tls'

await tls.setWebViewTlsPinsForHost('example.com', ['sha256/BASE64_DIGEST'])
await tls.addWebViewTlsPinsForHost('example.com', ['sha256/NEXT_BASE64_DIGEST'])
await tls.removeWebViewTlsPinsForHost('example.com')

const { configured, pins } = await tls.getWebViewTlsPinsForHost('example.com')
console.log({ configured, pins })
```

This call:

- Updates the process‑wide runtime config (`webview_tls_pins`), so Android’s WebView sees the new pins via `getUserConfigValue`.
- Updates the default window config used for future windows.
- Updates `bridge.userConfig["webview_tls_pins"]` for all active windows so Apple/Linux WebViews immediately pick up the new pins.

## Behaviour by Platform

- **macOS / iOS (WKWebView)**  
  - Pins are enforced during the TLS handshake via `WKNavigationDelegate`’s authentication challenge.  
  - When pins exist for a host, only certificates whose SHA‑256 digest matches one of the configured pins are accepted; other certificates are rejected even if they are trusted by the system.

- **Linux (WebKitGTK)**  
  - Pins are evaluated when WebKit reports TLS errors via `load-failed-with-tls-errors`.  
  - If the failing certificate’s digest matches a configured pin for the host, the runtime whitelists that certificate for the host and retries the navigation.  
  - If no pin matches, the original TLS error is preserved.  
  - Note: `webkit_web_context_allow_tls_certificate_for_host` is sticky for the lifetime of the WebKitWebContext; clearing pins does not revoke previously allowed certificates without restarting the WebView.
  - Note: this currently only relaxes errors for pinned certificates; it does not reject otherwise‑valid certificates that are not pinned.

- **Android (android.webkit.WebView)**  
  - Pins are evaluated in `onReceivedSslError`, which is only invoked when WebView encounters TLS errors.  
  - If pins exist for the host and the certificate digest matches, the error is overridden and the navigation proceeds; otherwise the navigation is cancelled.  
  - As with Linux, this cannot currently reject non‑pinned but otherwise valid certificates.

- **Windows (WebView2)**  
  - Pins are evaluated when WebView2 reports server certificate failures via `ServerCertificateErrorDetected`.
  - If the failing certificate’s digest matches a configured pin for the host, the runtime overrides the error and allows navigation; otherwise the navigation is cancelled.
  - Note: WebView2’s “always allow” decision may persist for the lifetime of the profile/user data folder; clearing pins does not necessarily revoke previously allowed certificates without clearing that profile state.
  - As with Linux/Android, this is currently an error‑path hook and cannot reject otherwise‑valid certificates that are not pinned.

When enabling pins, start with a single host in a controlled environment, verify behaviour on your target platforms, and only then roll out more broadly.

==============================================================================
DOCS: Web Bluetooth Runtime Status (WEB_BLUETOOTH_STATUS)
URL: /runtime/docs/?p=WEB_BLUETOOTH_STATUS
==============================================================================

# Web Bluetooth Runtime Status

This document tracks the current implementation status for Web Bluetooth in the native runtime. Use it as a hand‑off to resume work in a new session.

## Cross-cutting

- `WebBluetooth::parseRequestDeviceOptions` centralises spec validation (acceptAllDevices vs filters, optionalServices, manufacturerData masks) and reuses a single matcher for all backends.
- Router/bridge keep notification observers per-window with ref counts so repeated `startNotifications()` calls do not duplicate events. Observers are dropped automatically when a bridge is destroyed.
- The JS scaffold now de-dupes chooser rows and live-updates RSSI/name while a scan is active.

## Platform snapshot

- **Apple (CoreBluetooth)**
  - Filters run through the shared matcher before presenting devices; advertisement manufacturer data is normalised for matching.
  - Chooser dedupe is driven by peripheral UUIDs. Timeout uses `options.timeoutMs`, `web_bluetooth_timeout_ms`, or defaults to 12s.

- **Android (Kotlin + JNI + GATT)**
  - Scanner forwards advertised service UUIDs; native backend filters locally via the shared matcher and caches name/RSSI/service info for chooser resolution.
  - RequestDevice builds ScanFilters from the union of requested service UUIDs. Notifications, reads, and writes were already implemented.
  - On API 31+, checks `android.permission.BLUETOOTH_SCAN`/`BLUETOOTH_CONNECT` before scanning and triggers a runtime prompt when missing; returns `NotAllowedError` until granted.

- **Windows (classic + dynamic GATT)**
  - Classic radio enumeration still backs `requestDevice`; name/namePrefix filters now use the shared matcher data.
  - BLE GATT plumbing exists (BluetoothAPIs.dll) but discovery is limited to remembered devices; no manufacturer/service filtering yet.

- **Linux (BlueZ / D‑Bus)**
  - Discovery filter + matcher migrated to the shared helpers (services, names, prefixes, manufacturerData masks).
  - `requestDevice` emits chooser events only when the matcher passes; MAC-level dedupe remains in place.
  - GATT connect/discovery/read/write/notify already implemented; timeout/cancel flow unchanged (default 15s).

- **Tests**
  - `test/src/bluetooth/web-bluetooth.test.js` exercises JS option validation (including `servicesMatch`) and chooser cancellation logic. Platform E2E/device tests remain manual for now.

## Configuration quick reference

- `options.timeoutMs` or `[userConfig] web_bluetooth_timeout_ms` (number string) controls discovery timeout (default 15000ms on Linux, 12s on Apple fallback).
- `options.servicesMatch`: `'all'` (default) requires every service listed in a filter; `'any'` allows a match when any service is present. A userConfig override (`web_bluetooth_services_match=all|any`) sets the default mode for requests that omit the option.
- Linux-specific tuning: `web_bluetooth_emit_interval_ms` (default 1000) throttles repeated `devicefound` emissions, `web_bluetooth_emit_rssi_delta` (default 4) sets the RSSI delta required to emit early.

## Next steps / open items

1. Windows: switch requestDevice to WinRT BLE enumeration, honour service/manufacturer filters, and wire notifications to the shared matcher.
2. Android: add MTU negotiation, improve read/write data paths (zero-copy), audit JNI/loop hand-offs, and document the BLE permission flow.
3. Tests: add integration coverage for filter permutations and repeated notification subscriptions; document chooser override hooks for apps; automate chooser interaction for CI.
4. Configuration: surface per-platform timeout defaults and user-config overrides; ensure Linux notification backpressure can be tuned.

## Notes

- Manufacturer data matching uses optional masks when provided (shared helper); Linux obtains bytes from Device1 `ManufacturerData`, Android currently only matches by company ID (no payload yet).
- All chooser events continue to emit on the runtime dispatcher to keep window interaction thread-safe.

==============================================================================
DOCS: Web OTP Support (WEB_OTP)
URL: /runtime/docs/?p=WEB_OTP
==============================================================================

# Web OTP Support

## Overview

- The Oro Runtime implements the [WICG Web OTP](https://wicg.github.io/web-otp/) API via `navigator.credentials.get({ otp: { ... } })`.
- Android requests are brokered by a native OTP service backed by Google Play Services’ SMS Retriever API.
- iOS falls back to the system WebView implementation (WKWebView). Desktop platforms currently return `NotSupportedError`.

## SMS Format Requirements

- Incoming SMS messages must follow the Web OTP format:
  - Include the application origin, e.g. `@example.com` or `@example.com:443`.
  - Provide the OTP immediately after a `#` delimiter, e.g. `123456` in `Your code is: 123456 @example.com #123456`.
- The runtime validates the origin in the SMS before resolving the request.

## Configuration

- Toggle runtime access via `[permissions] allow_otp = true|false` in `oro.toml`.
  - When set to `false`, Android requests are rejected with `NotAllowedError` and the SMS receiver is never registered.

## Platform Notes

- **Android**
  - Requires Play Services on the device or emulator.
  - The runtime automatically registers and unregisters the SMS Retriever broadcast receiver per request.
  - No SMS permissions are requested; the Retriever API does not require `READ_SMS`.
- **iOS**
  - The runtime now presents an in-app one-time-code field (with `UITextContentTypeOneTimeCode`) so OTP suggestions surface inside the app.
  - No additional entitlements are required; the system QuickType bar provides the SMS code consent prompt.
- **Desktop**
  - Not supported today; requests are rejected with `NotSupportedError`.

## iOS Integration Roadmap

Even with the text-field-based implementation in place, we can explore deeper integration layers:

1. Evaluate `ASAuthorizationController` once Apple exposes an official Web OTP API to apps, allowing fully headless retrieval.
2. Consider an entitlements helper (`entitlements.ios.associated_domains`) if associated domains become a requirement for SMS code autofill.
3. Provide UI affordances for users to retry or dismiss OTP prompts when no SMS suggestion is offered.
4. Add XCTests that automate the QuickType OTP suggestion flow to guard against regressions across iOS releases.

## JavaScript Polyfill Behavior

- The runtime injects `navigator.credentials.get` support when the platform lacks a native implementation.
- The polyfill accepts `signal` and `timeout` options, propagating aborts to the native layer.
- Responses resolve with an `OTPCredential` object exposing `type`, `code`, `transports`, and `origin`.

### Quick start

```js
const controller = new AbortController()

try {
  const credential = await navigator.credentials.get({
    otp: { transport: ['sms'], hint: 'example-app' },
    signal: controller.signal,
    timeout: 60_000,
  })

  console.log('OTP code', credential.code)
} catch (err) {
  console.error('Unable to retrieve OTP', err)
}
```

## Error Handling

- Android rejects requests with DOMException names aligned to the Web OTP spec:
  - `AbortError` – configuration disabled, or request cancelled.
  - `InvalidStateError` – empty codes or malformed SMS payloads.
  - `NotAllowedError` – permission denied by config.
  - `NotSupportedError` – platform/features missing (e.g., Play Services absent).
  - `TimeoutError` – no matching SMS received before the request timeout.

==============================================================================
DOCS: WebHID Runtime Status (WEB_HID_STATUS)
URL: /runtime/docs/?p=WEB_HID_STATUS
==============================================================================

# WebHID Runtime Status

_Last updated: September 24, 2025_

This document tracks the native runtime implementation status for the WebHID API. Use it as a checklist when extending platform coverage and as a hand-off for integration testing with real devices.

## Overview

The JavaScript scaffold (`navigator.hid`) and core service plumbing are in place. The runtime currently uses:

- A libusb-based backend on Linux.
- An IOHIDManager backend on macOS.
- A SetupAPI/HidD backend on Windows.

Additional work (Android, hardware validation, entitlements) is still required for full parity.

On iOS/iPadOS, Apple does not expose public APIs for generic HID access. The runtime therefore disables WebHID on those platforms and `navigator.hid` calls reject with `NotSupportedError`.

## Platform Status

| Platform                | Enumeration | Request / Chooser | Open / Close | Input Reports | Feature / Output Reports | Notes                                                                                                                     |
| ----------------------- | ----------- | ----------------- | ------------ | ------------- | ------------------------ | ------------------------------------------------------------------------------------------------------------------------- |
| Linux (libusb)          | ✅          | ✅                | ✅           | ✅            | ✅                       | Uses libusb interrupt transfers. Requires udev rules for permissioning.                                                   |
| macOS (IOHIDManager)    | ✅          | ✅                | ✅           | ✅            | ✅                       | Backend built on IOHIDManager; pending validation on real devices and entitlement audit.                                  |
| Windows (SetupAPI/HidD) | ✅          | ✅                | ✅           | ✅            | ✅                       | Backend implemented via SetupAPI/HidD; pending hardware validation and packaging checks.                                  |
| Android                 | ⏳          | ⏳                | ⏳           | ⏳            | ⏳                       | Use `android.hardware.usb.UsbManager` with asynchronous bulk endpoints. Coordinate with permission prompts.               |
| iOS / iPadOS            | ❌          | ❌                | ❌           | ❌            | ❌                       | Unsupported: Apple does not expose public HID APIs; apps must fall back to Web Bluetooth or platform-specific frameworks. |

Legend: ✅ Ready │ ⏳ Planned │ ❌ Missing / blocked

## Implementation Roadmap

1. **macOS (IOHIDManager):** _Initial backend complete_
   - Follow-up: validate IOHIDElement-derived report metadata with real hardware and ensure multi-collection devices map correctly.
   - Confirm entitlement requirements for distribution builds and add build-system toggles if needed.

2. **Windows (Win32 HID):** _Backend implemented_
   - Follow-up: validate overlapped reads/report parsing with real HID hardware and document driver/permission requirements.

3. **Android (UsbManager):**
   - Kotlin service in `src/runtime/hid/android/` using `UsbDeviceConnection`.
   - Register broadcast receiver for `ACTION_USB_DEVICE_DETACHED`.
   - Forward input reports via `InputStream` reads on interrupt endpoints.

4. **iOS:**
   - Investigate `CoreHID` private APIs vs. accessory support; determine viability.
   - Prototype using `IOHIDManager` on macOS Catalyst as an intermediate step.

5. **Common tasks:**
   - Gate runtime permissions with `[permissions] allow_hid`.
   - Extend chooser UI to reflect device names per platform.
   - Add telemetry hooks for debugging (optional).

## Integration Testing Plan

1. **Device Matrix:**
   - Keyboard (report ID 0) – verifies zero-report handling.
   - Gamepad (multiple reports) – validates report ID routing.
   - Vendor-specific device – exercises feature reports.

2. **Test Harness:**
   - Add Oro desktop integration tests to open a HID device, listen for input, send a feature report, and assert payloads (legacy Socket suites remain available during the rename).
   - For Android, leverage instrumentation tests that dispatch synthetic USB intents.

3. **Manual Procedures:**
   - Document per-platform steps for granting OS-level permissions (e.g., `udev` rule snippets, Windows driver requirements).
   - Create troubleshooting guide (common errors, log locations).

4. **CI Considerations:**
   - Simulators lack HID hardware, so smoke tests should mock IPC responses.
   - Real-device regression tests can run on dedicated lab machines using the Oro test runner (legacy Socket mode sticks around for older pipelines).

## Automated Coverage Strategy

- **JavaScript scaffold:** continue expanding `test/src/hid/web-hid.test.js` with IPC-mocked scenarios that exercise report-ID edge cases (e.g., zero vs. non-zero report IDs, feature report truncation). The Oro test runner executes these in CI today (and still accepts `socket` invocations).
- **Backend-level shims:** introduce lightweight native unit tests per backend that feed synthetic descriptors into `parseReportDescriptor` (libusb) and IOHID/HIDP helpers. We can build these as `npm run test:runtime-core` fixtures compiled on each desktop target.
- **Descriptor fixtures:** define JSON fixtures under `test/fixtures/hid/` that represent common device classes (keyboard, gamepad, vendor-specific). The native tests and JS scaffold can both import these fixtures to ensure consistent expectations.
- **Mock transport hook:** expose a compile-time flag that swaps the platform HID APIs with a deterministic fake (e.g., a fake `libusb_device_handle`). This enables continuous testing without hardware and lets us assert on report payloads and event dispatch ordering.

## Open Questions

- How should we persist user grants across sessions? (Currently tied to runtime permissions only.)
- Should we expose additional events (e.g., `inputreporterror`) for parity with Chromium?
- Coordination with WebUSB / Bluetooth permissions to avoid overlapping prompts.

Please keep this document updated as platform backends move forward.

==============================================================================
DOCS: WebUSB in Oro Runtime (webusb)
URL: /runtime/docs/?p=webusb
==============================================================================

# WebUSB in Oro Runtime

Oro Runtime (formerly Socket) provides a WebUSB scaffold that exposes a `navigator.usb` API mirroring the browser specification. It bridges to the native libusb backend for enumeration, permission checks, hotplug events, and bulk/control transfers.

## Installing navigator.usb

The scaffold initializes automatically; simply call `navigator.usb.getDevices()` or `navigator.usb.requestDevice()` from your renderer. Devices returned include descriptors (vendor/product IDs, interface metadata) and support the usual WebUSB methods like `open`, `selectConfiguration`, `transferIn`, and `transferOut`.

## Platform support

The native WebUSB backend currently targets desktop platforms (macOS, Windows, Linux) where libusb integrations are available. Mobile builds ship the JS scaffold for API consistency, but the runtime service is disabled on iOS. Android builds expose device enumeration and permission flows through the foreground USB service (which requires `POST_NOTIFICATIONS` on Android 13+); data transfer APIs (`open`, `transferIn`, etc.) still return `NotSupportedError` until the remaining bindings land.

## Chooser Flow

When more than one device matches `requestDevice`, the scaffold fires a `usb.chooserequest` event whose detail object exposes the candidates plus `select(device)` and `cancel()` helpers.

```js
window.addEventListener('usb.chooserequest', (event) => {
  const { devices, select, cancel } = event.detail
  renderChooser(devices, select, cancel)
})
```

If no listener handles it, a default overlay is shown. The overlay honors `prefers-color-scheme` but you can override it entirely by handling the event yourself.

## Hotplug Events

The native backend emits `usb.deviceconnect` and `usb.devicedisconnect`; the scaffold transforms them into `navigator.usb` events:

```js
navigator.usb.addEventListener('connect', ({ device }) => {
  console.log('USB connected:', device.deviceId)
})
```

Existing devices in the cache update in place when descriptors change.

## Persistent grants

When a device is authorized, its identifier is stored in the runtime state database. On the next launch, the backend restores the grant so `navigator.usb.getDevices()` immediately returns previously-approved devices and `requestDevice()` can skip the chooser when only one persisted match exists.

## Permission queries

You can check the runtime's USB permission state without prompting:

```js
const status = await navigator.permissions.query({ name: 'usb' })
if (status.state === 'denied') {
  // surface your own UI before calling navigator.usb.requestDevice()
}
```

## Transfers

Control/Bulk OUT flows use binary IPC; IN transfers return `USBInTransferResult` with `DataView` payloads. `clearHalt` requires an explicit endpoint direction.

## Testing

See `test/src/usb/web-usb.test.js` for a minimal integration test demonstrating mocked IPC and chooser resolution.

==============================================================================
DOCS: MCP Server Configuration (MCP)
URL: /runtime/docs/?p=MCP
==============================================================================

# MCP Server Configuration

Oro Runtime ships with a lightweight MCP HTTP/SSE bridge. The bridge can be configured
statically through `oro.toml` or dynamically at runtime.

## CLI MCP server (`oroc mcp`)

The Oro CLI also ships with an MCP server that exposes common `oroc` workflows as MCP tools,
alongside safe workspace/config file access helpers.

### Stdio transport

`oroc mcp` defaults to JSON-RPC over stdio, which is the recommended transport for Codex and
other local agent runners.

```sh
oroc mcp --stdio
```

### Streamable HTTP transport

Use `--http` to run a Streamable HTTP MCP endpoint. The CLI prints a single JSON line to
stdout describing the bound host/port/endpoint/token, then continues serving requests.

```sh
oroc mcp --http --host 127.0.0.1 --port 0 --endpoint /mcp
```

Notes:
- The CLI follows the MCP Streamable HTTP transport (2025-06-18): JSON-RPC requests return
  `Content-Type: application/json`; notifications/responses return `202 Accepted` with no body.
- Sessions are normally created during `initialize`. Subsequent requests must include
  `Mcp-Session-Id` (missing: `400`). If a client supplies an unknown session id (POST or SSE),
  the CLI will create a new session for that id so stateless clients keep working.
- The CLI supports `GET` SSE streams for server-to-client messages, scoped to a session id.
  Only one active SSE stream is allowed per session (second connection returns `409` unless
  `--replace-sse-stream` is used).
- Loopback auth defaults to disabled unless `--token` is provided or `[mcp].token` is set.
- `--endpoint` normalises common variants (`mcp`, `/mcp/`) to avoid client/server mismatches.
- The HTTP server binds ports exclusively (no `SO_REUSEPORT`) so multiple `oroc mcp --http`
  instances cannot share a host/port. This prevents cross-session and cross-workspace confusion.

### Tools and resources

The CLI exposes:
- Tools: `run_cli`, workspace file read/write/list helpers, `oro.toml` read/write/validate,
  and convenience wrappers for common `oroc` commands (e.g., `build_app`, `run_app`).
- `read_file` reads absolute paths outside the workspace root by default. Use
  `--read-workspace-only` to disable this capability.
- Resources: `workspace:/` (root listing), `workspace:/oro.toml` (config), and additional
  resources discovered from `oro.toml` (build inputs/copy maps/icons) when present.

## oro.toml configuration

Add the optional `[mcp]` section to your app configuration to define defaults
the runtime uses whenever `mcp.startServer()` is invoked without overrides.

```ini
; [mcp]
; host = 127.0.0.1
; port = 0                  ; bind to an ephemeral port by default
; endpoint = /mcp           ; base HTTP/SSE endpoint
; token = my-shared-secret  ; static bearer token enforced by the runtime
; auth_timeout_ms = 5000    ; optional timeout used when awaiting dynamic auth handlers
```

- Setting `port = 0` instructs the runtime to bind to a random available port,
  which makes it easy to spin up multiple MCP servers in the same process.
- When `token` is provided the HTTP server enforces bearer authentication. The
  token still participates in the `Authorization` callback pipeline (see below),
  so you can mix static and dynamic checks.

## Dynamic Authorization

Use `mcp.setAuthorizationHandler()` to register a callback that approves or
rejects individual HTTP requests. The handler receives all available request
metadata and can return:

- `true` to accept the request.
- `false` (or throw) to reject the request with the default `401 Unauthorized`.
- An object `{ allow, status, message }` to customise both the decision and the
  HTTP response returned to clients.

```js
import mcp from 'oro:mcp'

await mcp.setAuthorizationHandler(({ authorization, headers }) => {
  // Reject requests that do not supply an Authorization header
  if (!authorization) {
    return { allow: false, status: 401, message: 'Missing bearer token' }
  }

  // Simple shared-secret check
  return authorization === `Bearer ${process.env.EXPECTED_TOKEN}`
})
```

Pass the same handler directly to `mcp.startServer({ authorize })` to configure
the server and set the callback in a single call.

```js
await mcp.startServer({
  port: 0, // bind to any free port
  authorize: ({ headers }) => headers['x-internal-key'] === 'expected-value',
})
```

Call `mcp.setAuthorizationHandler(null)` to remove the handler. Pending
authorization requests automatically fail closed when a handler is cleared or
the server shuts down.

## API Reference

The `oro:mcp` module now provides the following helpers in addition to the
existing registration functions:

| Function                          | Description                                                       |
| --------------------------------- | ----------------------------------------------------------------- |
| `mcp.startServer(options)`        | Starts the embedded server. Accepts `authorize` and `token`.      |
| `mcp.setAuthorizationHandler(fn)` | Registers or clears the dynamic authorization handler at runtime. |

See the runtime TypeScript declarations in the source repository (for example `api/index.d.ts`)
for the full schema (`MCPAuthorizationRequest`, `MCPAuthorizationDecision`, `MCPStartServerOptions`).

==============================================================================
DOCS: MCP Specification (2025-06-18) (mcp/2025-06-18/INDEX)
URL: /runtime/docs/?p=mcp/2025-06-18/INDEX
==============================================================================

# MCP Specification (2025-06-18)

Canonical spec base URL: https://modelcontextprotocol.io/specification/2025-06-18/

This page links to the upstream specification pages. For Oro Runtime’s MCP behavior, see `MCP.md`.

## Overview

- Model Context Protocol Specification: https://modelcontextprotocol.io/specification/2025-06-18
- Key Changes: https://modelcontextprotocol.io/specification/2025-06-18/key-changes
- Architecture: https://modelcontextprotocol.io/specification/2025-06-18/architecture

## Base Protocol

- Base Protocol Overview: https://modelcontextprotocol.io/specification/2025-06-18/basic
- Lifecycle: https://modelcontextprotocol.io/specification/2025-06-18/basic/lifecycle
- Transports: https://modelcontextprotocol.io/specification/2025-06-18/basic/transports
- Authorization: https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization
- Security Best Practices: https://modelcontextprotocol.io/specification/2025-06-18/basic/security-best-practices

## Base Protocol Utilities

- Cancellation Utility: https://modelcontextprotocol.io/specification/2025-06-18/basic/utilities/cancellation
- Ping Utility: https://modelcontextprotocol.io/specification/2025-06-18/basic/utilities/ping
- Progress Utility: https://modelcontextprotocol.io/specification/2025-06-18/basic/utilities/progress

## Client Features

- Roots: https://modelcontextprotocol.io/specification/2025-06-18/client/roots
- Sampling: https://modelcontextprotocol.io/specification/2025-06-18/client/sampling
- Elicitation: https://modelcontextprotocol.io/specification/2025-06-18/client/elicitation

## Server Features

- Server Features Overview: https://modelcontextprotocol.io/specification/2025-06-18/server
- Prompts: https://modelcontextprotocol.io/specification/2025-06-18/server/prompts
- Resources: https://modelcontextprotocol.io/specification/2025-06-18/server/resources
- Tools: https://modelcontextprotocol.io/specification/2025-06-18/server/tools

## Server Utilities

- Logging Utility: https://modelcontextprotocol.io/specification/2025-06-18/server/utilities/logging
- Completion Utility: https://modelcontextprotocol.io/specification/2025-06-18/server/utilities/completion

## Schema

- Schema Reference: https://modelcontextprotocol.io/specification/2025-06-18/schema

==============================================================================
DOCS: Embedded LLaMA Server (AI, OpenAI-compatible) (AI_SERVER)
URL: /runtime/docs/?p=AI_SERVER
==============================================================================

# Embedded LLaMA Server (AI, OpenAI-compatible)

The runtime embeds a llama.cpp-based server exposed via the in-process `oro:` scheme. There is no external listening socket; endpoints are available only inside the app.

## Endpoints (default prefix `/ai/llama`)

- `GET /health` — readiness + loaded models and basic metrics
- `GET /v1/models` — `{ object: "list", data: [{ id, object: "model" }] }`
- `POST/GET /v1/chat/completions` — OpenAI-compatible chat
  - SSE streaming: `?stream=true` or body `{ stream: true }`
- `POST/GET /v1/completions` — text completion
  - SSE streaming: `?stream=true` or body `{ stream: true }`
- `POST/GET /v1/embeddings` — vector for input
- Utilities: `POST/GET /tokenize`, `/detokenize`

## Model Loading (IPC)

```js
// Load a model by file name. Searches environment/userConfig paths.
await fetch('ipc://ai.llm.model.load?name=model.gguf')
// or provide `directory=/abs/path` explicitly
```

Search order for model files:

- `ORO_AI_LLM_MODEL_PATH` (env var: directory)
- userConfig key `ai_llm_model_path` (directory)
- explicit `directory` query parameter

## Request Semantics

- Location: `oro://<bundle>/<prefix>/<endpoint>`
- Content type: `application/json` supported; query params also accepted
- JSON body parse cap: 1 MiB (oversized bodies are not parsed)
- Prompt size cap: 128 KiB → 413
- Sampling defaults: taken from userConfig or server options when omitted
- Stop sequences:
  - Non-stream: output trimmed at earliest stop
  - Stream: rolling tail (size = longest stop) detects stop

### Tools/Function Calling (Stub)

When a request requires a function call (`tools` + required `tool_choice`), the server returns a minimal stub response:

- Non-stream: `choices[0].message.tool_calls[...]`, `finish_reason: "tool_calls"`
- Stream: a single chunk with `choices[0].delta.tool_calls[...]`, followed by `[DONE]`

Applications should interpret this and run their own vetted function implementation, then send a follow-up prompt.

## Configuration (userConfig)

- `ai_llm_server_prefix` (default `/ai/llama`)
- `ai_llm_default_model`
- `ai_llm_rate_limit_concurrency` (default 4)
- `ai_llm_rate_limit_rps` (0 = disabled)
- `ai_llm_rate_limit_burst` (0 = disabled)
- `ai_llm_default_max_tokens` (default 128)
- `ai_llm_default_temperature` (default 0.8)
- `ai_llm_default_top_p` (default 0.95)
- `ai_llm_default_top_k` (default 40)
- `ai_llm_default_min_p` (default 0.05)

Environment:

- `ORO_AI_LLM_MODEL_PATH` — directory containing models

## Metrics

`GET /health` returns metrics:

- `inflight`, `rateRPS`, `rateBurst`, `rateLimited`
- per-endpoint counts and average latencies (ms) for stream/non-stream chat and completions

## Security & Performance

- Internal-only exposure via `oro:`; no external ports
- Resource caps (prompt/JSON) to bound memory/CPU
- Concurrency and rate-limiting guards prevent overload; heavy jobs run off the UI thread
- SSE/chunk streams coalesce writes to reduce overhead
- Tool-calling does not execute arbitrary code; arguments are `{}` by default

## Testing Models in CI/Locally

- Optional env vars:
  - `ORO_AI_MODEL_NAME` (required)
  - `ORO_AI_MODEL_DIR` (optional directory)
- If set, E2E tests attempt to load the model and run basic streamed/non-stream chat checks.

==============================================================================
DOCS: Tool-Calling (Stub) Behavior (AI_TOOL_CALLING)
URL: /runtime/docs/?p=AI_TOOL_CALLING
==============================================================================

# Tool-Calling (Stub) Behavior

The embedded LLaMA server exposes OpenAI-compatible chat endpoints over the internal `oro:` scheme. For safety, when a request requires a function/tool call, the runtime does not execute arbitrary tool code. Instead, it returns a minimal, deterministic stub that applications can interpret and emulate client-side.

## When tool-calling stubs are used

- The request includes a `tools` array and a `tool_choice` that:
  - is `"required"`, or
  - an object specifying a particular function via `tool_choice.function.name`.

## What is returned

- Non-stream (`/v1/chat/completions`):

  ```json
  {
    "choices": [
      {
        "index": 0,
        "message": {
          "role": "assistant",
          "content": null,
          "tool_calls": [
            {
              "index": 0,
              "id": "call_...",
              "type": "function",
              "function": { "name": "<functionName>", "arguments": "{}" }
            }
          ]
        },
        "finish_reason": "tool_calls"
      }
    ]
  }
  ```

- Stream (`?stream=true`):
  - A single chunk with `choices[0].delta.tool_calls[...]`, then `data: [DONE]`.

## How to use this in applications

1. Detect a tool call in the response (non-stream) or streamed chunk.
2. Look up the function name (e.g., `weather.fetch`) in your own registry of allowed tools.
3. Execute the tool logic in your application environment (e.g., a JS function).
4. Append a follow-up message with the tool result and send another `/v1/chat/completions` request.

## Security notes

- The runtime never executes external code or system commands in response to tool-call requests.
- Arguments are returned as an empty JSON object (`{}`) to avoid passing arbitrary payloads. Applications should merge in validated arguments if desired.
- All inputs are size-limited and validated conservatively.

==============================================================================
DOCS: Whisper Speech Integration (AI_WHISPER)
URL: /runtime/docs/?p=AI_WHISPER
==============================================================================

# Whisper Speech Integration

Oro Runtime vendors [`whisper.cpp`](https://github.com/ggerganov/whisper.cpp.git) for
per-device speech-to-text. This document summarizes build requirements, IPC
endpoints, and the JavaScript API.

> capture snippet.

## Build & Packaging

The install script builds whisper alongside libuv/llama when `./bin/install.sh`
(or `ORO_HOME`/`PREFIX` packaging) is invoked. `_compile_whisper` currently
supports:

- **Desktop** (`x86_64-desktop`) – default path, verified.
- **Windows** – produces `whisper.lib` (experimental; requires MS toolchain).
- **iOS** (`iPhoneOS`/`iPhoneSimulator`) – uses `xcrun` clang/bitcode.
- **Android** (NDK) – static `libwhisper.a` per ABI.

> Pending: run platform-specific builds in CI to confirm toolchains and linking.

## IPC Routes

The runtime exposes whisper control commands through `ipc://`:

| Command                   | Description                                                                            |
| ------------------------- | -------------------------------------------------------------------------------------- |
| `ai.whisper.model.load`   | Load a model into memory (by `name` or `id`, optional `directory`, threading options). |
| `ai.whisper.model.list`   | List loaded models.                                                                    |
| `ai.whisper.model.unload` | Unload a model by `id` or `name`.                                                      |
| `ai.whisper.transcribe`   | Transcribe PCM payload (`POST` body) with optional query parameters (see below).       |

### Transcribe Query Parameters

- `id` / `name` – identify the model (one required).
- `format` – `f32` (default) or `pcm16`.
- `sampleRate` – source sample rate (default 16000).
- `channels` – channel count (default 1).
- `normalize` – `true` to scale waveform prior to inference.
- `stream` – `true` to stream partial segments over Conduit.
- `language`, `translate`, `detectLanguage`, `timestamps`, `wordTimestamps`, `diarize`, `threadCount`, `maxSegmentLength`, `temperature`, `temperatureIncrement`, `entropyThreshold`, `logProbThreshold`, `noSpeechThreshold` – forwarded to whisper.

When `stream=true` and a Conduit client exists for the `id`, segments are pushed
incrementally with payloads encoded via the Conduit binary framing. If no
Conduit client is present, partial segments are emitted via `ipc.write` queued
responses (sequence `-1`).

### Response Structure

```json
{
  "text": "full transcription",
  "language": "en",
  "audioMs": 1234.5,
  "processingMs": 456.7,
  "inputSampleRate": 44100,
  "inputSamples": 44100,
  "outputSamples": 16000,
  "resampled": true,
  "normalized": true,
  "segments": [
    {
      "index": 0,
      "start": 0.0,
      "end": 1.0,
      "text": "hello",
      "confidence": 0.95
    }
  ]
}
```

## JavaScript API (`oro:ai/whisper`)

```js
import whisper from 'oro:ai/whisper'

const model = new whisper.WhisperModel({ name: 'ggml-base.en.bin' })
await model.load({ directory: '/abs/path/to/models' })

const audio = new Int16Array(/* PCM16 samples */)
const result = await model.transcribe(audio, {
  sampleRate: 44100,
  channels: 2,
  normalize: true,
  stream: true,
  onSegment(segment) {
    console.log(segment)
  },
  signal: abortController.signal,
})
```

Options (typed in the runtime TypeScript declarations):

- `sampleRate`, `channels`, `format` – audio metadata.
- `normalize` – enable RMS normalization.
- `stream` + `onSegment` – receive partial hypotheses (requires Conduit).
- `signal` – abort the request.
- Other decoding knobs mirror llama (`temperature`, `maxSegmentLength`, etc.).

### Helpers

- `whisper.listModels()` – fetch loaded models.
- `whisper.unloadModel(idOrName)` – unload a specific model.

## Testing

The integration tests expect heavy fixtures and are skipped by default. Provide
the following environment variables to enable them:

```bash
export ORO_TEST_WHISPER_MODEL=/absolute/path/to/ggml-base.en.bin
export ORO_TEST_WHISPER_AUDIO=/absolute/path/to/audio.pcm
export ORO_TEST_WHISPER_AUDIO_FORMAT=pcm16   # optional
export ORO_TEST_WHISPER_AUDIO_SAMPLE_RATE=44100  # optional
export ORO_TEST_WHISPER_AUDIO_CHANNELS=2   # optional
```

Then run (optionally skipping native test extensions in CI):

```bash
ORO_TEST_SKIP_DESKTOP_EXTENSION=1 \
ORO_TEST_SKIP_TEST_EXTENSIONS=1 \
ORO_TEST_WHISPER_MODEL=... \
ORO_TEST_WHISPER_AUDIO=... \
npm test whisper-streaming -- --runInBand
```

## Configuration Keys

The following user-config (`oro.toml`) keys affect whisper:

- `ai_whisper_model_path` – directory fallback when loading models.
- `ai_whisper_queue_limit` – max queued transcription jobs (defaults to 4).

Per-model keys follow the same pattern as llama (e.g. `ai_whisper_model_<name>_*`).

## Notes & Limitations

- Non-16 kHz input is resampled via linear interpolation; consider higher-quality
  resamplers if your application demands it.
- Streaming currently emits full text for each partial segment; consumers may
  want to diff successive outputs.
- iOS/Android/Windows builds require platform toolchains; confirm in CI before
  shipping to end users.

==============================================================================
DOCS: Oro Application Update Protocol (OUP) (APPLICATION_UPDATE_PROTOCOL)
URL: /runtime/docs/?p=APPLICATION_UPDATE_PROTOCOL
==============================================================================

# Oro Application Update Protocol (OUP)

This document describes a portable, transport-agnostic system for delivering
signed application updates over HTTP and custom UDP/TCP transports.

The design is inspired by existing update frameworks (for example, systems like
The Update Framework and package manager repositories) but is tailored for the
Oro runtime, libsodium, and environments where application developers can host
their own infrastructure.

## Goals

- Protect users against tampered or replayed updates, even over untrusted
  networks.
- Make the format transport-agnostic so the same metadata works over HTTP,
  TCP, or UDP.
- Keep the server side simple enough for static hosting or small services.
- Allow applications to remain in control: the runtime can fetch & verify;
  the app decides when and how to apply an update.
- Provide a clear, evolvable wire format that can be implemented in other
  languages or runtimes.

Non-goals:

- Full OS / installer updates.
- Mobile app store updates (those environments are expected to use store
  mechanisms).
- Complex multi-role key hierarchies; the initial design keeps keys simple
  but is compatible with future extensions.

## High-level architecture

The update system separates **metadata**, **artifacts**, and **transport**:

- **Artifacts** are the update payloads (archives, binaries, bundles, etc).
- **Manifests** describe artifacts (version, platform, hashes, URLs) and are
  signed with an Ed25519 key.
- **Transports** (HTTP, TCP, UDP) move manifests and artifacts between
  publisher and client. Transport is assumed untrusted; integrity and
  authenticity are enforced at the metadata level with libsodium.

Each application ships with a built‑in **update public key**. Only holders of
the corresponding **update private key** can publish updates for that
application.

## Cryptography

The system uses libsodium:

- **Signatures**: `crypto_sign_ed25519_*` for manifest signatures.
- **Hashes**: `crypto_generichash` (or SHA‑256 via WebCrypto) for artifact
  digests.

Recommendations:

- Use one or more long‑lived Ed25519 **root/update keys** per application.
- Store private keys offline or in a CI secret store.
- Distribute the public key with the app (for example, hard‑coded or loaded
  from a trusted bundle).

Public keys and signatures are represented as:

- Public key (`pk`): 32‑byte Ed25519 public key, encoded as lowercase hex or
  base64url.
- Signature (`sig`): 64‑byte Ed25519 signature, encoded as lowercase hex or
  base64url.

The client treats encodings as interchangeable and normalises them back to
raw bytes for verification.

## Manifest format

The manifest is an opaque byte string from the perspective of signature
verification: publishers sign the raw bytes of the manifest file, and
clients verify the exact same bytes. A canonical JSON representation is
recommended for portability.

### Top-level shape

```json
{
  "schemaVersion": 1,
  "appId": "com.example.myapp",
  "generatedAt": "2025-01-01T12:34:56Z",
  "channels": ["stable", "beta"],
  "updates": [
    {
      "id": "stable-1.2.3",
      "version": "1.2.3",
      "channel": "stable",
      "minRuntimeVersion": "0.6.0",
      "critical": false,
      "notesUrl": "https://example.com/myapp/1.2.3-notes.html",
      "targets": [
        {
          "platform": "darwin",
          "arch": "x64",
          "osVersionRange": ">=11",
          "artifactUrl": "https://updates.example.com/myapp/darwin-x64-1.2.3.tar.zst",
          "length": 12345678,
          "hashAlgorithm": "sha256",
          "hash": "b0f3…", // hex
          "signatureAlgorithm": "ed25519",
          "artifactSignature": "cafe…" // optional per-artifact signature
        }
      ]
    }
  ]
}
```

Key points:

- `schemaVersion` gates breaking changes in the manifest layout.
- `appId` uniquely identifies the application (reverse DNS is recommended).
- `updates` may contain many versions and channels; the client filters to the
  relevant channel, platform, and version.
- The manifest is **not** trusted until its signature has been verified.

An authoritative JSON Schema for this manifest lives at
`schemas/update-manifest.schema.json` in the repository. Publishers and
downstream tooling can use it to validate `manifest.json` files during CI or
manual editing.

### Manifest signature sidecar

The manifest is distributed together with a signature file:

- Manifest bytes: `manifest.json`
- Signature bytes: `manifest.sig`

The signature file contains an encoded signature and metadata:

```json
{
  "schemaVersion": 1,
  "algorithm": "ed25519",
  "keyId": "pk-1",
  "signature": "cafe…" // base64url or hex
}
```

The JSON Schema for the signature file is available at
`schemas/update-manifest-signature.schema.json` in this repository.

Clients:

1. Download `manifest.json` as raw bytes.
2. Download and parse `manifest.sig`.
3. Decode the `signature` field to raw bytes.
4. Verify the signature over the raw `manifest.json` bytes using the
   configured public key.
5. Only then parse `manifest.json` as JSON and process its contents.

The same manifest and signature format is used for all transports.

## HTTP transport binding

HTTP(S) is the primary transport for manifests and artifacts. A minimal
setup can be hosted on static file storage or any simple HTTP server.

### Layout

Publishers choose a base URL and directory structure. One suggested layout is:

```text
https://updates.example.com/myapp/
  manifest.json
  manifest.sig
  artifacts/
    darwin-x64-1.2.3.tar.zst
    win32-x64-1.2.3.zip
```

The client is configured with:

- `manifestUrl` (for example, `https://updates.example.com/myapp/manifest.json`)
- `publicKey` (Ed25519 public key)
- Optionally a `channel`, `currentVersion`, and target platform/arch.

### HTTP request/response flow

1. Client sends `GET manifestUrl`.
2. Client sends `GET manifestUrl + ".sig"` (unless overridden).
3. Client verifies the manifest signature.
4. Client selects the best update for its channel, version, and platform.
5. Client downloads `artifactUrl` with `GET`, optionally using `Range`
   requests.
6. Client verifies the artifact digest and optional per‑artifact signature.

Transport security:

- HTTPS is strongly recommended.
- Even when HTTPS is unavailable or misconfigured, the client must reject
  updates whose manifest signatures or artifact hashes do not validate.

## UDP/TCP transport binding

Some deployments may prefer a push‑oriented or low‑latency transport. The
update protocol defines a simple binary framing suitable for TCP or UDP.

All messages start with:

```text
struct Header {
  uint8  version;     // protocol version, e.g., 1
  uint8  msgType;     // 0x01 = CHECK, 0x02 = RESPONSE, 0x03 = MANIFEST_CHUNK, 0x04 = ERROR
  uint16 reserved;    // must be zero for now
  uint32 length;      // length of the remaining payload in bytes (big-endian)
}
```

Payloads are encoded as JSON or CBOR; implementations may choose either as
long as both sides agree. For portability, JSON with UTF‑8 is recommended
initially.

### CHECK message

Client → server:

```json
{
  "schemaVersion": 1,
  "appId": "com.example.myapp",
  "currentVersion": "1.1.0",
  "channel": "stable",
  "platform": "darwin",
  "arch": "x64",
  "runtimeVersion": "0.6.0"
}
```

### RESPONSE message

Server → client:

```json
{
  "schemaVersion": 1,
  "hasUpdate": true,
  "selectedUpdateId": "stable-1.2.3",
  "manifestInline": false,
  "manifestUrl": "https://updates.example.com/myapp/manifest.json"
}
```

If `manifestInline` is `true`, the server may send the manifest bytes over
subsequent `MANIFEST_CHUNK` messages:

```text
struct ManifestChunkPayload {
  uint32 offset;      // byte offset of this chunk
  uint32 totalLength; // total manifest length in bytes
  uint8  data[];      // chunk bytes
}
```

The client reassembles the manifest bytes, then verifies the signature as in
the HTTP case. Artifacts are still typically downloaded over HTTP, but a
TCP or UDP stream could also carry artifact chunks, subject to deployment
constraints.

## Client-side API (overview)

The Oro runtime exposes a high‑level `oro:application/update` module
that:

- Fetches manifest and signature over HTTP.
- Verifies manifest signatures using libsodium.
- Selects an appropriate update for the app’s platform/channel/version.
- Downloads and verifies artifact hashes.
- Returns verified artifacts to the application for installation.

The API is transport‑agnostic: advanced users can swap the HTTP transport
with a custom TCP/UDP implementation that conforms to the same manifest and
signature rules.

### Mapping to the `oro:application/update` module

The `api/application/update.js` module provides a small set of primitives that map
directly onto this protocol:

- `fetchManifest(options)`  
  - Inputs: `manifestUrl`, optional `signatureUrl`, `publicKey`, optional
    `fetch`, `signal`, and extra HTTP headers.  
  - Behavior: downloads `manifest.json` and `manifest.sig`, verifies the
    Ed25519 signature using libsodium, then parses the manifest JSON.  
  - Returns: `{ manifest, raw, signature }`, where `raw` is the original
    manifest bytes and `signature` includes the decoded signature bytes and
    metadata.

- `selectUpdate(manifest, options)`  
  - Inputs: a verified `UpdateManifest` and selection hints (`channel`,
    `currentVersion`, `platform`, `arch`, `runtimeVersion`).  
  - Behavior: filters updates by channel and targets by platform/arch,
    enforces `minRuntimeVersion` and `currentVersion`, then chooses the
    highest compatible version (preferring `critical` when versions tie).  
  - Returns: `{ manifest, update, target }` or `null` if no suitable update
    exists.

- `downloadUpdate(target, options)`  
  - Inputs: a `UpdateTarget` from the manifest and optional `fetch`/`signal`.  
  - Behavior: downloads the artifact at `artifactUrl`, enforces `length` (if
    provided), computes a digest using WebCrypto (`SHA-256` by default), and
    compares it to the manifest’s `hash` field.  
  - Returns: a `Uint8Array` with the verified artifact bytes.

- `verifyArtifact(payload, target)`  
  - Inputs: artifact bytes and the corresponding `UpdateTarget` from the
    manifest.  
  - Behavior: enforces `length` (if present) and verifies the declared hash.  
  - Use this when artifacts are obtained via a non-HTTP transport (for
    example, custom TCP/UDP delivery or a local cache).

- `checkForUpdates(options)`  
  - Convenience wrapper that calls `fetchManifest`, `selectUpdate`, and (if
    requested via `download: true`) `downloadUpdate`.  
  - Returns a discriminated result:
    - `{ updateAvailable: false, manifest, signature }`, or  
    - `{ updateAvailable: true, manifest, signature, update, target, artifact? }`.

- `openArtifactArchive(artifact)`  
  - Inputs: a verified artifact payload (for example, the `artifact` field
    from `checkForUpdates` when `download: true`).  
  - Behavior: wraps the bytes in a native tar reader and returns a
    `TarArchive` backed by the runtime’s tar service. This allows callers to
    inspect and extract entries using the same semantics as `oro:tar`
    (see `TAR_API.md` for details).  
  - Intended for tar-based update bundles; callers are free to ignore it for
    non-tar artifacts.

Client code is expected to embed or otherwise obtain the Ed25519 public key
and pass it in as `publicKey`. The runtime does not manage update keys.

When calling `fetchManifest` or `checkForUpdates`, callers MAY also provide
an `expectedAppId` option; if present, the helpers will reject manifests
whose `appId` does not match the expected value. This is recommended for
applications that support multiple products or environments.

### Example integration

Simple HTTP-based check-and-download flow:

```js
import { checkForUpdates } from 'oro:application/update'

const result = await checkForUpdates({
  manifestUrl: 'https://updates.example.com/myapp/manifest.json',
  publicKey: '<ed25519-public-key-hex-or-base64>',
  channel: 'stable',
  currentVersion: '1.2.3',
  download: true,
})

if (!result.updateAvailable) {
  console.log('No updates available')
} else {
  const { update, target, artifact } = result
  console.log('Selected update', update.version, 'for', target.platform, target.arch)
  // TODO: apply the update bytes in a way that makes sense for your app.
}
```

### CLI tooling

The Oro CLI provides first-party helpers for managing update keys, manifests,
and bundles:

- `oroc update keygen`  
  - Generates an Ed25519 keypair suitable for signing manifests.  
  - Outputs JSON with `keyId`, `publicKey`, and `privateKey` (hex).

- `oroc update init`  
  - Scaffolds a minimal `manifest.json` file in the current directory.  
  - Sets `schemaVersion = 1`, `appId` from your oro.toml's `[meta] bundle_identifier` (falling back to a placeholder),
    `generatedAt` (UTC), `channels` from `update_channel` (or `["stable"]` when not set), and an `updates` array
    containing a single entry for the current version/channel with an empty `targets` array.

- `oroc update sign`  
  - Signs a manifest file and writes a detached `manifest.sig` JSON sidecar.  
  - Inputs: optional `--manifest=<path>` (defaults to `manifest.json` or a
    custom name), and either `--keys=<file>` (JSON) or
    `--private-key=<hex>`.  
  - Supports `--key-id` and `--out` to control metadata and output path.
  - By default, the signature filename is derived from the manifest name by stripping the extension and appending `.sig`
    (for example, `manifest.json` → `manifest.sig`).
  - Advanced: set `ORO_UPDATE_MANIFEST_FILENAME` or pass
    `--manifest-name=<name>` to change the default manifest filename (and
    derived signature path).

- `oroc update verify`  
  - Verifies a manifest + signature pair against a public key.  
  - Inputs: optional `--manifest=<path>` (defaults to `manifest.json` or a
    custom name), optional `--signature=<path>` (defaults to the derived signature path, e.g. `manifest.json` → `manifest.sig`),
    and either
    `--keys=<file>` (JSON) or `--public-key=<hex>`.
  - Advanced: set `ORO_UPDATE_MANIFEST_FILENAME` or pass
    `--manifest-name=<name>` to change the default manifest filename; the
    default signature path is derived by stripping the manifest's extension and appending `.sig`
    (for example, `manifest.json` → `manifest.sig`).

- `oroc update validate`  
  - Validates a manifest JSON file against the expected schema shape.  
  - Inputs: optional `--manifest=<path>` (defaults to `manifest.json` or a
    custom name), and optional `--manifest-name=<name>` (used when `--manifest` is not provided).  
  - Behavior: parses the manifest and enforces structural rules aligned with
    `schemas/update-manifest.schema.json` (required fields, types, relationships).  
  - Advanced: with `--strict`, additional consistency rules are applied (for example,
    ensuring each update’s `channel` is present in the top‑level `channels` array and that `artifactUrl` values do not
    contain whitespace). Intended for fast local checks and CI.

- `oroc update bundle`  
  - Builds a tar archive containing the contents of a directory, suitable as
    an update artifact.  
  - Inputs: optional `--input=<dir>` (defaults to the project directory, i.e.,
    the app source) and optional `--output=<bundle.tar>` (defaults to
    `<build_name>-<version>.tar` derived from `oro.toml`).  
  - Additional options:
    - `--manifest` / `--manifest-name` (or `ORO_UPDATE_MANIFEST_FILENAME`): when provided, the CLI parses the manifest,
      validates it against the schema shape, and updates it with a new target describing the bundle (including `length`,
      `hashAlgorithm`, and `hash`).  
    - `--channel`, `--update-id`, `--platform`, `--arch`, `--artifact-url`: control which update entry and target
      are created or amended. Reasonable defaults are derived from `oro.toml` (`update_channel`, `meta_version`) and the
      bundle filename when these flags are omitted (for source-only bundles, `platform` defaults to `"source"` and
      `arch` defaults to `"any"`).  
    - `--hash-algorithm=<sha256|sha1>`: hash algorithm for the tar payload. Defaults to `sha256` when libsodium is
      available at build time (via `crypto_generichash`) and to `sha1` otherwise. The resulting digest is written into
      the manifest’s `hash` field for the new target.
  - Preserves directory layout and file metadata (size, basic mode bits,
    and mtime) using the runtime’s native tar implementation.

- `oroc update extract`  
  - Extracts a tar archive (for example, one produced by `update-bundle`)
    into a destination directory.  
  - Inputs: `--bundle=<bundle.tar>`, `--dest=<dir>`.  
  - Rejects absolute paths and `..` segments inside the archive to avoid
    directory traversal; ignores special entries such as symlinks.

- `oroc update server`  
  - Runs an update server implementing the HTTP and binary TCP/UDP bindings of this protocol.  
  - Default mode is HTTP and is intended to be run behind a reverse proxy or
    load balancer in production, but TCP and UDP modes are also suitable for production
    deployments when a binary CHECK/RESPONSE transport is desired.  
  - Inputs: `--root=<dir>` (directory containing one or more manifest trees),
    optional `--host=<host>` and `--port=<port>` (default `0.0.0.0:8080`), and optional
    `--manifest-name=<name>` (defaults to `manifest.json` or `ORO_UPDATE_MANIFEST_FILENAME`).  
  - HTTP exposes:
    - `GET /health` — readiness metadata for the server.  
    - `POST /check` — accepts a `CHECK` JSON payload with `appId` and responds with a
      `RESPONSE` JSON whose `manifestUrl` points at `/<appId>/<manifest-name>` when such a manifest
      exists under `--root`; otherwise `hasUpdate: false`.  
    - `GET /<path>` — serves static files rooted under `--root`, including
      `/<appId>/<manifest-name>` and the corresponding signature file (for example
      `/<appId>/manifest.sig` when `manifest-name` is `manifest.json`).  
  - TCP/UDP expose the same CHECK/RESPONSE semantics over the OUP binary framing described above:
    - The payload inside the binary frame is the same JSON `CHECK`/`RESPONSE` body as HTTP,
      including `schemaVersion`, `appId`, `hasUpdate`, and `manifestUrl`.

- `oroc update info`  
  - Acts as a small client for the update protocol and for static manifest hosting.  
  - HTTP static mode: with `--manifest-url=<url>`, fetches a JSON manifest from an HTTP(S) origin, pretty‑prints it,
    and reports whether a companion signature file is reachable (by default derived as `manifest.sig`). When `--keys` or
    `--public-key` is provided and libsodium is available, it also verifies the manifest signature before printing.  
  - HTTP server mode: with `--host`/`--port` and no `--manifest-url`, sends a `CHECK` JSON body to an HTTP update server’s
    `/check` endpoint and pretty‑prints the `RESPONSE` JSON. With `--follow-manifest`, if the RESPONSE includes a
    `manifestUrl` pointing at a HTTP(S) resource, the CLI follows that URL, validates the referenced manifest, and when
    `--keys`/`--public-key` are provided it also verifies the manifest signature before printing it.  
  - TCP/UDP modes: with `--transport=tcp`/`--tcp` or `--transport=udp`/`--udp`, sends a binary‑framed `CHECK` message and
    pretty‑prints the JSON `RESPONSE` payload returned by the server. A `--timeout-ms` flag can be used to bound how long the
    client waits for a TCP or UDP response. When `--follow-manifest` is provided and the RESPONSE contains a `manifestUrl`
    pointing at a HTTP(S) resource, the CLI follows that URL and applies the same manifest validation / verification flow
    as in the HTTP server mode.  
  - Common hints such as `--app-id`, `--channel`, `--current-version`, `--platform`, `--arch`, and `--runtime-version`
    are included in the `CHECK` payload when provided; their defaults are taken from `oro.toml` when available.  
  - The flags `--http`, `--tcp`, and `--udp` are shorthands for `--transport=http`, `--transport=tcp`, and
    `--transport=udp` respectively.  
  - When `--follow-manifest` is used in server modes and `--app-id` is set, any fetched manifest must have a matching
    `appId` value or the command fails; this prevents misconfiguration where a server points to a manifest for a different app.

#### Example end-to-end flows

Basic local flow using the default `manifest.json`:

```bash
# 1) Scaffold a manifest for the current project.
oroc update init

# 2) Generate a signing keypair (writes key.json).
oroc update keygen > key.json

# 3) Build a source-only bundle and record it in the manifest.
oroc update bundle --manifest manifest.json

# 4) Sign the manifest using the generated keypair.
oroc update sign --keys key.json --manifest manifest.json

# 5) Verify the manifest + signature using the same keypair.
oroc update verify --keys key.json --manifest manifest.json
```

Serving many apps/manifests and querying them:

```bash
# 1) Prepare a directory of per-app trees.
mkdir -p ./updates/com.example.app
cp manifest.json ./updates/com.example.app/
cp manifest.sig ./updates/com.example.app/

# 2) Run an HTTP update server on 0.0.0.0:8080.
oroc update server --root ./updates

# 3) From another terminal, query for a given app and follow the manifestUrl.
oroc update info --http --host 127.0.0.1 --port 8080 \
  --app-id com.example.app \
  --follow-manifest
```

Static object store hosting (no custom server, just HTTP):

```bash
# 1) Upload manifest.json and manifest.sig to object storage/CDN.
#    Example URLs:
#      https://cdn.example.com/app/manifest.json
#      https://cdn.example.com/app/manifest.sig

# 2) Inspect the manifest only (no verification).
oroc update info \
  --manifest-url https://cdn.example.com/app/manifest.json

# 3) Inspect and verify the manifest using a public key file.
oroc update info \
  --manifest-url https://cdn.example.com/app/manifest.json \
  --keys app-pubkey.json
```

### Configuration defaults

Applications can provide update defaults in `oro.toml` (or `.ororc`) which
the native update service uses when corresponding options are not provided
programmatically:

- `update_channel` (flattened key)  
  - Default update channel when a `channel` option is not provided to
    `checkForUpdates`.  
  - Common values: `"stable"`, `"beta"`, `"nightly"`.  
  - When absent, `"stable"` is used.

- `update_max_manifest_bytes`  
  - Maximum allowed manifest size in bytes when `maxManifestBytes` is not
    passed to `checkForUpdates`.  
  - Manifests larger than this are rejected with `ERR_MANIFEST_TOO_LARGE`.

- `update_max_artifact_bytes`  
  - Maximum allowed artifact size in bytes when `maxArtifactBytes` is not
    passed to `checkForUpdates`/`downloadUpdate`.  
  - Artifacts larger than this are rejected with `ERR_ARTIFACT_TOO_LARGE`.

All per-call options (`channel`, `maxManifestBytes`, `maxArtifactBytes`,
etc.) continue to take precedence over configuration defaults when
explicitly provided.

A UDP/TCP deployment can mirror the same flow but substitute a custom
transport for the manifest/artifact fetch:

1. Use `oro:dgram` or `oro:tcp` to send the `CHECK` message and receive
   `RESPONSE` / `MANIFEST_CHUNK` messages.  
2. Reassemble the manifest bytes as described in the UDP/TCP section.  
3. Call `fetchManifest`-like logic (or `verifyManifestBytes`/`parseManifest`
   if you are reusing the implementation) with the reassembled bytes and the
   configured public key.  
4. Use `selectUpdate`, `downloadUpdate`, and/or `verifyArtifact` exactly as
   in the HTTP case.

## Server-side considerations

Publishers are free to implement infrastructure however they like, subject
to a few constraints:

- Manifests and signatures must be served as opaque byte streams (no
  on‑the‑fly rewriting).
- Artifact bytes must be stable and match the hashes declared in the
  manifest.
- Version/channel rules should stay monotonic for a given app to avoid
  downgrade attacks (for example, never republish an older binary with a
  newer version).
- Keys should be rotated rarely and with care; when rotation is necessary,
  ship a new app build that trusts the new key before publishing manifests
  signed solely by that key.

### Key management recommendations

- Keep update signing keys separate from other application secrets.  
- When rotating keys:
  - Ship a new app build that trusts both the old and new public keys.  
  - Start signing manifests with the new key while still allowing the old
    one for a defined window.  
  - Once a majority of clients are upgraded, stop accepting the old key.
- Record which key was used in the `keyId` field of `manifest.sig` so logs
  and tooling can easily audit past updates.

## Extensibility

The protocol is designed to evolve without breaking existing clients:

- `schemaVersion` allows new required fields to be introduced.
- New hash or signature algorithms can be added as additional values.
- Additional metadata (for example, delta update descriptors or mirrors) can
  be added without affecting signature verification, as long as publishers
  sign the full manifest bytes.

Future work can add:

- Multi‑role key hierarchies (root vs. release keys).
- Delta update formats and patch application helpers.
- Push notifications over the Oro network stack to notify clients of
  available updates without polling.

### Current implementation status and limitations

The implementation in this repository provides:

- Full HTTP binding support (manifest + signature fetch over HTTP(S)), now
  implemented natively in the Oro runtime (C++ service) and exposed via IPC.  
- Manifest verification using Ed25519 via libsodium in the native runtime
  (with a JS fallback for environments where the native service is
  unavailable).  
- Artifact integrity checks using SHA‑2 digests and optional length checks,
  performed natively when the update service is enabled.  
- An application-facing API in `oro:application/update` that delegates to
  the native update service when available and falls back to a
  transport-agnostic JS implementation that can be reused with custom
  transports.

Notable limitations and areas reserved for future work:

- Per-artifact signatures: the manifest format supports
  `signatureAlgorithm`/`artifactSignature`, but the current JS helpers only
  enforce hashes and lengths. Deployments that require per-artifact
  signatures must add verification on top or extend `verifyArtifact`.  
- `schemaVersion` handling: manifests and signature files carry
  `schemaVersion`. The current helpers enforce `schemaVersion === 1` for
  manifests and reject unknown values as unsupported. Future versions may
  allow callers to opt into accepting additional schema versions.  
- `appId` enforcement: callers can provide an `expectedAppId` option when
  fetching manifests. If present, the helpers enforce an exact match between
  `manifest.appId` and this value. Deployments that reuse signing keys
  across multiple products SHOULD set `expectedAppId` to avoid configuration
  mistakes.  
- UDP/TCP transport helpers: the binary framing and messages are specified,
  but no concrete `oro:application/update` UDP/TCP helpers ship yet. Deployments that
  require them should implement framing on top of `oro:dgram` / `oro:tcp`
  and then reuse the manifest/artifact verification APIs described above.

==============================================================================
DOCS: Oro Runtime Release Automation (npm packages) (release/ORO_RELEASE_AUTOMATION)
URL: /runtime/docs/?p=release/ORO_RELEASE_AUTOMATION
==============================================================================

# Oro Runtime Release Automation (npm packages)

This document describes how the release scripts in this repo publish Oro Runtime
CLI/runtime packages to npm.

## Scripts

- `bin/version.sh`
  - Interactively bumps `VERSION.txt` and `clib.json`.
  - When the major/minor version changes, bumps `npm/packages/@orocomputer/runtime-node`.

- `bin/publish-npm-modules.sh`
  - Builds the CLI and runtime artifacts under a temporary publish root (`$ORO_HOME`).
  - Stages and publishes the Oro npm packages (top-level + platform variants).

- `bin/runtime-artifacts.sh`
  - Centralizes runtime artifact naming (`ORO_RUNTIME_ARTIFACT_NAME=oro-runtime`).
  - Provides helpers used by `bin/publish-npm-modules.sh` to locate and validate
    platform/arch outputs.

## Guardrails

- Release tooling is Oro-only: no legacy CLI names, package scopes, or artifact aliases.
- `test/unit/bootstrap-tooling.test.js` asserts the scripts stay Oro-only.

==============================================================================
DOCS: Oro Runtime CI/CD Matrix (CI_MATRIX)
URL: /runtime/docs/?p=CI_MATRIX
==============================================================================

# Oro Runtime CI/CD Matrix

This document describes the community‑run CI/CD validation for the Oro Runtime
in this repository. The goals are:

- Give contributors a predictable, documented test matrix.
- Ensure changes are validated on at least one desktop target.
- Make it easy to extend coverage (extra OSes, architectures, or self‑hosted runners).

## Current GitHub Actions workflow

The primary workflow lives at `.github/workflows/ci.yml` with the name **CI**.

Triggers:

- `push` to `dev`, `jwerle/**`, `feature/**`, or `fix/**` branches.
- `pull_request` targeting this repository.
- Manual `workflow_dispatch` from the GitHub Actions UI.

Jobs overview:

- **Lint (standardjs)** — runs `npm run test:lint:ci` on Linux.
- **Desktop + runtime-core tests** — builds the Oro Runtime CLI and runs the
  desktop and runtime-core test suites on Linux across a Node.js matrix.

## Test matrix

The current matrix is intentionally conservative and can be expanded as the
community exercises the pipeline:

- Operating systems:
  - `ubuntu-latest`
- Node.js versions:
  - `18.x` (LTS)
  - `20.x` (LTS)
- Test targets:
  - Lint: `npm run test:lint:ci`
  - Desktop tests: `npm test` (desktop target via `test/scripts/run.js`)
  - Runtime core tests: `npm run test:runtime-core`

## Runtime build settings

The CI workflow builds the `oroc` CLI before running tests:

- `./bin/install.sh` runs on `ubuntu-latest` with:
  - `NO_ANDROID=1` and `NO_IOS=1` to avoid mobile toolchain setup in CI.
  - `DEBUG=1` to produce debug builds useful for diagnosing failures.
  - `VERBOSE=1` to log build configuration and any dependency advice.
- Desktop tests run with:
  - `ORO_TEST_HEADLESS=1` to prefer headless/browserless execution where supported.
  - `ORO_TEST_SKIP_DESKTOP_EXTENSION=1` and
    `ORO_TEST_SKIP_TEST_EXTENSIONS=1` to avoid building heavy native test
    extensions in constrained CI environments while still exercising the
    core/runtime.

Contributors should still follow the guidance in `CONTRIBUTING.md` for local
builds (for example, running `./bin/install.sh` before `npm test`), but the CI
matrix is designed to work out of the box on GitHub‑hosted Linux runners.

## How to trigger CI for your changes

- Open a pull request against this repository.
  - The **CI** workflow runs automatically and reports status on the PR.
- Push commits to an existing PR branch.
  - CI re‑runs on the updated commit set.
- For long‑lived topic branches (e.g., `jwerle/run-48-…`), push directly to the
  branch; CI runs on `push` in addition to any open PRs.
- To re‑run checks without pushing a new commit:
  - Use the **Re-run jobs** button in the Actions tab, or
  - Trigger `workflow_dispatch` manually from the **CI** workflow page.

## Reading results and debugging failures

- Each job publishes logs directly in the GitHub Actions UI.
- Lint failures:
  - Look for `standard` output in the **Lint (standardjs)** job; it lists file
    paths and rule violations that must be fixed.
- Desktop/runtime-core test failures:
  - The **Desktop + runtime-core tests** job emits:
    - Build output from `./bin/install.sh` (including missing dependency hints).
    - Test runner output from `npm test` and `npm run test:runtime-core`.
  - Common issues:
    - Missing system packages (see hints printed by `bin/install.sh`).
    - Tests that assume non‑headless environments; consider using
      `ORO_TEST_HEADLESS=0` locally when reproducing.

## Extending the matrix

The matrix is intentionally minimal to keep CI turnaround reasonable. To propose
additional coverage:

- Open a GitHub issue in this repository describing:
  - Desired OS/arch (e.g., `macos-latest`, `windows-latest`, self‑hosted label).
  - Any additional Node.js versions or test targets to include.
  - Whether failures on the new axis should be blocking or optional.
- Optionally send a pull request that:
  - Extends `matrix.os` or `matrix.node` in `.github/workflows/ci.yml`.
  - Adjusts environment variables or build steps to keep runtimes stable on the
    new platform.

## Feedback and community input

Feedback on the CI/CD matrix is welcome:

- File issues for flaky jobs, missing coverage, or confusing failure modes.
- Suggest improvements to this document or the workflow in pull requests.
- Use GitHub Discussions (where enabled for the org) to coordinate broader
  changes to the test strategy before sending large matrix expansions.

==============================================================================
DOCS: Oro Runtime Artifact Naming (ORO_ARTIFACT_NAMING)
URL: /runtime/docs/?p=ORO_ARTIFACT_NAMING
==============================================================================

# Oro Runtime Artifact Naming

This document defines the canonical naming for Oro Runtime build artifacts across
platforms and packaging ecosystems.

## Native libraries and archives

Primary Oro Runtime libraries use the `oro-runtime` stem:

- **Static libraries (desktop/mobile toolchains)**
  - Linux/macOS: `liboro-runtime.a`
  - Windows (MSVC): `oro-runtime.lib`
- **Dynamic libraries / shared objects (where produced)**
  - Linux: `liboro-runtime.so`
  - macOS: `liboro-runtime.dylib`
  - Windows: `oro-runtime.dll`

## pkg-config files

Oro Runtime ships a pkg-config file using the Oro name:

- Primary file: `oro-runtime.pc`
  - `Name: oro-runtime`
  - `Version: <runtime version>`

## CLI and configuration artifacts

- CLI binary: `oroc`
- Project config: `oro.toml`
- Per-developer overrides/secrets: `.ororc`
- Environment variables: `ORO_*`

## NPM packages and scopes

Oro Runtime publishes packages under the `@orocomputer` scope:

- `@orocomputer/runtime`
- `@orocomputer/runtime-{darwin,linux,win32}-{arm64,x64}`
- `@orocomputer/runtime-node`

## Updating this policy

If artifact naming changes, update this document alongside the implementation
and ensure `test/unit/bootstrap-tooling.test.js` continues to enforce Oro-only
release tooling.

==============================================================================
DOCS: Oro Runtime Governance Overview (GOVERNANCE)
URL: /runtime/docs/?p=GOVERNANCE
==============================================================================

# Oro Runtime Governance Overview

This document explains how Oro Runtime is governed: who maintains the project, how decisions are made, and how to escalate when changes have broad impact (such as the Socket → Oro rebrand).

It complements the contribution and security guidelines in the runtime source repository and should be read alongside `RUNTIME_ARCHITECTURE.md` for compatibility-sensitive changes.

## Roles

- **Maintainers**
  - Steer project direction and own final decisions on design, architecture, and releases.
  - Triage issues, prioritize work, and merge pull requests.
  - Ensure the project follows documented security, release, and compatibility policies.

- **Reviewers**
  - Provide code review, documentation review, and test coverage feedback.
  - Can approve most PRs; escalate controversial or cross‑cutting changes to maintainers.
  - May be maintainers in related repos (CLI, website, tooling) acting as liaisons.

- **Contributors**
  - Anyone opening issues, PRs, or participating in discussions.
  - Follow the contribution guide, code style, and security guidelines.
  - Can propose changes to policies, APIs, and governance via issues and discussions.

- **Release captain (per release)**
  - Coordinates tagging, changelogs, and release announcements.
  - Ensures the release checklist is followed (see the runtime repository’s release checklist and release notes).
  - Acts as the tie‑breaker when release‑blocking decisions need a prompt resolution.

- **Technical steering (TSC‑style group)**
  - Small group of maintainers responsible for long‑term direction and cross‑repo policy.
  - Handles escalations and approves changes to governance or rebrand‑affecting policy docs.

## Decision‑making model

Oro Runtime uses a **lazy consensus** model:

- For most changes, **one maintainer approval + passing checks** is sufficient once reasonable review time has passed.
- If someone has significant concerns, they should:
  - Comment directly on the PR or issue with clear, actionable feedback.
  - Propose concrete alternatives if they are blocking a change.
- If consensus cannot be reached in a reasonable time:
  - The discussion is escalated to the relevant maintainer or the TSC group.
  - The escalated decision and rationale are recorded in the issue or PR for future reference.

### When to open an RFC or discussion first

Use a GitHub Discussion or dedicated design issue when:

- A change affects **documented public APIs** (JS APIs, CLI commands, config fields).
- Backward compatibility guarantees documented in `RUNTIME_ARCHITECTURE.md` may be impacted.
- Governance, security, or release policy documents need substantial edits.

In these cases:

- Capture the problem, constraints, and proposed approach concisely.
- Link related Linear tickets (e.g., Socket → Oro rebrand work items).
- Give stakeholders time to respond before landing implementation PRs, unless the change is clearly low‑risk and time‑sensitive.

## Review expectations

New contributors should have clear expectations about how reviews work:

- For most changes, one maintainer or reviewer approval plus passing checks is sufficient, provided there has been a reasonable opportunity for others to comment.
- Documentation-only or low-risk changes are typically merged after a single maintainer approval.
- Runtime, API, or policy changes that affect compatibility guarantees (for example, items documented in `RUNTIME_ARCHITECTURE.md`) may require explicit sign-off from the relevant maintainers or the TSC group.
- Maintainers aim to provide an initial response to new issues and PRs within a few business days. If you have not received feedback, it is appropriate to ping the thread or ask in the Matrix/Discord `#oro-runtime` channels.
- Contributors are encouraged to keep PRs focused; large cross-cutting work should be broken into smaller pieces or preceded by a design/RFC discussion so reviews remain tractable.

## Escalation paths

If you disagree with a proposed or merged change, or if a decision feels blocked:

1. **Start with the PR/issue thread**
   - Ask clarifying questions.
   - Provide concrete examples or data where possible.
2. **Escalate to maintainers**
   - Mention a maintainer directly in the PR/issue.
   - Summarize the points of agreement and disagreement so far.
3. **Escalate to the TSC group**
   - Use a GitHub Discussion (e.g., “Request for decision: …”) when the change affects multiple repos or long‑term policy.
   - The TSC aims to respond promptly, with a clear written decision and follow‑up tasks as needed.

Security‑sensitive reports should always follow the security process in `SECURITY.md` rather than public escalation.

## Roadmap visibility and release cadence

The Oro Runtime roadmap and releases are visible through a few sources:

- Near-term technical priorities and status are tracked in issues and project boards.
- Release notes and version history are tracked in the runtime repository (releases/changelog).
- Larger project arcs are tracked in Linear projects and via GitHub Projects/Discussions referenced from those tickets.

Oro Runtime does not mandate a strict calendar-based release cadence. Instead:

- Runtime releases are cut when they satisfy the project’s documented quality criteria (release checklist).
- Patch releases are issued as needed for critical bugs and security fixes.

## How to propose changes

To propose a change to Oro Runtime (code, APIs, docs, or policy):

1. **Open an issue**
   - Describe the problem, motivation, and rough proposal.
   - Link any relevant Linear tickets if you are working off a scoped project.
2. **Decide whether an RFC/discussion is needed**
   - For routine fixes or small features, a PR referencing the issue is usually enough.
   - For cross‑repo work, open a Discussion and link it from the issue.
3. **Open a PR**
   - Follow the coding and documentation guidelines in `AGENTS.md` and `CODE_STYLE.md` (in the runtime repository).
   - For APIs, ensure usage, parameters, return values, and examples are documented in JSDoc and the relevant docs.
4. **Request review**
   - Tag maintainers or reviewers when ready.
   - For large cross‑repo changes, call out which docs or policies you believe are impacted.

## Onboarding and where to start

New contributors should:

- Read `CONTRIBUTING.md` for setup instructions and contribution workflow.
- Skim `AGENTS.md` and `CODE_STYLE.md` for repo‑specific conventions.
- Use `GOVERNANCE.md` (this document) as the reference for how decisions are made and how to get help when a change needs broader agreement.

==============================================================================
DOCS: Engineering Note: Scoped State, Metrics, and Limits (ENGINEERING_SCOPING)
URL: /runtime/docs/?p=ENGINEERING_SCOPING
==============================================================================

# Engineering Note: Scoped State, Metrics, and Limits

This note captures patterns for tracking metrics and enforcing limits across the runtime without introducing process‑wide behavior that can blur isolation between windows, origins, or embedded servers.

## Principles

- Avoid process‑wide global statics for counters or behavior (limits, caches) that affect runtime request handling.
- Scope state to a meaningful domain:
  - Per‑origin (e.g., `oro://com.app`) + route prefix (e.g., `/ai/llama`).
  - Per‑window when appropriate (bridge `client.id`) for finer attribution.
- Store scoped state in Services (e.g., `core::services::AI`) rather than in routes.
  - Services provide `getOrCreate(scopeKey)` APIs to retrieve state.
  - Scoped state should be atomic for hot paths; only the map lookup/insert needs a lock.

## Implementation Pattern

```cpp
// Example container
struct ServerStats {
  std::atomic<int> inflight{0};
  std::atomic<uint64_t> reqA{0}, reqB{0};
  std::atomic<long long> latASum{0}, latACount{0};
  std::atomic<int> tokens{0};
  std::atomic<long long> lastRefillMs{0};
  bool tryConsumeToken(int rps, int burst);
};

// Service state
Mutex statsMutex;
Map<String, SharedPointer<ServerStats>> stats;

SharedPointer<ServerStats> getStats(const String &scope) {
  Lock lock(statsMutex);
  if (stats.contains(scope)) return stats.at(scope);
  auto s = std::make_shared<ServerStats>();
  stats.insert_or_assign(scope, s);
  return s;
}
```

Routes:

- Build a scope key from `origin` + `prefix` (and optionally `client.id`).
- Retrieve stats once per request; update atomics in the hot path.
- Avoid heavy locks or per‑request allocations in streaming loops.

## Rate Limiting

- Use a token‑bucket per scope with steady‑clock refill (1s cadence is usually sufficient and cheap).
- Store `tokens` and `lastRefillMs` in the scoped stats; update atomics only.
- Enforce per‑scope concurrency (e.g., `inflight >= maxConcurrent`).
- Return a JSON error payload (e.g., 429/"Too Many Requests") when limits are exceeded.

## Metrics & /health

- Track counts and latency aggregates (sum + count) per scope.
- Report only the metrics for the scope serving the current request, not process‑global totals.
- Optionally include per‑window metrics alongside the aggregate origin+prefix view.
- Consider EWMA or percentiles if needed later; keep overhead minimal.

## Streaming (SSE/Chunks)

- Coalesce small writes to reduce syscall pressure.
- Track latency from start → finish for stream metrics.
- Respect cancellation; ensure resources (context, streams) are released.

## JSON Parsing & Caps

- Parse JSON bodies only when necessary and with a strict size cap (e.g., 1 MiB), falling back to query params.
- Avoid unbounded string growth; use small rolling windows for stop‑sequence detection.

## Tool‑Calling

- Do not execute arbitrary tool code in the runtime.
- Return a minimal tool_call stub (non‑stream) or a single stream chunk, then finish.
- Let applications resolve the tool function and post follow‑up prompts.

## Testing

- Add base tests that do not require external models (health/models/error paths, SSE shape, caps).
- Gate E2E tests that require a model behind env vars (e.g., `ORO_AI_MODEL_NAME` / `ORO_AI_MODEL_DIR`).

## Applying Broadly

- Where future services expose metrics/limits, follow the same scoping model (origin/prefix or window) and store the state in the appropriate Service.
- Keep hot paths atomic; lock only for map lookups/initialization.

==============================================================================
DOCS: CDP (Chrome DevTools Protocol) (CDP)
URL: /runtime/docs/?p=CDP
==============================================================================

# CDP (Chrome DevTools Protocol)


This document is the source of truth for what Oro’s CDP server:
- **Supports today** (implemented and expected to work)
- **Can support in the future** (plausible with additional runtime/engine work)
- **Will never support** (requires Chromium/V8 internals or Chrome-specific infrastructure)

## Goals

- **Connectivity-complete**: stable HTTP + WebSocket endpoints, sane errors, no crashes.
- **Tooling-complete**: enough protocol coverage for real-world Playwright/Puppeteer automation flows.
- **Safe by default**: bind to loopback by default; make “remote debugging” clearly insecure when exposed off-machine.

Non-goals:
- Full Chrome/Chromium CDP parity.
- A bundled DevTools frontend UI.

## Enabling CDP

### CLI / Desktop flag

The desktop app binary supports a Chromium-style flag:

```
--remote-debugging-port=<port>
```

- `<port> == 0` selects a random available port.
- When enabled, the runtime prints a Chrome-like line to stderr:
  - `DevTools listening on ws://127.0.0.1:<port>/devtools/browser/<browserId>`
- If the bind address is **not loopback**, the runtime prints a warning.

The `oroc` CLI forwards this flag to the app binary, so you can use the same option when launching via `oroc`.

### JavaScript API (`oro:cdp`)

Apps can start/stop/query CDP from JS:

```js
import * as cdp from 'oro:cdp'

const status = await cdp.listen({ hostname: '127.0.0.1', port: 0 })
console.log(status.httpEndpoint) // http://127.0.0.1:<port>
console.log(status.wsEndpoint)   // ws://127.0.0.1:<port>/devtools/browser/<browserId>
```

## Server endpoints

### HTTP

- `GET /json` and `GET /json/list`: returns page targets with `webSocketDebuggerUrl`.
- `GET /json/version`: returns `webSocketDebuggerUrl` plus basic version fields.
- `GET /json/protocol`: minimal schema (many tools ship their own protocol definitions).
- `GET /json/new?<url>` (also supports `?url=<url>`): creates a new window and navigates.
- `GET /json/activate/<targetId>`: attempts to focus the window for the target.
- `GET /json/close/<targetId>`: requests closing the window for the target.

### WebSocket

- `ws://<host>:<port>/devtools/browser/<browserId>`: browser session (root).
- `ws://<host>:<port>/devtools/page/<targetId>`: binds directly to a page target.

## Target model

- Each desktop window maps to a CDP `TargetInfo` with:
  - `type: "page"`
  - `browserContextId` is always present for tooling compatibility; the default context uses `default-<browserId>` and is not returned by `Target.getBrowserContexts`
- Non-default browser contexts are tracked for automation tooling:
  - `Target.getBrowserContexts` returns IDs created via `Target.createBrowserContext` (does not include default)
  - `Target.disposeBrowserContext` forgets the context and closes windows created in that context

Note: Oro currently tracks browser contexts for protocol compatibility, but does not yet guarantee Chromium-like storage/process isolation between contexts.

## Supported protocol surface (today)

Notes:
- Unknown methods in known CDP domains return `code: -32000` (`"Not supported"`). Unknown domains return `code: -32601` (`"Method not found"`).
- Any method name ending with `.enable` or `.disable` is accepted as a **no-op** unless explicitly implemented below.
- `Runtime.evaluate` / `Runtime.callFunctionOn` provide a compatibility-focused subset and do not aim to emulate Chromium/V8 evaluation semantics in full (some edge cases around multi-statement inputs may differ).
- `Runtime.executionContextCreated` includes `auxData.frameId` and `auxData.isDefault`, and isolated worlds created via `Page.createIsolatedWorld` surface as distinct execution contexts via `context.name` (required for Puppeteer/Playwright frame/world bookkeeping).
- `DOM.describeNode` includes `node.frameId` for iframe/frame elements (content frame id) and `documentElement` nodes so Puppeteer/Playwright can map handles to frames.
- Network instrumentation covers in-page `fetch`/`XMLHttpRequest` plus runtime-handled scheme requests (SchemeHandlers). This is still not full “subresource parity” with Chromium.
- Fetch interception (`Fetch.*`) supports runtime-handled scheme requests and in-page `fetch()` requests (instrumented). It does not intercept browser-network subresources and it does not currently intercept `XMLHttpRequest`.
- Input injection is implemented via in-page event synthesis (DOM/Pointer events + `element.click()` for default actions), not native OS-level input; some sites may behave differently.
- Frame model: `Page.getFrameTree` includes iframe entries discovered in the DOM, but frames do not have separate CDP sessions, and iframe execution contexts are compatibility-only (treat the top-level frame as the only fully addressable context).
- `Page.addScriptToEvaluateOnNewDocument`: scripts are applied at the start of a document load (via `readystatechange`), but this does not guarantee true Chromium “pre-page-script” semantics on all platforms.
- CDP discovery endpoints accept a trailing slash (e.g. Playwright probes `GET /json/version/`).

### Safety limits

To avoid OOMs and giant WebSocket frames, Oro applies safety caps:

- **Network response bodies**: captured for in-page `fetch`/`XMLHttpRequest` and for runtime-handled scheme responses; bounded to **5 MiB per request**. A global **20 MiB total** and **256 request** cap is applied for stored bodies used by `Network.getResponseBody`.
- **Base64 response bodies**: when a response body is binary, it is returned base64-encoded; due to encoding overhead, the `Network.getResponseBody` payload can be larger than 5 MiB even when the decoded body is within the 5 MiB cap.
- **Network request bodies (`postData`)**: captured for in-page `fetch`/`XMLHttpRequest` and runtime-handled scheme requests; bounded to **256 KiB per request**. When caps are hit, `postData` may be omitted.
- **Screenshots**: `Page.captureScreenshot` is guarded (dimensions/pixels + payload size) and may return `"Screenshot too large"` for very large pages or clips.
- **WebSocket messages**: inbound and outbound frames are capped at **32 MiB**; oversized frames will close the connection to avoid OOM.
- **IO streams**: `Fetch.takeResponseBodyAsStream` and `Network.takeResponseBodyForInterceptionAsStream` store at most **64** active streams, **20 MiB total**, and serve at most **256 KiB** per `IO.read` call.
- **`Page.addScriptToEvaluateOnNewDocument`**: bounded to **128 scripts per target**, **1 MiB per script**, and **4 MiB total** per target.
- **`Runtime.addBinding`**: bounded to **256 bindings per target**.
- **DOM snapshots**: `DOM.getDocument` / `DOM.describeNode` `depth` is clamped (max **3**); `DOM.querySelectorAll` returns at most **2048** nodeIds.
- **DOM serialization**: `DOM.getDocument` / `DOM.describeNode` are additionally capped to **4096** serialized nodes per call to avoid huge payloads.
- **`Runtime.getProperties`**: returns at most **2048** property descriptors per call.
- **Navigation history**: bounded to **128 entries per window**.
- **Telemetry**: unknown method log-dedup is bounded to **1024 unique method names** per server run.

### Implemented methods (expected to work)

- `Browser.getVersion`
- `Browser.getBrowserCommandLine` (stub: returns empty `arguments`)
- `Browser.getWindowForTarget` (bounds-only)
- `Browser.getWindowBounds` (bounds-only)
- `Browser.setContentsSize` (resize; may be ignored by platform)
- `Browser.setWindowBounds` (move/resize/windowState; platform-dependent)
- `Browser.close` (closes window `0`, which exits on most desktop builds)

- `Target.setDiscoverTargets`
- `Target.getTargets`
- `Target.setAutoAttach`
- `Target.attachToBrowserTarget` (returns a new `sessionId`)
- `Target.attachToTarget`
- `Target.detachFromTarget`
- `Target.sendMessageToTarget` (flattened sessions)
- `Target.getTargetInfo`
- `Target.createTarget`
- `Target.closeTarget`
- `Target.activateTarget`
- `Target.getBrowserContexts`
- `Target.createBrowserContext` (returns a unique id)
- `Target.disposeBrowserContext` (closes windows in that context)

- `Page.enable` (emits initial `Page.frameNavigated` for the attached target)
- `Page.navigate`
- `Page.setDocumentContent`
- `Page.getFrameTree`
- `Page.getResourceTree` (returns document + `<script src>` + `<link rel="stylesheet">` URLs discovered in DOM)
- `Page.getResourceContent` (returns main document HTML when `url` matches current page; otherwise empty content)
- `Page.getLayoutMetrics`
- `Page.getNavigationHistory`
- `Page.navigateToHistoryEntry`
- `Page.bringToFront`
- `Page.reload`
- `Page.stopLoading`
- `Page.close`
- `Page.addScriptToEvaluateOnNewDocument`
- `Page.removeScriptToEvaluateOnNewDocument`
- `Page.createIsolatedWorld` (returns an executionContextId; not true world isolation)
- `Page.captureScreenshot` (Linux/WebKitGTK only; `png` only; may reject huge pages)

- `Runtime.enable` (emits initial `Runtime.executionContextCreated` for the attached target)
- `Runtime.evaluate`
- `Runtime.callFunctionOn`
- `Runtime.getProperties`
- `Runtime.releaseObject`
- `Runtime.releaseObjectGroup`
- `Runtime.addBinding`
- `Runtime.removeBinding`
- `Runtime.runIfWaitingForDebugger` (no-op)
- `Runtime.getIsolateId` (returns a stable id for this runtime instance)

- `Log.enable` (enables `Log.entryAdded` events for console/errors)
- `Log.disable`
- `Log.clear` (no-op)

- `DOM.getDocument`
- `DOM.getOuterHTML`
- `DOM.setOuterHTML`
- `DOM.querySelector`
- `DOM.querySelectorAll`
- `DOM.getAttributes`
- `DOM.requestChildNodes` (emits `DOM.setChildNodes`)
- `DOM.setAttributeValue`
- `DOM.removeAttribute`
- `DOM.setNodeValue`
- `DOM.describeNode`
- `DOM.resolveNode`
- `DOM.getContentQuads`
- `DOM.getNodeForLocation`
- `DOM.getBoxModel`
- `DOM.scrollIntoViewIfNeeded`
- `DOM.focus`
- `DOM.getFrameOwner`
- `DOM.setFileInputFiles`

- `CSS.getComputedStyleForNode`
- `CSS.getInlineStylesForNode` (returns `style` attribute; no rule/source mapping)
- `CSS.getMatchedStylesForNode` (returns empty `matchedCSSRules`; includes `inlineStyle`)

- `Input.dispatchMouseEvent`
- `Input.dispatchKeyEvent`
- `Input.insertText`

- `Emulation.setDeviceMetricsOverride` (may resize the window on desktop)
- `Emulation.clearDeviceMetricsOverride`

- `Network.getResponseBody` (fetch/XHR, synthetic navigation HTML, and runtime-handled scheme responses)
- `Network.getRequestPostData` (fetch/XHR, plus runtime-handled scheme requests)
- `Network.setExtraHTTPHeaders` (applies to in-page `fetch`/`XMLHttpRequest` plus runtime-handled scheme requests)
- `Network.getResponseBodyForInterception` (delegates to `Network.getResponseBody`)
- `Network.takeResponseBodyForInterceptionAsStream` (IO stream; keyed by `interceptionId`)
- `Network.setBlockedURLs` (blocks in-page `fetch`/`XMLHttpRequest` plus runtime-handled scheme requests)
- `Network.setRequestInterception` (compat layer; enables `Fetch.requestPaused` + emits `Network.requestIntercepted` for the same requests)
- `Network.continueInterceptedRequest` (resolves requests paused via `Fetch.requestPaused`; supports `errorReason`, request overrides, and `rawResponse` fulfill)

- `Performance.getMetrics` (compat subset; values may be 0 on non-Chromium engines)
- `Memory.getDOMCounters` (compat subset)
- `Memory.getBrowserCounters` (compat subset)
- `Runtime.getHeapUsage` (compat subset)

- `Fetch.enable` (runtime-handled scheme requests + in-page `fetch()` (instrumented); request-stage only)
- `Fetch.disable` (same scope as `Fetch.enable`)
- `Fetch.continueRequest` (same scope as `Fetch.enable`)
- `Fetch.continueResponse` (accepted; treated like continue)
- `Fetch.fulfillRequest` (same scope as `Fetch.enable`; `body` treated as base64)
- `Fetch.failRequest` (same scope as `Fetch.enable`)
- `Fetch.continueWithAuth` (accepted; auth challenges not modeled)
- `Fetch.getResponseBody` (delegates to `Network.getResponseBody`)
- `Fetch.takeResponseBodyAsStream` (IO stream; keyed by `requestId`)

- `IO.read`
- `IO.close`
- `IO.resolveBlob` (stub: returns a UUID but does not expose blob retrieval by UUID)

### Implemented events (limited coverage)

- `Target.targetCreated`
- `Target.targetDestroyed`
- `Target.targetInfoChanged`
- `Target.attachedToTarget`
- `Target.detachedFromTarget`

- `Page.frameNavigated`
- `Page.frameStartedLoading` (synthesized)
- `Page.frameStoppedLoading` (synthesized)
- `Page.lifecycleEvent`
- `Page.domContentEventFired`
- `Page.loadEventFired`
- `Page.javascriptDialogOpening` (in-page wrappers)

- `Runtime.executionContextsCleared`
- `Runtime.executionContextCreated`
- `Runtime.bindingCalled`
- `Runtime.consoleAPICalled` (in-page wrappers)
- `Runtime.exceptionThrown` (in-page wrappers)
- `Log.entryAdded` (when `Log.enable` has been called)

- `Network.requestWillBeSent` (fetch/XHR + synthetic navigation + runtime-handled scheme requests)
- `Network.responseReceived` (fetch/XHR + synthetic navigation + runtime-handled scheme requests)
- `Network.loadingFinished` (fetch/XHR + synthetic navigation + runtime-handled scheme requests)
- `Network.loadingFailed` (fetch/XHR + runtime-handled scheme failures)
- `Network.dataReceived` (runtime-handled scheme requests only)
- `Network.requestIntercepted` (when `Network.setRequestInterception` is enabled; mirrors `Fetch.requestPaused`)

- `Fetch.requestPaused` (runtime-handled scheme requests + in-page `fetch()` (instrumented))

### No-op stubs (accepted, but currently do nothing)

- `Schema.getDomains` (returns empty)
- `Security.setIgnoreCertificateErrors`
- `Browser.grantPermissions` / `Browser.resetPermissions`
- `Browser.setDownloadBehavior`
- `Browser.cancelDownload` (no-op)
- `Animation.getPlaybackRate` / `Animation.setPlaybackRate` (stored/returned for compatibility; does not affect engine playback)
- `Overlay.*` (no-op)

- `Network.clearBrowserCache` (no-op)
- `Network.clearBrowserCookies` (no-op)
- `Network.setCacheDisabled`
- `Network.setBypassServiceWorker`
- `Network.emulateNetworkConditions`
- `Network.getCookies` (returns empty)
- `Network.setCookies` (no-op)
- `Network.deleteCookies` (no-op)
- `Storage.getCookies` (returns empty)
- `Storage.setCookies` (no-op)
- `Storage.clearCookies` (no-op)

- `Emulation.setUserAgentOverride`
- `Emulation.setTimezoneOverride`
- `Emulation.setLocaleOverride`
- `Emulation.setTouchEmulationEnabled`
- `Emulation.setFocusEmulationEnabled`

- `Page.setLifecycleEventsEnabled`
- `Page.setBypassCSP`
- `Page.setFontFamilies` (no-op)
- `Page.setInterceptFileChooserDialog`
- `Page.handleJavaScriptDialog` (no-op)
- `Page.getAppManifest` (returns empty)
- `Page.getInstallabilityErrors` (returns empty)
- `Page.captureSnapshot` (returns empty)
- `Page.startScreencast` / `Page.stopScreencast` / `Page.screencastFrameAck` (no-op)

- `Accessibility.getFullAXTree` (returns empty)
- `Accessibility.queryAXTree` (returns empty)
- `DOMSnapshot.captureSnapshot` / `DOMSnapshot.getSnapshot` (returns empty)
- `DOMDebugger.*` (returns empty)
- `CSS.getStyleSheetText` (returns empty)
- `CSS.getPlatformFontsForNode` (returns empty)
- `CSS.getMediaQueries` (returns empty)
- `CSS.collectClassNames` (returns empty)
- `CSS.startRuleUsageTracking` (no-op)
- `CSS.stopRuleUsageTracking` (returns empty)
- `Debugger.getScriptSource` (returns empty)
- `Debugger.setSkipAllPauses` (no-op)
- `Debugger.getPossibleBreakpoints` (returns empty)
- `Debugger.setBreakpointByUrl` / `Debugger.setBreakpoint` (returns empty)
- `Debugger.removeBreakpoint` / `Debugger.pause` / `Debugger.resume` / `Debugger.stepOver` / `Debugger.stepInto` / `Debugger.stepOut` (no-op)
- `Debugger.searchInContent` (returns empty)
- `Profiler.startPreciseCoverage` (no-op)
- `Profiler.takePreciseCoverage` (returns empty)
- `Profiler.stopPreciseCoverage` (returns empty)
- `Profiler.setSamplingInterval` / `Profiler.start` (no-op)
- `Profiler.stop` (returns empty)
- `Profiler.getBestEffortCoverage` (returns empty)
- `Coverage.startJSCoverage` / `Coverage.stopJSCoverage` / `Coverage.startCSSCoverage` / `Coverage.stopCSSCoverage` (no-op)
- `Coverage.takePreciseCoverage` (returns empty)
- `HeapProfiler.collectGarbage` (no-op)
- `HeapProfiler.startSampling` (no-op)
- `HeapProfiler.getSamplingProfile` (returns empty)
- `HeapProfiler.stopSampling` (returns empty)
- `Tracing.start` (no-op)
- `Tracing.end` (no-op)

### Explicitly unsupported (returns `-32000 Not supported`)

- `Page.printToPDF`
- `Runtime.queryObjects`
- `HeapProfiler.takeHeapSnapshot`
- `Extensions.loadUnpacked` / `Extensions.uninstall`
- `DeviceAccess.enable` / `DeviceAccess.selectPrompt` / `DeviceAccess.cancelPrompt`
- `Autofill.trigger`
- `ServiceWorker.*` / `BackgroundService.*` / `BackgroundFetch.*` / `Audits.*` / `Audits2.*` / `WebAuthn.*` / `WebAudio.*` / `Media.*` / `Cast.*` / `DeviceOrientation.*`

## Playwright / Puppeteer compatibility

This CDP server is intended to support:
- Puppeteer connecting via `browserWSEndpoint` or `browserURL` (HTTP endpoint).
- Playwright connecting via `chromium.connectOverCDP(<httpEndpoint>)`.

Important: Playwright’s “CDP mode” is Chromium-oriented; Oro provides a CDP-compatible surface for automation, but it is not a Chromium engine and some features may behave differently or remain stubbed.

### Expectations checklist (what tools typically do)

This section is a practical checklist of the CDP surface that Puppeteer/Playwright commonly expect during `connect()` / `connectOverCDP()` and basic automation flows.

**Connectivity / discovery**
- HTTP endpoints used by tooling: `GET /json/version`, `GET /json`, `GET /json/list`.
- Browser WS endpoint: `ws://<host>:<port>/devtools/browser/<browserId>`.
- Page WS endpoint: `ws://<host>:<port>/devtools/page/<targetId>` (some tooling/debuggers use this directly).

**Target + session model (must not surprise clients)**
- `Target.setDiscoverTargets` should emit `Target.targetCreated` for existing targets *before* responding.
- `Target.getTargets` lists current targets.
- `Target.attachToTarget` with `flatten: true` (the preferred mode) yields a `sessionId` and emits `Target.attachedToTarget` before resolving.
- `Target.setAutoAttach` is accepted (Oro does not model worker/serviceworker subtargets today).
- `Target.sendMessageToTarget` works for flattened sessions (messages are processed as if they were sent with that `sessionId`).

**“Enable” dance + initial events**
- Automation clients typically issue many `*.enable` calls; Oro accepts them as no-ops unless explicitly implemented.
- `Runtime.enable` returns `{}` and emits `Runtime.executionContextCreated` for the attached page/session.
- `Page.enable` returns `{}` and emits `Page.frameNavigated` for the attached page/session.

**Diagnostics: execution contexts**
- `Runtime.executionContextCreated.context.auxData.frameId` and `auxData.isDefault` must be present so Puppeteer/Playwright can map contexts to frames.
- `Page.createIsolatedWorld` should surface as `Runtime.executionContextCreated` with `context.name === <worldName>` (e.g. Puppeteer’s `UTILITY_WORLD_NAME`).

**Core automation primitives**
- Navigation: `Page.navigate`, `Page.reload`, `Page.stopLoading`.
- DOM querying: `DOM.getDocument`, `DOM.querySelector`, `DOM.querySelectorAll`, `DOM.describeNode`, `DOM.resolveNode`.
- JS execution: `Runtime.evaluate`, `Runtime.callFunctionOn`, `Runtime.getProperties`, `Runtime.releaseObject`, `Runtime.releaseObjectGroup`.
- Input: `Input.dispatchMouseEvent`, `Input.dispatchKeyEvent`, `Input.insertText`.

**Observability (limited)**
- `Network.*` events and `Network.getResponseBody` / `Network.getRequestPostData` cover `fetch`/`XMLHttpRequest`, synthetic navigation events, and runtime-handled scheme requests (not full subresource parity).
- Console/errors may surface as `Runtime.consoleAPICalled` / `Runtime.exceptionThrown`.

**Known sharp edges (not Chrome parity)**
- Frame model: one top-level frame per window (frameId == targetId); iframes are not separate frames/targets today.
- Request interception: `Fetch.*` is supported for runtime-handled scheme requests (SchemeHandlers) and for in-page `fetch()` requests (instrumented). It ignores non-Request stages and it does not intercept browser-network subresources.
- Deprecated interception: `Network.setRequestInterception` is supported as a compatibility layer and forwards to the same underlying interception used by `Fetch.*` (emitting `Network.requestIntercepted` for `Fetch.requestPaused` requests). It does not currently intercept `XMLHttpRequest`.

### Example: Puppeteer

```js
import puppeteer from 'puppeteer'

const browser = await puppeteer.connect({ browserURL: 'http://127.0.0.1:<port>' })
const page = (await browser.pages())[0] || await browser.newPage()
await page.goto('https://example.com')
```

### Example: Playwright

```js
import { chromium } from 'playwright'

const browser = await chromium.connectOverCDP('http://127.0.0.1:<port>')
const context = browser.contexts()[0] || await browser.newContext()
const page = context.pages()[0] || await context.newPage()
await page.goto('https://example.com')
```

## Platform notes

### Linux (WebKitGTK)

When CDP is enabled, the runtime enables WebKit automation via `webkit_web_context_set_automation_allowed(...)` (when supported) so external tooling can attach.

## Things we can support (future candidates)

These are plausible, but require additional runtime/engine integration and will be implemented as needed by real tooling usage:

- **Network observability**: `Network.*` events (request/response lifecycle, headers, timing) and cookie access.
- **Request interception**: extend `Fetch.*` beyond SchemeHandlers to cover more request sources, if we can hook at the right layer.
- **Screenshots / PDFs**: cross-platform `Page.captureScreenshot` and `Page.printToPDF` via platform webview snapshot/print APIs.
- **Window management**: improve cross-platform parity for `Browser.getWindowForTarget` / `Browser.setWindowBounds` (positioning + window state).
- **More DOM helpers**: richer `DOM.*` and `DOMSnapshot.*` surfaces for robust selector/visibility tooling.
- **Frame/iframe parity**: richer `Page.*` frame events and per-frame execution contexts (requires deeper engine integration).

## Things we will never support

These require Chromium/V8 internals or Chrome-specific infrastructure, and are not realistic to emulate faithfully in Oro’s non-Chromium engines:

- **V8 debugging & profiling parity**:
  - `Debugger.*`, `Profiler.*`, `HeapProfiler.*`, `Coverage.*` (breakpoints, stepping, heap snapshots, precise CPU/heap profiling)
- **Chrome tracing infrastructure**:
  - `Tracing.*` and Chrome’s tracing model; Oro may provide small compatibility subsets (e.g. `Performance.getMetrics`, `Memory.getDOMCounters`) but does not implement Chrome’s tracing/memory panels
- **Chromium-only target/process models**:
  - Features that depend on Chromium’s multi-process architecture (OOPIF/process-per-site semantics, Chrome-specific worker/service worker inspection models)

## Security notes

Remote debugging gives full control over the app (evaluate JS, read DOM, drive input). Treat it like an admin interface:
- Prefer `hostname: 127.0.0.1` and local-only usage.
- Do not bind CDP to non-loopback on untrusted networks.
