{
  "generatedAt": "2026-01-27T13:07:52+00:00",
  "kind": "docs",
  "count": 29,
  "items": [
    {
      "id": "start",
      "title": "Oro Runtime Documentation",
      "section": "overview",
      "summary": "Oro Runtime embeds the platform WebView and exposes native capabilities to JavaScript via high-level `oro:*` APIs.",
      "text": "Oro Runtime Documentation Oro Runtime embeds the platform WebView and exposes native capabilities to JavaScript via high-level oro: APIs. These docs are the reference for the runtime\u2019s architecture, subsystems, and integration surfaces (TLS, storage, windowing, MCP, AI, and more). Use the sidebar to browse, or search for a specific concept. Recommended reading path 1. Architecture: Oro Runtime Architecture 2. Resource loading: Navigator mounts and Conduit 3. Platform behavior: Window management and Android storage 4. Security: Secure storage and Sandbox helper 5. Networking: TLS quickstart, TLS testing, and WebView TLS pins 6. Web platform surfaces: WebUSB, Web Bluetooth, Web HID, Web OTP 7. Agent integrations: MCP server configuration and Embedded LLaMA server Contributing and source code Runtime development happens in the oro-computer/oro-runtime repository on GitHub."
    },
    {
      "id": "RUNTIME_ARCHITECTURE",
      "title": "Oro Runtime Architecture",
      "section": "architecture",
      "summary": "This document provides a detailed view of the Oro Runtime internals (with notes for legacy Socket compatibility), including its threading model, IPC pipeline, services layer, resource loading, lifecycle, and security boundaries. It is intended for contributors and advanced users integrating or extending the native runtime.",
      "text": "Oro Runtime Architecture This document provides a detailed view of the Oro Runtime internals (with notes for legacy Socket compatibility), including its threading model, IPC pipeline, services layer, resource loading, lifecycle, and security boundaries. It is intended for contributors and advanced users integrating or extending the native runtime. Contents Goals and topology Diagram index Component map Threading and event loops IPC routing and flows IPC types (class diagram) Services architecture Windows/WebView integration Resource loading and Service Worker Lifecycle model Window states (state diagram) Security and configuration Performance and reliability Extension points Directory map and anchors Known gaps and future work See also: start.md, CONDUIT.md, NAVIGATORMOUNTS.md, TLSQUICKSTART.md, TLSTESTING.md, WEBVIEWTLSPINS.md Goals Unified, lean native runtime powering cross\u2011platform desktop and mobile. Rich JS APIs via custom schemes and a resilient IPC bridge. Deterministic dispatching: isolate UI/main thread work from loop work. Modular native services with feature gating and explicit lifecycles. Safe defaults: scheme isolation, optional filesystem sandbox, CORS/CSP knobs. Component Map graph LR subgraph JS[JS Layer (ESM APIs)] A1[api/bootstrap.js] A2[api/ipc.js] A3[api/fs/] A4[api/dgram.js] A5[api/window.js] end subgraph WV[WebView] B1[Preload Hooks] B2[window <-> bridge] end subgraph BR[Bridge] C1[SchemeHandlers ipc: oro: node:] C2[Router] C3[Navigator + Mounts] end subgraph RT[Runtime Core] D1[loop::Loop (libuv)] D2[context::Dispatcher] D3[context::RuntimeContext] D4[core::Services] D5[window::Manager] D6[serviceworker::Server/Container] end JS -- fetch ipc:// --> C1 JS -- import oro:/node: --> C1 C1 -- route --> C2 C2 -- invoke --> D4 D4 -- callbacks --> C2 C2 -- reply (send/eval) --> B2 B2 --> JS D5 <--> WV D2 -. UI/Main thread dispatch .-> WV D1 -. uvasync / loop thread .-> D4 C3 -- resolve() --> C1 C1 <-- dev/prod resources --> C3 C3 --> D6 Diagram Index Component Map: overview of JS, WebView, Bridge, Runtime, Services Threading Model: UI/main vs loop thread dispatch IPC Request/Response: standard request path IPC Streaming: SSE/chunked flows IPC Types: class diagram for key IPC types Oro Scheme Resolution: end-to-end request path with Service Worker fallback Permissions/Event Emission: system event propagation to JS Runtime Lifecycle: high-level runtime state machine Window States: window manager status transitions Rendering Diagrams Preview in Markdown: most editors (VS Code with Mermaid) render Export SVG locally: npm run docs:diagrams (writes to build/diagrams). Export PNG locally: npm run docs:diagrams:png. CI artifacts: a GitHub workflow renders diagrams on pushes/PRs touching docs and uploads them as an artifact named runtime-diagrams. Threading and Event Loops The runtime separates concerns between: loop thread: libuv\u2011based work, timers, IO; runs callbacks enqueued via Loop::dispatch(). UI/main thread: platform WebView and windowing; accessed via context::Dispatcher. background threads: optional worker threads spawned by services (e.g., process, UDP) and platform internals. Key primitives src/runtime/loop/loop.cc: backing libuv loop, uvasynct for dispatch, platform integration. src/runtime/context/dispatch.cc: platform\u2011specific marshaling to UI/main thread. flowchart LR subgraph UI[UI/Main Thread] U1[WebView + Window] U2[Dispatcher::dispatch(cb)] end subgraph UV[Loop Thread] L1[Loop::dispatch(cb)] L2[uvasynct] L3[Run Queue] end U1 <-- synchronous UI work --> U2 L1 --> L2 --> L3 --> U1 U2 --> platform invoke U1 classDef main fill:#eef,stroke:#88f classDef loop fill:#efe,stroke:#8b8 class U1,U2 main class L1,L2,L3 loop Platform specifics Linux: integrates uvbackendfd with GTK main loop via GSource (prepare/check/dispatch); see src/runtime/loop/loop.cc. Apple: loop may run on a dedicated thread; UI work is dispatchsync onto main queue. Windows: dispatcher uses WMAPP posts targeting the captured main thread; queued until notifyReady(); see src/runtime/context/dispatch.cc. Android: posts through the JVM/Looper to the activity thread. Loop states None \u2192 Init \u2192 Idle \u2194 Polling \u2192 Paused/Stopped \u2192 Shutdown. Loop::dispatch() transitions to Polling while draining queue; resumes Idle afterward. IPC Routing and Flows The bridge installs custom scheme handlers in the WebView. The JS layer performs IPC by issuing HTTP\u2011like requests to ipc:// with a JSON body; results are sent back via evaluateJavaScript() or streamed via queued responses. Main types src/runtime/ipc.hh: ipc::Message, ipc::Result, ipc::Router. src/runtime/bridge/bridge.cc: scheme handlers, coalesced SSE/chunk writes, JavaScript resolution. Basic request/response sequenceDiagram participant JS as JS (api/ipc.js) participant WV as WebView (ipc:) participant BR as Bridge::Router participant SV as Service JS->>WV: fetch(\"ipc://service.method?seq=123\", body) WV->>BR: SchemeHandlers::Request BR->>BR: parse Message(uri) BR->>SV: router.invoke(message, body, cb) SV-->>BR: Result(Data Err) BR-->>WV: Response 200/4xx with JSON WV-->>JS: Promise resolve/reject Queued responses and streaming Queued body: service sets QueuedResponse{body,length,headers}, bridge serializes minimal JS to resolve client when the renderer pulls the queue. SSE: QueuedResponse::eventStreamCallback emits text/event-stream events; bridge coalesces small writes for efficiency. Chunked: QueuedResponse::chunkStreamCallback emits chunked transfer; bridge buffers to 16KB threshold before writes. sequenceDiagram participant JS as JS (EventSource) participant WV as WebView (ipc:) participant BR as Bridge participant SV as Service JS->>WV: GET ipc://events (Accept: text/event-stream) WV->>BR: Request BR->>SV: router.invoke(...) SV-->>BR: Result{ queuedResponse.eventStreamCallback } BR-->>WV: 200 + headers (SSE) loop Until finished SV-->>BR: event(name,data,false) BR-->>WV: write SSE frame (coalesced) end SV-->>BR: event(,,true) BR-->>WV: finalize Oro scheme resolution (detailed) sequenceDiagram participant WV as WebView (oro:) participant BR as Bridge.oro-handler participant SW as ServiceWorker Container participant NV as Navigator.resolve() participant FS as Filesystem Resource WV->>BR: GET oro://<bundle>/path alt SW registered and allowed BR->>SW: container.fetch(req) SW-->>BR: response (200/other) BR-->>WV: send response else No SW match or 404 BR->>NV: resolve(path, resourcesDir) alt Redirect BR-->>WV: 302 Location else Mount NV-->>BR: mount filename BR->>FS: read file FS-->>BR: data + mime BR-->>WV: 200 + headers + body else Resource NV-->>BR: app resource BR->>FS: read file FS-->>BR: data + mime BR-->>WV: 200 + headers + body end end Cancellation WebView cancels pending requests (navigation, network abort); SchemeHandlers::RequestCallbacks.cancel triggers MessageCancellation if provided. Windows note WebView2 may buffer custom\u2011scheme bodies; incremental delivery of SSE/chunked responses is not guaranteed. Services Architecture Services expose native capabilities and map IPC routes to API semantics. Key pieces src/runtime/core/services.hh: registry and lifecycle. Service examples: FS, DNS, Timers, UDP, OS, Process, SQLite, NetworkStatus, Notifications, MediaDevices, Geolocation, TLS, Diagnostics, AI. SQLite depends on the amalgamation staged at build/sqlite/sqlite3.c; bin/install.sh (and CI bootstrap) should run bin/fetch-sqlite.sh or set SQLITESOURCEDIR before building. Each service gets context, dispatcher, loop, and manages its own handles and observers. Lifecycle core::Services::start()/stop() called by runtime::Runtime on resume/pause/stop. Feature gating enables/disables specific services by build/user config. Concurrency patterns Long\u2011running or blocking operations are scheduled on the loop thread. UI\u2011bound work (dialogs, permission prompts) marshaled via dispatcher.dispatch(). libuv handles must be closed explicitly; prefer uvclose(handle, cb) where state needs cleaning. Windows and WebView Integration Window lifecycle and lookup src/runtime/window/manager.cc: indexed manager tracks windows and their status transitions (NONE \u2192 CREATED \u2192 SHOWN/HIDDEN \u2192 CLOSING \u2192 EXITING). Each window owns a bridge::Bridge, which owns Navigator and SchemeHandlers. Manager can resolve windows by bridge, webview, or client id. Bridge responsibilities src/runtime/bridge/bridge.cc: inject preload, set up scheme handlers (ipc, oro, node) route IPC to services; marshal results to JS (resolve/emit) coalesce SSE and chunked writes integrate Service Worker proxying for oro: origin WebView custom schemes (src/runtime/webview.hh) SchemeHandlers::Request/Response wrap platform handles and headers/body. Platform typedefs unify Apple/Linux/Windows/Android request/response types. Navigator maintains origin, mounts, resolution logic and can block/allow navigation. Resource Loading and Service Worker Module and asset delivery paths oro: scheme Serves packaged app assets or dev resources directory. Honors webviewdefaultindex fallback when resolving. Supports SPA fallback when enabled via webviewallowanyroute = true (unmatched routes fall back to the default index, typically /index.html). Integrates with Service Worker Server when registration exists for origin. node: scheme Proxies allowed Node core module imports to packaged shims /oro/<module>.js. Produces an ESM proxy module ensuring a canonical module instance URL. flowchart TB WV[WebView] -- oro://<bundle>/... --> BR[Bridge] BR --> SW{Service Worker registered?} SW -- yes --> SWC[serviceworker::Container.fetch] SW -- no --> RES[Resolve to resource/mount] SWC --> RSP[Response] RES --> RSP RSP --> WV Permissions and event emission sequenceDiagram participant OS as OS/Platform Permission participant SV as Service (e.g., Notifications) participant BR as Bridge participant WV as WebView participant JS as JS (window) OS-->>SV: permission change / event SV-->>BR: observer callback(JSON) BR->>WV: evaluateJavaScript(emit(name, data)) WV-->>JS: dispatch event in page Service Worker Server src/runtime/serviceworker/server.cc creates a hidden headless window per origin when needed; toggled by OROSERVICEWORKERDEBUG env. Streams and fetch path are coordinated via bridge maps (swPending, swActive). Lifecycle Model High\u2011level app events are emitted to windows via window::Manager.emit() and bridged to JS (mirrors host window activation/minimize). stateDiagram-v2 [] --> Init Init --> Idle: start() Idle --> Polling: loop work Idle --> Paused: pause() Paused --> Init: resume() Idle --> Stopped: stop() Stopped --> Shutdown: destroy() Window States (state diagram) stateDiagram-v2 [] --> WINDOWNONE WINDOWNONE --> WINDOWCREATED: createWindow() WINDOWCREATED --> WINDOWSHOWN: show() WINDOWCREATED --> WINDOWHIDDEN: headless WINDOWSHOWN --> WINDOWHIDDEN: hide() WINDOWHIDDEN --> WINDOWSHOWN: show() WINDOWSHOWN --> WINDOWCLOSING: close() WINDOWCLOSING --> WINDOWCLOSED WINDOWCLOSED --> WINDOWEXITING: exit(code) WINDOWCLOSED --> WINDOWKILLING: kill() WINDOWEXITING --> WINDOWEXITED WINDOWKILLING --> WINDOWKILLED Platform mapping summary iOS/macOS/Android/Windows/Linux map activation/background/terminate to applicationpause/applicationresume/applicationstop events. On desktop, native pause/resume is opt\u2011in (lifecycledesktopalwaysrunning = false). File watchers are stopped on pause; recreate on applicationresume as needed. Security and Configuration Boundaries Scheme isolation: only registered schemes are allowed; node: restricts module list. JS only gains native capabilities through IPC routes, which consult permissions/config. Optional filesystem sandbox and symlink restrictions. Key config (oro.toml or env overrides) Filesystem sandbox: filesystemsandboxenabled, FSSANDBOX=1. No\u2011follow symlinks: filesystemnofollowsymlinks, FSNOFOLLOW=1. WebView headers: webviewcsp, webviewreferrerpolicy, webviewcors. Lifecycle desktop behavior: lifecycledesktopalwaysrunning. Service Worker debug: OROSERVICEWORKERDEBUG. Performance and Reliability Event/write coalescing SSE: coalesce small events before flush to reduce per\u2011frame overhead. Chunked: buffer chunks to 16KB before write to reduce syscall pressure. Libuv loop shutdown (src/runtime/loop/loop.cc) Ensure uvstop + uvrun(NOWAIT), close async handle, repeatedly try uvloopclose, walk/close remaining handles, retry, with small sleeps to yield; avoids leaks/hangs on shutdown. Dispatch correctness UI work must go through context::Dispatcher to avoid thread affinity bugs. On Windows, dispatcher captures main thread id, posts WMAPP messages, and queues until notifyReady(). Handle lifecycle Prefer uvclose(handle, callback) when state updates are needed; avoid relying on nulling pointers. Extension Points Add a new service 1. Create src/runtime/core/services/<name>.hh/.cc exposing IPC\u2011level methods with signatures (const ipc::Message::Seq&, Params..., Callback). 2. Register routes in src/runtime/ipc/routes.cc mapping \"<service>.<method>\" to service calls. 3. Add feature flag in core::Services::Features and include in lifecycle start()/stop(). 4. Expose JS surface under api/ (and update api/index.d.ts). Add an IPC route Map in ipc::Router::map(name, callback) or via routes.cc. Use dispatcher for UI\u2011bound actions and loop.dispatch for loop\u2011bound work. Serve custom content Register a new scheme via SchemeHandlers.registerSchemeHandler(\"myscheme\", handler) in the bridge (or extend platform registration if needed). Integrate a Service Worker behavior Extend serviceworker::Container and fetch handling; use bridge swPending and swActive maps for streaming coordination. Directory Map and Anchors Loop and Dispatch src/runtime/loop/loop.cc src/runtime/context/dispatch.cc Bridge and IPC src/runtime/bridge.hh src/runtime/bridge/bridge.cc src/runtime/ipc.hh src/runtime/ipc/message.cc src/runtime/ipc/router.cc src/runtime/ipc/routes.cc WebView and Windowing src/runtime/webview.hh src/runtime/window/manager.cc src/runtime/window/\\.cc .mm .kt .cc (platforms) Services src/runtime/core/services.hh src/runtime/core/services/\\.cc .hh Service Worker src/runtime/serviceworker/server.cc src/runtime/serviceworker/\\.cc Runtime Container src/runtime/runtime.hh JS surface (ESM proxies and APIs) api/.js and api/.d.ts api/ipc.js (IPC client), api/\\ for service surfaces Known Gaps and Future Work Tighten timers ownership and ensure consistent uvclose semantics across services. Validate Windows dispatcher end\u2011to\u2011end scenarios and lifecycle edge cases. Audit window manager read locks and enumerations for thread safety. Recreate FS watchers on resume with helper utilities. Windows WebView2 buffering: evaluate alternative strategies for streaming (e.g., WebSocket/SSE polyfills) when the custom oro: scheme is buffered. Appendix: Example Sequence Annotations Queued response script injection src/runtime/context/context.cc creates a small JS program that notifies the renderer of queued response IDs so the JS side can fetch payloads/bodies lazily. Node core module proxying src/runtime/bridge/bridge.cc generates an ESM proxy to the canonical oro://.../oro/<module>.js path to ensure a single module instance across import URLs. Service Worker server window src/runtime/serviceworker/server.cc spawns a hidden window per origin; toggled by env; ensures consistent SW lifecycle and debugging hooks. IPC Types (class diagram) classDiagram class ipc::Message { +bytes::BufferQueue buffer +Client client +URL uri +String seq +bool isHTTP } class QueuedResponse { +ID id +uint64t ttl +SharedPtr<byte[]> body +sizet length +http::Headers headers +EventStreamCallback +ChunkStreamCallback } class ipc::Result { +Message message +String seq +JSON::Any value +http::Headers headers +QueuedResponse queuedResponse } class ipc::Router { +map(name, cb) +invoke(Message, body, cb) +listen(name, cb) +unlisten(name, token) } class bridge::Bridge { +SchemeHandlers schemeHandlers +Navigator navigator +ipc::Router router +bool send(seq, json, qr) +bool emit(name, json) } class webview::SchemeHandlers { +registerSchemeHandler(scheme, handler) +handleRequest(Request, cb) } class webview::Navigator { +Location location +configureWebView(wv) +resolve(path, dir) } ipc::Router <-- bridge::Bridge webview::SchemeHandlers <-- bridge::Bridge webview::Navigator <-- bridge::Bridge ipc::Result --> QueuedResponse ipc::Result --> ipc::Message"
    },
    {
      "id": "NAVIGATOR_MOUNTS",
      "title": "Navigator Mounts",
      "section": "architecture",
      "summary": "The navigator mounting system lets you expose host file system directories to the webview so that `fetch`, `<img>`, `<video>`, navigation, and other URL-based requests can read live files without bundling them into the application. Each mount maps a host directory to a virtual root under the app's `oro://<bundle id>` origin, so in-page navigation behaves like a regular static file server while still honouring the runtime's security policies.",
      "text": "Navigator Mounts The navigator mounting system lets you expose host file system directories to the webview so that fetch, <img>, <video>, navigation, and other URL-based requests can read live files without bundling them into the application. Each mount maps a host directory to a virtual root under the app's oro://<bundle id> origin, so in-page navigation behaves like a regular static file server while still honouring the runtime's security policies. Configuration Mounts are declared in oro.toml under [webview.navigator.mounts]. Each entry takes the form <host path> = <navigator base path>. [webview.navigator.mounts] $HOSTHOME/.oro/navigator/example = /navigator linux/srv/shared/assets = /shared mac$HOSTCONTAINER/Resources = /app-bundle Key conventions Host aliases: $HOSTHOME, $HOSTCONTAINER, $HOSTPROCESSWORKINGDIRECTORY, ~, and $HOME expand to platform-specific directories. Platform targeting: Prefix a key with mac, win, linux, ios, or android to enable the mount only on that platform. The prefix is removed after matching the current platform. Navigator paths should begin with / and may omit the trailing slash. They are compared against incoming request paths using a simple prefix test. Aliases are resolved before the path is canonicalised, so you can point at network shares or other absolute paths once expanded. Changes to src/cli/templates.hh sync into api/CONFIG.md via npm run gen. URL Resolution Semantics When a webview requests oro://<bundle-id>/navigator/foo, the runtime resolves the path using the following rules (mirroring how bundled resources behave): 1. Check for an explicit file (foo). 2. Check for a directory containing index.html; requesting /navigator/foo will redirect to /navigator/foo/ for GET requests if that index exists. 3. As a convenience, resolve foo.html if present. If the request matches a mount, the resolved host file path is served. Otherwise the runtime falls back to packaged resources (/index.html, defaultindex, or SPA fallback when allowanyroute is enabled) after giving registered service workers a chance to respond. Security Model Navigator mounts participate in the runtime's sandbox and entitlements: filesystem::Resource::isMountedPath whitelists mounted directories so they can be opened without triggering macOS security-scoped bookmarks. When the macOS sandbox is enabled (macsandbox != false), any $HOSTHOME-based mounts are added to the generated entitlements automatically. On Linux, each mount is injected into the WebKit sandbox via webkitwebcontextaddpathtosandbox so the renderer can read mounted files directly. The filesystem sandbox (filesystemsandboxenabled) still applies: requests are denied with SecurityError if they escape the declared mount roots or recognised well-known paths. Behavioural Notes Mount resolution is case-sensitive on Unix-like systems and case-preserving on Windows\u2014follow the host file system's semantics when authoring URLs. Service workers see the mounted responses exactly as if they were bundled resources, so they can cache or intercept them as usual. Mounted directories are read-only from the webview's perspective; write operations must use the runtime fs APIs and target the host path directly. Example Workflow 1. Create a host directory and initial content: mkdir -p \"$HOME/.oro/navigator/example\" echo \"Hello from host\" > \"$HOME/.oro/navigator/example/hello.txt\" 2. Declare the mount in oro.toml: [webview.navigator.mounts] $HOSTHOME/.oro/navigator/example = /navigator 3. Reference it from the webview: <img src=\"/navigator/hello.txt\" alt=\"Mounted content\" /> Repository Example The examples/navigator-mounts demo scaffolds a mount at $HOSTHOME/.oro/navigator-mounts and shows how to: Populate the host directory using the runtime's fs module when bootstrapping the app. List mounted files and stream their contents through fetch. Toggle between bundled assets and mounted assets to compare behaviours. Build the examples bundle and run the navigator-mounts entry to try it out: npm run relink oroc build examples oroc run examples --entry navigator-mounts/index.html (Replace oroc build/oroc run with your usual workflow if you already have the examples app linked.)"
    },
    {
      "id": "CONDUIT",
      "title": "Conduit Transport",
      "section": "architecture",
      "summary": "Conduit is the Oro Runtime-managed binary channel used for high-frequency or low-latency communication between JavaScript and the native services. It complements the request/response style `ipc://` bridge by exposing a WebSocket endpoint that stays open across the runtime lifetime, reuses a single framing format, and avoids work on the UI thread whenever possible.",
      "text": "Conduit Transport Conduit is the Oro Runtime-managed binary channel used for high-frequency or low-latency communication between JavaScript and the native services. It complements the request/response style ipc:// bridge by exposing a WebSocket endpoint that stays open across the runtime lifetime, reuses a single framing format, and avoids work on the UI thread whenever possible. The transport is implemented in runtime::core::services::Conduit and surfaced to JavaScript through the oro:conduit module (api/conduit.js). Modules such as UDP, TLS, AI streaming, and future high-throughput features should attempt to use Conduit first, falling back to ipc.send/ipc.write only when the socket is unavailable. Lifecycle When the runtime boots, the Conduit service launches a local WebSocket server bound to an ephemeral port. The port, hostname, and optional shared key are exported to JavaScript via globalThis.args.conduit. Conduit.port tracks the current server port. The helpers Conduit.status() and Conduit.waitForActiveState() let code query or await activation. Instances (new Conduit({ id })) register themselves in an internal pool. The pool is used when the application is paused or resumed: hooks.onApplicationPause stops the server and marks every client inactive. hooks.onApplicationResume restarts the server, updates the known port, and calls reconnect() on clients that opted in (shouldReconnect = true). The WebSocket URL is ws://localhost:<port>/<client-id>/<top-window-id>?key=<sharedKey>. The shared key is optional and can be updated at runtime via Conduit.setSharedKey(). Conduit emits standard DOM events (open, message, error, close). Reconnects dispatch a synthetic reopen event so higher layers can resume subscriptions after the socket returns. Message Framing All messages are binary Uint8Array payloads with a compact header section. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Byte Offset \u2502 Meaning \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 0 \u2502 Number of headers (uint8) \u2502 \u2502 1..n \u2502 Repeated header entries \u2502 \u2502 \u2502 - key length (uint8) \u2502 \u2502 \u2502 - key bytes (UTF-8) \u2502 \u2502 \u2502 - value length (uint16 BE)\u2502 \u2502 \u2502 - value bytes (UTF-8) \u2502 \u2502 n+1..n+2 \u2502 Payload length (uint16 BE) \u2502 \u2502 rest \u2502 Payload bytes \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Values in the header section are decoded back into JavaScript primitives. Strings matching true, false, or null return the corresponding primitive; decimal strings are converted to numbers. The payload is exposed as a Uint8Array and is left untouched. Recommended header keys include route (identifies the native handler), port, address, and any other domain-specific metadata consumers need to interpret the payload. JavaScript API Overview Static helpers: Conduit.status() \u2192 { port, isActive, sharedKey } Conduit.diagnostics() \u2192 runtime level stats (active handles, count) Conduit.waitForActiveState({ maxQueriesForStatus }) \u2192 resolves when the server reports isActive. Conduit.getSharedKey() / Conduit.setSharedKey() Instance methods and patterns: new Conduit({ id, sharedKey }) immediately attempts to connect. Instances keep themselves alive with GC finalizers; call close() to opt out and prevent reconnects. connect(callback) establishes the WebSocket and resolves once the open event fires. The callback receives an Error if the attempt fails. reconnect({ retries, timeout }) wraps connect() in an exponential backoff loop (default: 32 retries, capped at 30s delay). A successful reconnection dispatches a reopen event. receive(handler) registers a message callback (handler(error null, { options, payload })). Only one receive handler is active at a time; calling receive replaces the previous hooks. send(options, payload?) frames the provided metadata and optional payload. It returns false when the socket is paused, disconnected, or otherwise unusable. Callers should treat a false return as a signal to enter their fallback path and trigger reconnect(). close() prevents further reconnects, removes event listeners, and severs the WebSocket if one is active. Integration Guidelines 1. Prefer Conduit for streaming workloads. For example, UDP uses it to start/stop reads and deliver datagrams without blocking ipc:// handlers. 2. Set up receive before issuing commands. In modules that expect inbound data (message events, AI streaming segments, etc.), register the receive handler immediately after constructing the Conduit instance. 3. Gracefully degrade. If send() returns false, log the failure, invoke any module-specific fallback (ipc.send/ipc.write), and call conduit.reconnect().catch(() => {}) to restore the preferred transport in the background. 4. Handle reopen. When the transport reconnects the runtime dispatches a reopen event. Reissue any outstanding subscriptions (e.g., udp.readStart) inside this handler so delivery resumes without requiring user action. 5. Pause/Resume aware. During application pause events the transport is torn down intentionally. Modules should expect a burst of error/close events and rely on the reopen path to restart delivery when the app resumes. 6. Keep IDs stable. The id passed to new Conduit({ id }) is part of the WebSocket routing path and is used server-side to demultiplex clients. Reusing the same ID across reconnects allows the native side to resume stateful streams cleanly. Diagnostics and Troubleshooting Enable DEBUG=conduit to surface verbose logs during development. The transport logs connection attempts, retries, and failures. Conduit.diagnostics() aggregates runtime statistics, including active handles and the IDs currently subscribed. Use internal.conduit.status/stop/start (via ipc.request) for low-level testing or when running in headless environments. A false return from send() indicates the WebSocket is not open. Check whether the application is paused (hooks.onApplicationPause currently sets a global flag) or whether the shared key is out of sync. Related Reading api/conduit.js \u2013 JavaScript implementation and hooks. src/runtime/core/services/conduit.cc \u2013 native service and client management. api/dgram.js \u2013 example of a module that mixes Conduit and IPC pathways for resilience."
    },
    {
      "id": "TAR_API",
      "title": "Tar Archive API (`oro:tar`)",
      "section": "apis",
      "summary": "The `oro:tar` module exposes a small, robust API for working with tar archives from JavaScript. It is designed for very large archives, supports random access, and can be backed either by files on disk (optionally `mmap`-backed on supported platforms) or in-memory buffers.",
      "text": "Tar Archive API (oro:tar) The oro:tar module exposes a small, robust API for working with tar archives from JavaScript. It is designed for very large archives, supports random access, and can be backed either by files on disk (optionally mmap-backed on supported platforms) or in-memory buffers. At a high level: Archives on disk are opened via the native tar service and indexed once. Individual entries are read on demand via range reads (streaming decode). New archives are written entry-by-entry via chunked body writes (streaming encode). In-memory archives are backed by a single buffer and use the same reader/index. Importing import as tar from 'oro:tar' // or: // import { TarArchive, open, create, fromBuffer } from 'oro:tar' Opening archives tar.open(path, options?) Opens an existing archive on disk. tar.create(path, options?) Creates (or truncates) an archive for writing. tar.fromBuffer(buffer) Opens a read\u2011only archive backed by a Buffer, Uint8Array, or ArrayBuffer. All helpers return a TarArchive instance. const archive = await tar.open('./assets.tar', { mmap: true }) const entries = await archive.entries() const logo = await archive.read('images/logo.png') TarOpenOptions: writable?: boolean \u2013 set true to open a file for writing (implied by create). mmap?: boolean \u2013 hint that the runtime may mmap very large archives when opening them read\u2011only on supported platforms. uid?: number \u2013 optional global uid metadata for writers. gid?: number \u2013 optional global gid metadata for writers. uname?: string \u2013 optional global uname metadata for writers. gname?: string \u2013 optional global gname metadata for writers. mtime?: number \u2013 optional global mtime metadata for writers (seconds since UNIX epoch). TarArchive TarArchive represents an open archive descriptor in the runtime: TarArchive.open(path, options?) TarArchive.create(path, options?) TarArchive.fromBuffer(buffer) Properties: id: string \u2013 stable descriptor id (for IPC only). path: string \u2013 resolved path for file\u2011backed archives (empty for buffers). writable: boolean \u2013 whether the archive was opened for writing. mmap: boolean \u2013 whether the runtime was asked to use mmap. size: number \u2013 total archive size in bytes (for indexed archives). entryCount: number \u2013 number of indexed entries. closed: boolean \u2013 true after close() succeeds. finalized: boolean \u2013 true after finalize() succeeds (writers only). Metadata and random access archive.entries(): Promise<TarEntryStat[]> Returns metadata for all indexed entries in the archive. archive.stat(path: string): Promise<TarEntryStat> Returns metadata for a single entry, or throws if not found. TarEntryStat: path: string linkpath?: string \u2013 present for symlink/hardlink entries. devmajor?: number \u2013 present for char/block device entries. devminor?: number \u2013 present for char/block device entries. sparse?: { offset: number, length: number }[] \u2013 present for sparse file entries (data regions only). size: number mode: number mtime: number (seconds since UNIX epoch) uid: number gid: number uname?: string gname?: string kind: 'file' 'directory' 'symlink' 'hardlink' 'block-device' 'char-device' 'fifo' 'other' isFile: boolean isDirectory: boolean The native reader builds an in\u2011memory index at open time for random access. For very large archives with many entries, this trades O(entryCount) memory for O(1) lookups by path. The reader supports PAX (x/g), GNU longname/longlink (L/K), and GNU sparse entries (old GNU S format, plus PAX GNU.sparse. variants). Reading archive.read(path, options?): Promise<Buffer> Reads a slice of an entry into a single Buffer. archive.readStream(path, options?): AsyncIterableIterator<Buffer> Provides a streaming view over an entry, yielding chunks as Buffers. TarReadOptions: offset?: number \u2013 starting byte offset (default 0). length?: number \u2013 number of bytes to read (defaults to size - offset). signal?: AbortSignal timeout?: number \u2013 per\u2011request timeout in milliseconds. TarReadStreamOptions: highWaterMark?: number \u2013 max chunk size in bytes (default 65536). start?: number \u2013 starting byte offset (default 0). end?: number \u2013 inclusive end offset (defaults to entry.size - 1). signal?: AbortSignal timeout?: number Example (streaming decode): const chunks = [] for await (const buf of archive.readStream('dir/streamed.txt', { highWaterMark: 64 1024 })) { chunks.push(buf) } const full = Buffer.concat(chunks) Attempting to read a directory entry will throw an error with code EISDIR. Sparse file holes are synthesized as zero bytes when reading or streaming. When extracting sparse files to disk, the runtime attempts to preserve holes by writing only the sparse data regions. Writing Writing is only allowed for archives opened with create (or open with { writable: true }): archive.append(header, body, options?): Promise<void> archive.finalize(): Promise<void> TarEntryHeader: path: string \u2013 entry path within the archive. linkpath?: string \u2013 required when kind is 'symlink' or 'hardlink'. devmajor?: number \u2013 required when kind is 'char-device' or 'block-device'. devminor?: number \u2013 required when kind is 'char-device' or 'block-device'. size?: number \u2013 total body size in bytes; required when body is an async iterable. sparse?: { offset: number, length: number }[] \u2013 sparse data regions for sparse file entries (sorted, non-overlapping). sparseSize?: number \u2013 logical size of the sparse file entry (defaults to the end of the last region). mode?: number \u2013 file mode (defaults to 0o644 for files and 0o755 for directories). mtime?: number \u2013 modification time in seconds (defaults to the archive global mtime if set, otherwise current time). uid?: number \u2013 optional uid metadata (overrides archive global uid for this entry). gid?: number \u2013 optional gid metadata (overrides archive global gid for this entry). uname?: string \u2013 optional uname metadata (overrides archive global uname for this entry). gname?: string \u2013 optional gname metadata (overrides archive global gname for this entry). kind?: TarEntryKind \u2013 entry type (defaults to 'file'). Bodies can be: Buffer Uint8Array ArrayBuffer AsyncIterable<Buffer Uint8Array> For link entries (kind: 'symlink' 'hardlink'), linkpath must be provided and the entry body must be empty (pass null or an empty buffer). For non-file entries (kind: 'directory' 'symlink' 'hardlink' 'fifo' 'char-device' 'block-device'), the entry body must be empty and header.size (if provided) must be 0. For device entries (kind: 'char-device' 'block-device'), devmajor and devminor must be provided. When using an async iterable, header.size must be provided and match the total number of bytes yielded; otherwise the append is rejected. For non\u2011stream bodies (Buffer/Uint8Array/ArrayBuffer), if header.size is provided it must match the body length; mismatches are rejected rather than padded or truncated implicitly. Sparse file entries can be written by providing header.sparse. The entry body must contain only the stored data regions (concatenated in order), and header.size/body length must equal the sum of region lengths. The resulting entry reports size === sparseSize when read back. All sizes and offsets are JavaScript numbers and must be safe integers (<= 2^53 - 1). Sparse maps are capped to 16384 regions to keep PAX metadata within supported limits. TarWriteOptions: signal?: AbortSignal timeout?: number Example (single buffer): await archive.append( { path: 'foo.txt', mode: 0o644 }, Buffer.from('hello world') ) Example (streaming encode): async function body() { yield Buffer.from('chunk-1-') yield Buffer.from('chunk-2') } await archive.append( { path: 'dir/streamed.txt', size: 15 }, body() ) await archive.finalize() finalize() writes the terminating tar blocks and flushes the underlying sink. After finalization, the archive descriptor remains open, but additional writes should not be attempted. Extracting entries TarArchive exposes convenience helpers for writing entry contents to disk using a streaming pipeline: archive.extract(path, destPath, options?): Promise<void> This method: Resolves path within the archive. For file entries, streams contents via TarArchive.readStream and writes to destPath using fs.createWriteStream, handling backpressure and respecting signal/timeout when provided. For directory entries, creates destPath as a directory. For symlink entries, creates a symlink at destPath pointing to the entry's linkpath. For hardlink entries, creates a hardlink at destPath pointing to the entry's linkpath when the target is available at the computed destination root. Other special entries ('fifo', 'char-device', 'block-device') are not materialized by this helper. Attempts to preserve mode and mtime metadata when supported by the underlying platform/filesystem. When requested, it will also attempt to preserve owner metadata and special mode bits. Example: const archive = await tar.open('./assets.tar') await archive.extract('images/logo.png', './out/logo.png') await archive.close() To extract all file and directory entries into a directory: const archive = await tar.open('./assets.tar') await archive.extractAll('./out/assets') await archive.close() extractAll accepts an optional filter(entry) callback which can be used to select which entries to materialize. Directory entries are created explicitly when present in the archive so empty directories can be preserved. By default extractAll only materializes file and directory entries. To also extract symlink and hardlink entries, pass { preserveLinks: true }. Other special entries ('fifo', 'char-device', 'block-device') are skipped. extractAll and extract refuse to traverse existing symlinks within the destination directory tree when creating output paths. extractAll and extract options: preserveOwner?: boolean \u2013 attempt to apply uid/gid via chown/lchown (may require privileges; may be ignored by platform). preserveSpecialModes?: boolean \u2013 when true, preserves mode bits beyond 0o777 (setuid/setgid/sticky) when supported. In-memory archives TarArchive.fromBuffer and the top\u2011level tar.fromBuffer helper open a read\u2011only archive backed by an in\u2011memory buffer: const raw = await fs.promises.readFile('./assets.tar') const archive = await tar.fromBuffer(raw) const logo = await archive.read('images/logo.png') await archive.close() Buffers are not copied when already a Buffer. Uint8Array and ArrayBuffer inputs are coerced to a Buffer once up front; the native service then holds a shared reference for the lifetime of the archive descriptor. This path is useful for: Update artifacts downloaded into memory (see APPLICATIONUPDATEPROTOCOL.md). Embedding asset bundles in higher\u2011level protocols without touching disk. Writable in-memory archives can be created via tar.createInMemory(options). These archives behave like any other writable TarArchive instance (they support append, finalize, entries, stat, read, etc.) but their contents are kept in memory and can be retrieved as a Buffer using archive.toBuffer(): const archive = await tar.createInMemory({ uid: 1000, uname: 'alice' }) await archive.append({ path: 'mem.txt' }, Buffer.from('in-memory tar payload')) const buf = await archive.toBuffer() // buf now contains a complete tar archive; it can be persisted or // reopened via tar.fromBuffer(buf) Large archives and mmap For file\u2011backed archives: The native reader uses 64\u2011bit offsets internally and can index very large archives (subject to platform limits and available memory). When mmap: true is passed and supported, the runtime may map the entire archive into memory and satisfy reads via simple memcpy, avoiding repeated pread calls. Entry headers and payloads are validated so that header + body + padding never exceed the underlying archive size; malformed archives are rejected. Very large entry sizes that do not fit in the standard octal field are encoded and decoded using the base\u2011256 extension supported by many tar implementations. Random access is implemented via a per\u2011archive index: TarArchive.open/fromBuffer build an index of path -> entry mappings. Reads (read/readStream) use the index to locate the entry and issue a single range read for each requested slice. For extremely large archives with many entries, this index will dominate memory usage. In those cases, prefer: Streaming decode via readStream for individual entries. Keeping a single long\u2011lived TarArchive open instead of repeatedly opening and closing the same file. Conduit and streaming The tar service uses standard IPC routes: tar.open, tar.openBuffer, tar.createBuffer, tar.close tar.list, tar.stat, tar.read tar.write.begin, tar.write.data, tar.finalize tar.buffer The oro:tar module wraps these routes and uses the shared IPC helpers (ipc.request, ipc.write) so it works seamlessly with Conduit\u2011backed transports. Callers should use the high\u2011level TarArchive API rather than invoking the routes directly unless they are implementing lower\u2011level tools."
    },
    {
      "id": "WINDOW_MANAGEMENT",
      "title": "Window Management",
      "section": "platform",
      "summary": "This guide covers common window operations available in Oro Runtime across desktop and mobile platforms (legacy Socket terminology is noted where users may still encounter it).",
      "text": "Window Management This guide covers common window operations available in Oro Runtime across desktop and mobile platforms (legacy Socket terminology is noted where users may still encounter it). APIs live under oro:window and are typically used via an ApplicationWindow instance returned from oro:application helpers. Quick Start Get current window: const win = await application.getCurrentWindow() Focus/Blur (desktop/mobile): await win.focus() / await win.blur() Always On Top (desktop): await win.setAlwaysOnTop(true) const onTop = await win.isAlwaysOnTop() Context Menu (native, desktop): await win.setContextMenu({ value: 'Menu:\\n Foo: f;' }) Examples Focus and blur current window import application from 'oro:application' const win = await application.getCurrentWindow() await win.blur() await win.focus() Always on top (desktop) import application from 'oro:application' const win = await application.getCurrentWindow() await win.setAlwaysOnTop(true) console.log(await win.isAlwaysOnTop()) // -> true await win.setAlwaysOnTop(false) Targeted context menu for a specific window (desktop) import application from 'oro:application' const child = await application.createWindow({ index: 2, path: 'examples/window/secondary.html', title: 'Secondary' }) await child.setContextMenu({ value: 'Menu:\\n Foo: f;', targetWindowIndex: child.index }) Platform Notes Desktop: focus, blur, and Always On Top map to native window manager features. Mobile: focus/blur map to show/hide; Always On Top is not supported. See also api/window.js (ApplicationWindow) api/application.js (createWindow, getWindow(s)) examples/kitchen-sink (interactive demo)"
    },
    {
      "id": "ANDROID_STORAGE",
      "title": "Android Storage Defaults",
      "section": "platform",
      "summary": "Oro Runtime scopes all Android file access to the app\u2019s private storage (legacy Socket behavior is still honored during the transition) unless you explicitly broker additional locations. The native bootstrap wires the following directories when the activity starts:",
      "text": "Android Storage Defaults Oro Runtime scopes all Android file access to the app\u2019s private storage (legacy Socket behavior is still honored during the transition) unless you explicitly broker additional locations. The native bootstrap wires the following directories when the activity starts: Root directory \u2013 Context.getExternalFilesDir(null); falls back to Context.getFilesDir() when the scoped \u201cexternal\u201d directory is unavailable. Cache directory \u2013 Context.getExternalCacheDir() with an internal cache fallback. Media directory \u2013 Context.getExternalMediaDirs().first() when present, otherwise externalFilesDir/media. Temporary directory \u2013 subdirectory of the scoped cache: externalCacheDir/BUNDLEIDENTIFIER. All directories are created eagerly so IPC consumers can assume they exist. Implications Path lookups that historically resolved to /sdcard/... now land inside the app sandbox (~/ maps to the scoped root above). Code that needs to expose files outside the sandbox must go through the Storage Access Framework (SAF) or an explicit document tree grant. Build scripts and tests should avoid hardcoding /sdcard paths; rely on App.getRootDirectory() or the well-known directories exposed by the runtime. No additional runtime permissions are required for these scoped locations on Android 10+; broader media access still depends on the config-driven READMEDIA/READEXTERNALSTORAGE permissions."
    },
    {
      "id": "background-services",
      "title": "Background Services Architecture",
      "section": "platform",
      "summary": "Applications need to run JavaScript work while the UI is suspended or the process is in the background. This document proposes a cross-platform background service subsystem that gives developers a worker-like JavaScript context hosted by platform-native primitives:",
      "text": "Background Services Architecture Overview Applications need to run JavaScript work while the UI is suspended or the process is in the background. This document proposes a cross-platform background service subsystem that gives developers a worker-like JavaScript context hosted by platform-native primitives: Android \u2014 Android Service (foreground optional) driven by WorkManager jobs. iOS / iPadOS \u2014 BGTaskScheduler (BGProcessingTask/BGAppRefreshTask) runners. Desktop \u2014 headless webview contexts owned by the runtime. The goal is a single JavaScript surface that hides platform differences while still exposing enough scheduling controls to satisfy entitlement-driven flows (notably iOS). Goals Provide a simple JS API for defining one-off or long-lived background services. Ensure service lifecycle can be managed from configuration (oro.toml) so iOS static declarations are respected. Allow services to communicate with the foreground runtime via existing IPC primitives. Minimise platform-specific code duplication and reuse the existing runtime service infrastructure. Support graceful degradation when a platform does not allow persistent execution. Non-Goals Replace existing ServiceWorker/SharedWorker APIs. Guarantee infinite background execution on platforms with strict limits (iOS). Provide UI surfaces; background services are headless. JavaScript API Module New module api/background.js exposing: import background from 'oro:background' await background.register({ id: 'sync-notifications', entry: 'background/notifications.js', trigger: { type: 'interval', minimumInterval: 15 60 1000, }, keepAlive: false, permissions: ['notifications', 'network'], }) await background.schedule('sync-notifications') API surface: register(options) \u2014 declare a background service. Persists definition in runtime state. schedule(id, overrides?) \u2014 request execution respecting platform rules. cancel(id) \u2014 cancel pending runs. status(id) \u2014 retrieve last run metadata. Background scripts behave like dedicated workers: Use self.postMessage, self.addEventListener('message', ...). Access to a restricted API surface identical to worker threads plus any explicitly granted permissions. Receive lifecycle events (activate, run, abort, complete) dispatched via runtime:events. IPC Integration api/background.js communicates over ipc.request('background:'). The runtime service translates registration into platform-specific schedulers. Foreground contexts can subscribe to background events via ipc.subscribe('background:events'). Configuration Extend oro.toml with a [background] namespace. Example: [background] enabled = true defaultentry = background/index.js [background.service.syncnotifications] entry = background/notifications.js required = ios trigger.type = interval trigger.minimuminterval = 900000 keepalive = false permissions = notifications,network Key points: enabled gates the entire subsystem. defaultentry used when JS registers without an explicit entry. Each [background.service.<id>] block pre-declares a service (needed for iOS so BGTaskScheduler identifiers exist at build time). required = ios enforces that builds targeting that platform must provide the service (fails fast during build). Additional platform-specific overrides live under [background.service.<id>.platform.<platform>]. npm run gen will surface typings for the JS API; configuration changes require updates to the config parser (new slice config.background). Runtime Architecture Core Service Add core::BackgroundService to src/runtime/core/services.cc. Responsibilities: Persist registered services in core::state. Coordinate scheduling requests across platforms. Launch headless JavaScript isolates using the existing bridge (Runtime::dispatcher and javascript::createJavaScript). Route postMessage traffic (background \u2194 foreground). Emit service lifecycle events to JS observers. Execution Model Each run creates a BackgroundExecution instance: Owns a libuv loop pinned to the runtime loop (desktop) or platform thread (Android/iOS). Bootstraps with background/runtime.js to patch the worker environment. Applies permission gating before exposing modules (leveraging existing Services toggles). Enforces run timeout (configurable default 30 minutes; platform-specific minimums apply). Background runs reuse the existing queued-response infrastructure (runtime/context/context.cc) for IPC serialization. State Management Extend core::state storage with background-service/<id>.json entries storing metadata (triggers, last run, failure counts). Synchronise with config overrides on boot; runtime rejects registrations not whitelisted by config when required is set. Platform Notes Android Implement BackgroundService extending android.app.Service. Use WorkManager for deferred/scheduled work; ForegroundService when keepAlive = true. Spin up a headless runtime via existing bootstrap (Runtime::Options with hidden window manager). Tie lifecycle to onStartCommand; completion stops service unless scheduling recurring work. Respect Doze/App Standby by marking network requests as NetworkType.CONNECTED when needed. iOS / iPadOS Register task identifiers from config during app launch (BGTaskScheduler.shared.register). Support two trigger types: processing \u2192 BGProcessingTaskRequest. refresh \u2192 BGAppRefreshTaskRequest. Background execution spins up a lightweight runtime inside the app process (no separate extension). The headless webview (WKWebView) loads oro:background. Provide helper in bin/generate-plist to inject PermittedBackgroundTaskSchedulerIdentifiers. Enforce configuration: if a service is marked required = ios and not scheduled, warn during build. Desktop (macOS, Windows, Linux) Add HeadlessWebView to src/runtime/window for hidden contexts. Background executions hosted in that headless view, sharing the same process and IPC loop. Scheduling: interval triggers emulate timers via existing timers service. on-demand runs triggered only when JS calls schedule. Persisted alarms survive restarts via core::state. Shared Behaviour postMessage and message events mirrored through the dispatcher. Graceful cancellation when foreground requests cancel. Debug logging gated by debugbackground config. Metrics recorded via diagnostics (success/failure counters). Implementation Phases 1. Scaffolding Add config parser support and runtime service skeleton. Implement JS module stubs returning Unimplemented errors on unsupported platforms. 2. Desktop Headless Runner Introduce headless webview execution and IPC. Provide integration tests under test/src/background. 3. Android Service Integration Implement Android service/WorkManager binding. Validate with instrumentation tests (npm run test:android). 4. iOS Background Tasks Hook BGTaskScheduler, update build scripts for plist generation. Add simulator coverage (npm run test:ios-simulator scenario). 5. Developer Experience Ensure npm run gen produces typings and docs. 6. Polish Add metrics, logging, timeout handling. Harden permission gating and failure retries. Testing Strategy Unit: new runtime service tests covering registration validation and state persistence. Integration: Oro runner suites verifying message passing and timeout behaviours (legacy Socket suites still run until the deprecation window closes). Platform: Android instrumentation verifying WorkManager scheduling and service restart. iOS simulator tests using BGTaskScheduler debug APIs. Desktop headless tests ensuring timers survive pause/resume. Manual: sample app demonstrating notifications sync in the background. Open Questions Should background services share the same JS bundle cache as foreground windows? How aggressively should we retry failed runs on iOS where background time is scarce? Do we expose platform-specific scheduling hints (e.g., requiresExternalPower) directly, or keep them in config only?"
    },
    {
      "id": "SECURE_STORAGE",
      "title": "Secure Storage",
      "section": "security",
      "summary": "Oro Runtime provides a cross-platform secure storage service that keeps key/value pairs in the native credential stores. Data written through this API is backed by the platform keystore (Keychain on Apple platforms, Credential Manager on",
      "text": "Secure Storage Oro Runtime provides a cross-platform secure storage service that keeps key/value pairs in the native credential stores. Data written through this API is backed by the platform keystore (Keychain on Apple platforms, Credential Manager on Windows, libsecret on Linux, and the Android Keystore). import { setItem, getItem, removeItem, clear, keys } from 'oro:secure-storage' const scope = 'oro://com.example.my-app' // Store sensitive data await setItem('refresh-token', 'secret', { scope }) const token = await getItem('refresh-token', { scope }) // Enumerate known keys for the scope const storedKeys = await keys({ scope }) // Remove data when it is no longer needed await removeItem('refresh-token', { scope }) // Or clear the scope entirely await clear({ scope }) Scopes Keys live inside a scope which should be an origin-style string (for example oro://com.example.app). When no scope is provided the runtime uses the default origin of the current application window. Encodings setItem accepts strings, Uint8Array, ArrayBuffer, or Buffer instances. getItem returns strings by default and can return binary data when { encoding: 'buffer' } is supplied. Platform notes Linux backends depend on libsecret-1; if the library is unavailable the API will reject with an informative error. Android values are encrypted with an AES-GCM key stored in the platform keystore and then persisted using app-private shared preferences."
    },
    {
      "id": "SANDBOX_HELPER",
      "title": "Sandbox Helper Implementation Plan",
      "section": "security",
      "summary": "1. **Privileged Helper Binary (`oro-helper`)** - Installed system-wide, owned by root (or platform equivalent). - Responsible for opening privileged resources, managing policy, and spawning sandboxed child processes. 2. **Zygote Process**",
      "text": "Sandbox Helper Implementation Plan Goals & Scope Allow Oro Runtime apps to access USB and other privileged resources without running as root. Provide a reusable, least-privilege service that works across all desktop targets (Linux, macOS, Windows). Mirror Chromium\u2019s security posture: central privileged broker + sandboxed child processes with per-user permissions. Support multiple apps concurrently, with policy controls that can restrict per-app capabilities when needed. Ship with tooling that keeps developer ergonomics: once installed, oroc build -r (and similar flows) just work. High-Level Architecture 1. Privileged Helper Binary (oro-helper) Installed system-wide, owned by root (or platform equivalent). Responsible for opening privileged resources, managing policy, and spawning sandboxed child processes. 2. Zygote Process A long-lived child of the helper that preloads runtime code and listens for spawn requests from user-facing tools. Forks lightweight sandboxed processes for each launched app. 3. IPC Layer UNIX domain sockets (Linux/macOS) and named pipes (Windows) for communication between CLI/runtime and helper. Uses authenticated, versioned messages (CBOR/JSON/Protocol Buffers) plus descriptor passing where available. 4. Policy & Capability Engine Defines which device classes, VID/PIDs, network ports, or filesystem paths are permitted. Future-ready for per-app manifests or signed capability tokens. 5. Logging & Observability Helper writes to system log (journald, Unified Logging, Windows Event Log). Optional structured audit trail for privileged operations. Client Entry Points & Authentication Shared bootstrap shim is linked into the runtime so oroc build -r, oroc run, and directly-invoked packaged apps all follow the same handshake before touching privileged APIs. Helper publishes one IPC endpoint per user/session. Filesystem ACLs gate access, and the helper verifies peer identity (SOPEERCRED on Linux, audittokent on macOS, ImpersonateNamedPipeClient or GetNamedPipeClientProcessId on Windows) before servicing requests. Clients send an app identifier (bundle ID or executable hash) during handshake so per-app policy can be enforced independent of launch path. Developer mode (opt-in via local policy) relaxes signing checks for unsigned builds while still enforcing UID/SID verification. Shared Implementation Phases 1. Research & Prototype (Milestone A) Verify descriptor passing for libusb on each platform. Spike a minimal helper that opens a USB node and echoes data from an unprivileged client. 2. Helper Core (Milestone B) Implement helper binary with argument parsing, privilege drop, policy hooks, logging skeleton. Define IPC protocol (OpenDevice, SpawnProcess, ReleaseHandle, Quit). 3. Zygote & Sandbox (Milestone C) Embed runtime bootstrap: helper forks zygote, zygote preloads runtime libs, forks per-app processes. Apply sandboxing (namespaces/seccomp, posixspawnattr, Windows Job Objects). 4. Platform Services Integration (Milestone D) Linux: setuid helper packaging, udev rule install, oro-helper --ensure bootstrap integration. macOS: launchd plist, SMJobBless installer, entitlement management. Windows: service registration, installer scripts (MSI/Inno), service control shim. 5. CLI & Runtime Adaptation (Milestone E) Extend oroc CLI to detect helper status, auto-start services, and request capabilities. Update runtime IPC layer to request USB descriptors via helper before initializing libusb. 6. Security Review & Hardening (Milestone F) Threat modeling, code audit, fuzzing IPC parser, privilege-dropping verification. Document escalation paths and incident response. 7. Developer Experience & Testing (Milestone G) Automated integration tests for helper lifecycle. End-to-end tests for USB enumeration via helper on each platform. Docs, troubleshooting guides, and logging instructions. Subsequent phases can iteratively add other privileged capabilities (low-number ports, system config writes, etc.) once USB support is stable. Descriptor Passing Fallback Strategy Prefer native descriptor/handle passing (libusbwrapsysdevice, macOS IOKit connections, Windows DuplicateHandle). If descriptor passing fails, transparently downgrade to a brokered transfer API where the helper executes ControlTransfer, BulkTransfer, InterruptTransfer, and hotplug notifications on behalf of the client, using correlation IDs to pair responses. Handshake records which mode is active; clients emit telemetry so we can track fallback usage. Integration tests should exercise both code paths to prevent regressions. Linux Plan Permissions Model Ship a udev rule (e.g., /lib/udev/rules.d/80-oro-usb.rules) tagging supported device classes: SUBSYSTEM==\"usb\", MODE=\"0660\", TAG+=\"uaccess\", TAG+=\"seat\", GROUP=\"orousb\" TAG+=\"uaccess\" allows systemd-logind to grant per-session ACLs automatically. Optional group (orousb) provides compatibility for non-systemd environments; helper\u2019s installer creates the group and adds users on request. Helper Deployment Install helper binary at /usr/lib/oro/oro-helper with mode 4755 (setuid root). Installation script: Copies helper, bootstrap shim, and supporting configs. Creates runtime directories (/run/oro-helper), noting they live on tmpfs and may be recreated at boot. Installs udev rule, reloads via udevadm control --reload. Optionally adds user to orousb group for non-logind hosts. No systemd unit is required; the helper is invoked on demand by CLI or app bootstrap. A lightweight oro-helper --ensure command can daemonize a broker if we want it resident. Helper Runtime On invocation, helper: 1. Verifies it is running as setuid root and performs self-integrity checks (hash/signature). 2. Ensures /run/oro-helper exists (recreating it on tmpfs as needed) and that a per-user broker process is running; if not, forks a small root-owned parent (oro-helperd) that stays resident and opens privileged resources (udev monitor, libusb context). 3. Parent drops all ambient capabilities except the minimal set required for device I/O (target: CAPDACREADSEARCH + CAPDACOVERRIDE, pending validation during Milestone A/B) and sets PRSETNONEWPRIVS. 4. Parent spawns/refreshes a per-user zygote process (running as the calling user) and creates /run/oro-helper/<uid>.sock (mode 0600, owned by user). 5. Subsequent invocations short-circuit to a control message (oro-helper --ping) that confirms broker health. Descriptor passing: Root broker opens /dev/bus/usb/<bus>/<dev> with ORDWR. Uses sendmsg + SCMRIGHTS to hand the fd to the requesting child process through the per-user socket. Child wraps the fd in libusb via libusbwrapsysdevice. Sandbox & Process Lifecycle Use user and mount namespaces, PID namespace when possible. Apply seccomp filter allowing required syscalls (dup, read, write, ioctl, etc.). Child processes run under original user UID/GID, not helper UID. Broker tracks all outstanding descriptors; on disconnect, closes fd and notifies clients. CLI Integration oroc build -r: 1. Executes oro-helper --ensure (via bootstrap shim) to spawn/refresh the broker and zygote for the current user. 2. Connects to /run/oro-helper/<uid>.sock; if handshake fails, prints actionable remediation. 3. Uses IPC SpawnProcess to launch or attach to the app\u2019s runtime process after the bootstrap shim connects. oroc helper status: Invokes oro-helper --status to query broker version, uptime, loaded policy. Standalone apps ship with the same shim and automatically call oro-helper --ensure on startup. Testing & Diagnostics Unit tests for IPC message parsing and policy evaluation (run as part of npm run test:runtime-core). Integration tests may use systemd-run --user (when available) or setsid/custom launchers to simulate clean sessions. Troubleshooting doc: helper logs to syslog/journald with the oro-helperd ident, so journalctl -t oro-helperd (or /var/log/oro-helperd.log if rsyslog writes there); additionally getfacl /dev/bus/usb/, oroc helper doctor. macOS Plan Helper Deployment Use SMJobBless to install a privileged helper at /Library/PrivilegedHelperTools/com.oro.helper. Launchd plist (/Library/LaunchDaemons/com.oro.helper.plist) starts the helper on demand. CLI oroc helper install triggers SMJobBless, requiring an admin consent prompt (standard macOS UX). Helper Runtime Helper listens on launchd-managed UNIX socket (/var/run/oro-helper/<uid>.sock). After accepting a connection: Reads the client audittokent to confirm the caller UID matches the launch session. Validates code signature (SecCodeCopyGuestWithAttributes) against the Oro Runtime maintainer certificates; developer mode (toggled via local policy) allows unsigned builds while still checking the caller UID. Uses AuthorizationExternalForm to ensure the caller is the logged-in user. Zygote uses posixspawn with posixspawnattrsetflags to enter sandbox profiles (Seatbelt). Profiles live under /Library/Application Support/Oro/runtime-sandbox.sb. Testing & Diagnostics Integration tests using launchctl kickstart -k system/com.oro.helper. Debug command: log show --predicate 'subsystem == \\\"com.oro.helper\\\"' --last 1h. Windows Plan Permissions Model Install a Windows Service (OroHelperService) running as LocalSystem. Service keeps device DACLs locked down and relies on brokered handles so only approved processes can touch devices. Maintain per-session named pipe endpoints (\\\\\\\\.\\\\pipe\\\\oro-helper-<SessionId>). Helper Deployment Provide MSI/Inno installer performing: Copy of helper binaries to %ProgramFiles%\\\\Oro\\\\helper. Service registration (sc create OroHelperService binPath= ... start= auto). Installation of WinUSB drivers if required (pnputil /add-driver). Firewall rule adjustments if helper exposes network diagnostics. CLI oroc helper install uses Start-Process -Verb RunAs to trigger installer or leverages elevate.exe. Logging & Diagnostics Service logs to Windows Event Log under Application source OroHelper. Provide oroc helper status that queries service state with QueryServiceStatusEx. Troubleshooting: Get-WinEvent -LogName Application where ProviderName -eq 'OroHelper'. Policy & Configuration Policy file (/etc/oro/policy.json, %ProgramData%\\\\Oro\\\\policy.json, /Library/Application Support/Oro/policy.json). Schema: { \"version\": 1, \"capabilities\": { \"usb\": { \"allow\": [{ \"vid\": \"0x1234\", \"pid\": \"\" }, { \"class\": \"cdc\" }] }, \"ports\": { \"allow\": [22, 443] }, \"fs\": { \"allow\": [\"/var/lib/oro/runtime\"] } } } Helper loads policy at startup, reloads on SIGHUP / platform equivalent. CLI commands to manage policy (oroc helper policy add-usb --vid 0x1234 --pid 0x0001). Developer Workflow Prerequisite: run sudo oroc helper install on Linux, oroc helper install with admin prompt (macOS/Windows). During development: oroc build -r connects to helper, spawns sandboxed process, and requests USB descriptors. Logs accessible via oroc helper logs --follow (wraps platform log readers). For hot reload, zygote keeps runtime libs warm; rebuilds only restart child process. Packaged apps launched directly (outside the CLI) rely on the same bootstrap shim: on startup the binary finds the user IPC endpoint, performs the handshake, and either requests a fresh sandboxed process or binds to an existing one as dictated by policy. Open Questions & Follow-Ups Confirm libusb descriptor wrapping works on macOS/Windows helper \u2192 child handoff, or plan for proxying calls. Determine per-app trust model (signed manifests vs. user prompts). Evaluate need for GUI prompts when new devices are accessed. Assess integration with mobile runtimes (Android/iOS) for parity. This plan should be revised after Milestone A prototypes validate descriptor passing and sandbox mechanics on each platform."
    },
    {
      "id": "TLS_QUICKSTART",
      "title": "TLS Quickstart (Experimental)",
      "section": "networking",
      "summary": "1. Build-time provider selection: - Linux desktop defaults to **mbedTLS**. - To build with **OpenSSL** instead, set `ORO_TLS_BUILD_PROVIDER=openssl` (or `ORO_TLS_ENABLE_OPENSSL=1`) when building the runtime. - `ORO_TLS_BUILD_PROVIDER=gnutls` is currently rejected because there is no backend implementation under `src/runtime/tls`.",
      "text": "TLS Quickstart (Experimental) Linux desktop defaults to the vendored mbedTLS backend (built by bin/install.sh). The OpenSSL backend is an optional build-time alternative (desktop only). Other targets currently build with no TLS provider unless you opt into OpenSSL (or provide a dynamic provider module). GnuTLS, SecureTransport, and platform Android TLS providers are not implemented in this repository yet. Enabling TLS 1. Build-time provider selection: Linux desktop defaults to mbedTLS. To build with OpenSSL instead, set OROTLSBUILDPROVIDER=openssl (or OROTLSENABLEOPENSSL=1) when building the runtime. OROTLSBUILDPROVIDER=gnutls is currently rejected because there is no backend implementation under src/runtime/tls. 2. Runtime selection: OROTLSPROVIDER can select a provider at runtime when multiple providers are available (e.g., via dynamic provider modules). With the current single-provider build model, OROTLSPROVIDER must match the compiled provider (or tls.connect will return NOTIMPLEMENTED). export OROTLSPROVIDER=mbedtls # or: openssl You can confirm the active provider at runtime from JavaScript: import as tls from 'oro:tls' const { provider } = await tls.getTlsProvider() console.log('TLS provider:', provider) 3. Manual OpenSSL flags (when pkg-config is unavailable): export OROTLSCFLAGS=\"-I/path/to/include\" export OROTLSLDFLAGS=\"-L/path/to/lib -lssl -lcrypto\" Client API (oro:tls) import { connect } from 'oro:tls' const socket = connect({ host: 'example.com', port: 443, servername: 'example.com', // SNI/hostname (defaults to host) rejectUnauthorized: true, // default true alpnProtocols: ['h2', 'http/1.1'], // optional minVersion: 'TLSv1.2', // optional maxVersion: 'TLSv1.3' // optional }) socket.on('secureConnect', () => { socket.write('GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n') }) socket.on('data', (buf) => { console.log(Buffer.from(buf).toString('utf8')) }) socket.on('error', (err) => console.error('TLS error:', err)) Trust and Verification rejectUnauthorized defaults to true. When enabled: If ca PEM is provided, it is used as the trust store. Otherwise, the runtime attempts to load the system CA bundle on Linux; if unavailable, verification fails. Hostname (SNI) is set to servername host and must match the certificate. On verification failure, the error will include a code with a canonical value such as: HOSTNAMEMISMATCH CERTUNTRUSTED CERTUNTRUSTEDROOT CERTEXPIRED CERTNOTTIMEVALID CERTREVOKED CRLEXPIRED CRLUNTRUSTED CERTNOTPERMITTED CERTBADSIGNATUREALG CERTBADSIGNATURE CERTBADPUBLICKEY CERTBADKEY or CERTIFICATEVERIFYFAILED TLS Pinning (Runtime TLS) The runtime TLS service supports strict leaf-certificate pinning via the tlspins configuration key and the oro:tls JavaScript API. Pins are evaluated after the TLS handshake completes: If pins are configured for a host, the connection succeeds only when the peer leaf certificate\u2019s SHA\u2011256 digest matches one of the configured pins. Pinning is enforced even when rejectUnauthorized: false. When rejectUnauthorized: true (default), both certificate verification and pin matching must succeed. Configuration (oro.toml) Pins are declared as a newline\u2011separated list of entries: [tls] pins = \"\"\" example.com sha256/BASE64DIGEST api.example.test sha256/OTHERBASE64DIGEST \"\"\" Alternatively, in TOML you can use a string array: [tls] pins = [ \"example.com sha256/BASE64DIGEST\", \"api.example.test sha256/OTHERBASE64DIGEST\", ] Each non-empty, non-comment line has the form: <host> <pin> [<pin>...] <host> may be a hostname, hostname:port, [ipv6]:port, or a URL; any scheme/path/query/fragment is ignored and any :port suffix is normalised away (pins apply to the host, not a specific port). <pin> is either sha256/<base64> or just <base64> (always interpreted as SHA\u2011256). <base64> may be standard Base64 or Base64URL (using - and ), with or without padding. Hosts are matched case-insensitively. Lines may include comments starting with # or ; (trailing content is ignored). Computing a pin From a remote server (uses OpenSSL): HOST=example.com PORT=443 openssl sclient -connect \"${HOST}:${PORT}\" -servername \"${HOST}\" </dev/null 2>/dev/null \\ openssl x509 -outform der \\ openssl dgst -sha256 -binary \\ openssl base64 -A Or from JavaScript (DER or PEM): import as tls from 'oro:tls' // await tls.createTlsPinFromCertificateDer(derBytes) // await tls.createTlsPinFromCertificatePem(pemString) Runtime API import as tls from 'oro:tls' await tls.setTlsPins( [ 'example.com sha256/BASE64DIGEST', 'api.example.test sha256/OTHERBASE64DIGEST', ], { mode: 'append' } // or 'replace' ) const { value } = await tls.getTlsPins() console.log(value) setTlsPins() validates entries and throws when the host or pin tokens are invalid. If you use IPC directly (tls.setPins), invalid entries are rejected with err.code = TLSPINSINVALID. Per-host helpers If you want to manage pins for a single host without rewriting the entire config string: import as tls from 'oro:tls' await tls.setTlsPinsForHost('example.com', ['sha256/BASE64DIGEST']) await tls.addTlsPinsForHost('example.com', ['sha256/NEXTBASE64DIGEST']) await tls.removeTlsPinsForHost('example.com', ['sha256/OLDBASE64DIGEST']) // Remove the host entry entirely: await tls.removeTlsPinsForHost('example.com') const { configured, pins } = await tls.getTlsPinsForHost('example.com') console.log({ configured, pins }) Per-connection pins connect() also accepts per-connection pin overrides: import { connect } from 'oro:tls' connect({ host: 'example.com', port: 443, // pins can be a list of pin tokens (auto-associated with servername host), // or full '<host> <pin>' lines. pins: ['sha256/BASE64DIGEST'], // 'append' (default) merges with global tlspins; 'replace' uses only pins above. // If pins is omitted/blank, global tlspins still apply. pinsMode: 'replace', // rejectUnauthorized: false, // optional: rely on pins without CA validation }) Invalid pins input throws a TypeError before any network I/O occurs. With pinsMode: 'replace', pins must include at least one pin that applies to servername host. On pin failure, the error includes: code: PINMISCONFIGURED PINUNAVAILABLE PINMISMATCH provider: mbedtls openssl schannel auto peerPin: sha256/<base64> (when available) expectedPins: string[] On success, the secureConnect event payload also includes peerPin (when available) and provider, which is useful for logging and pin rotation. Mutual TLS Provide cert and key in PEM format to enable client authentication. If the private key is encrypted, pass keyPassphrase (or passphrase) alongside key; this is supported for both connect() and createServer(). ALPN, Versions, and Ciphers alpnProtocols: e.g., ['h2', 'http/1.1'] (order matters) minVersion, maxVersion: 'TLSv1.2' 'TLSv1.3' (if supported by the provider) ciphers: numeric cipher IDs as hex strings (e.g., ['0x1301']) Notes Handshake and record I/O are non-blocking and integrated with libuv; both client and server APIs are available via oro:tls. Builds that do not compile a TLS provider will surface NOTIMPLEMENTED errors from the IPC routes. For WebView TLS certificate pinning (WebKit/WebView/WebView2), see docs/WEBVIEWTLSPINS.md."
    },
    {
      "id": "TLS_TESTING",
      "title": "TLS Testing Guide",
      "section": "networking",
      "summary": "This guide shows how to run the experimental TLS tests (examples use Linux tooling) with either the OpenSSL or mbedTLS provider, and how to decrypt captures in Wireshark using the key\u2011log file. The same environment variables apply on macOS/Windows; supply platform-specific compiler/linker flags as needed.",
      "text": "TLS Testing Guide This guide shows how to run the experimental TLS tests (examples use Linux tooling) with either the OpenSSL or mbedTLS provider, and how to decrypt captures in Wireshark using the key\u2011log file. The same environment variables apply on macOS/Windows; supply platform-specific compiler/linker flags as needed. Prerequisites Build toolchain: gcc/g++ (C++20), make, pkg-config Libraries (Ubuntu/Debian names): Core GUI/runtime: libwebkit2gtk-4.1-dev, libgtk-3-dev, libdbus-1-dev, libsoup-3.0-dev TLS provider (choose one): OpenSSL: libssl-dev mbedTLS: libmbedtls-dev Optional: xvfb (for CI headless runs), wireshark (for capture/decrypt) Install example (Ubuntu): sudo apt-get update sudo apt-get install -y \\ build-essential pkg-config \\ libwebkit2gtk-4.1-dev libgtk-3-dev libdbus-1-dev libsoup-3.0-dev \\ libssl-dev # or: libmbedtls-dev Environment Enable TLS and pick a provider: export OROENABLETLS=1 export OROTLSPROVIDER=openssl # or: mbedtls On macOS/Windows/mobile targets, provide build flags if pkg-config is unavailable: export OROTLSCFLAGS=\"-I/path/to/include\" export OROTLSLDFLAGS=\"-L/path/to/lib -lssl -lcrypto\" # adjust for your TLS provider Optional: write TLS key log lines for Wireshark decryption: export OROTLSKEYLOG=/tmp/sslkeys.txt or, per invocation: oroc run --tls-keylog=/tmp/sslkeys.txt --test=\u2026 oroc build --tls-keylog=/tmp/sslkeys.txt \u2026 When using encrypted private keys in tests, pass the matching keyPassphrase (or passphrase) field alongside the PEM. Run the tests 1. Echo + ALPN + mTLS oroc run --test=test/src/tls/echo.js 2. Negative scenarios oroc run --test=test/src/tls/negative.js Expected results echo.js Self-signed echo succeeds when rejectUnauthorized:false and negotiates alpnProtocol: 'http/1.1'. CA-trusted echo succeeds with rejectUnauthorized:true and negotiates alpnProtocol: 'http/1.1'. mTLS echo succeeds when server requestCert:true and client supplies cert/key. negative.js Missing CA path fails; error may include code such as CERTUNTRUSTED or CERTIFICATEVERIFYFAILED. Hostname mismatch fails (HOSTNAMEMISMATCH or CERTIFICATEVERIFYFAILED). Server requires client cert, client omits it \u2192 handshake fails. Wireshark decryption (OpenSSL provider) 1. Ensure OROTLSKEYLOG is set to a writable path (see Environment above). 2. In Wireshark: Preferences \u2192 Protocols \u2192 TLS \u2192 set \u201c(Pre)-Master-Secret log filename\u201d to the keylog path. 3. Capture filters (ports used by tests): tcp port 30443 or tcp port 30444 or tcp port 30445 or tcp port 30446 or tcp port 30447 or tcp port 30448 4. Display filter examples: tls or tcp.stream eq 0. Troubleshooting If you see linker errors for WebKitGTK or GTK, ensure libwebkit2gtk-4.1-dev and libgtk-3-dev are installed. In CI/headless environments, you may need xvfb-run to provide a display server. To skip building the desktop extension in constrained Linux CI, set OROTESTSKIPDESKTOPEXTENSION=1."
    },
    {
      "id": "WEBVIEW_TLS_PINS",
      "title": "WebView TLS Pins",
      "section": "networking",
      "summary": "The `webview_tls_pins` configuration key lets you pin server certificates for HTTPS requests made by the embedded WebViews. When no pins are configured for a host, the platform\u2019s default certificate validation behaviour is preserved.",
      "text": "WebView TLS Pins The webviewtlspins configuration key lets you pin server certificates for HTTPS requests made by the embedded WebViews. When no pins are configured for a host, the platform\u2019s default certificate validation behaviour is preserved. Configuration Pins are declared in oro.toml as a newline\u2011separated list of entries: [webview] tlspins = \"\"\" example.com sha256/BASE64DIGEST api.example.test sha256/OTHERBASE64DIGEST \"\"\" Each non\u2011empty, non\u2011comment line has the form: <host> <pin> [<pin>...] <host> may be a hostname, hostname:port, [ipv6]:port, or a URL; any scheme/path/query/fragment is ignored and any :port suffix is normalised away (pins apply to the host, not a specific port). <pin> is either sha256/<base64> or just <base64> (the digest is always interpreted as SHA\u2011256). <base64> may be standard Base64 or Base64URL (using - and ), with or without padding. Hosts are matched case\u2011insensitively. Lines may include comments starting with # or ; (trailing content is ignored). The digest is the SHA\u2011256 of the server certificate (not the entire chain), encoded as standard Base64. Computing a Pin The pin value is the Base64-encoded SHA-256 digest of the leaf certificate\u2019s DER bytes. From a remote server (uses OpenSSL): HOST=example.com PORT=443 openssl sclient -connect \"${HOST}:${PORT}\" -servername \"${HOST}\" </dev/null 2>/dev/null \\ openssl x509 -outform der \\ openssl dgst -sha256 -binary \\ openssl base64 -A From a local PEM file: openssl x509 -in server.pem -outform der \\ openssl dgst -sha256 -binary \\ openssl base64 -A Then configure: example.com sha256/<PASTEOUTPUTHERE> Runtime Updates In addition to static configuration, you can update pins at runtime via IPC: import ipc from 'oro:ipc' await ipc.request('application.setWebviewTlsPins', { value: example.com sha256/BASE64DIGEST api.example.test sha256/OTHERBASE64DIGEST , // mode: 'append' (default) to extend existing pins, // or 'replace' to overwrite them entirely. mode: 'append', }) Invalid entries are rejected with err.code = WEBVIEWTLSPINSINVALID. Or from JavaScript via the TLS module: import as tls from 'oro:tls' await tls.setWebViewTlsPins( [ 'example.com sha256/BASE64DIGEST', 'api.example.test sha256/OTHERBASE64DIGEST', ], { mode: 'append' } ) // Clear pins: await tls.clearWebViewTlsPins() Per-host helpers are also available: import as tls from 'oro:tls' await tls.setWebViewTlsPinsForHost('example.com', ['sha256/BASE64DIGEST']) await tls.addWebViewTlsPinsForHost('example.com', ['sha256/NEXTBASE64DIGEST']) await tls.removeWebViewTlsPinsForHost('example.com') const { configured, pins } = await tls.getWebViewTlsPinsForHost('example.com') console.log({ configured, pins }) This call: Updates the process\u2011wide runtime config (webviewtlspins), so Android\u2019s WebView sees the new pins via getUserConfigValue. Updates the default window config used for future windows. Updates bridge.userConfig[\"webviewtlspins\"] for all active windows so Apple/Linux WebViews immediately pick up the new pins. Behaviour by Platform macOS / iOS (WKWebView) Pins are enforced during the TLS handshake via WKNavigationDelegate\u2019s authentication challenge. When pins exist for a host, only certificates whose SHA\u2011256 digest matches one of the configured pins are accepted; other certificates are rejected even if they are trusted by the system. Linux (WebKitGTK) Pins are evaluated when WebKit reports TLS errors via load-failed-with-tls-errors. If the failing certificate\u2019s digest matches a configured pin for the host, the runtime whitelists that certificate for the host and retries the navigation. If no pin matches, the original TLS error is preserved. Note: webkitwebcontextallowtlscertificateforhost is sticky for the lifetime of the WebKitWebContext; clearing pins does not revoke previously allowed certificates without restarting the WebView. Note: this currently only relaxes errors for pinned certificates; it does not reject otherwise\u2011valid certificates that are not pinned. Android (android.webkit.WebView) Pins are evaluated in onReceivedSslError, which is only invoked when WebView encounters TLS errors. If pins exist for the host and the certificate digest matches, the error is overridden and the navigation proceeds; otherwise the navigation is cancelled. As with Linux, this cannot currently reject non\u2011pinned but otherwise valid certificates. Windows (WebView2) Pins are evaluated when WebView2 reports server certificate failures via ServerCertificateErrorDetected. If the failing certificate\u2019s digest matches a configured pin for the host, the runtime overrides the error and allows navigation; otherwise the navigation is cancelled. Note: WebView2\u2019s \u201calways allow\u201d decision may persist for the lifetime of the profile/user data folder; clearing pins does not necessarily revoke previously allowed certificates without clearing that profile state. As with Linux/Android, this is currently an error\u2011path hook and cannot reject otherwise\u2011valid certificates that are not pinned. When enabling pins, start with a single host in a controlled environment, verify behaviour on your target platforms, and only then roll out more broadly."
    },
    {
      "id": "WEB_BLUETOOTH_STATUS",
      "title": "Web Bluetooth Runtime Status",
      "section": "web-platform",
      "summary": "This document tracks the current implementation status for Web Bluetooth in the native runtime. Use it as a hand\u2011off to resume work in a new session.",
      "text": "Web Bluetooth Runtime Status This document tracks the current implementation status for Web Bluetooth in the native runtime. Use it as a hand\u2011off to resume work in a new session. Cross-cutting WebBluetooth::parseRequestDeviceOptions centralises spec validation (acceptAllDevices vs filters, optionalServices, manufacturerData masks) and reuses a single matcher for all backends. Router/bridge keep notification observers per-window with ref counts so repeated startNotifications() calls do not duplicate events. Observers are dropped automatically when a bridge is destroyed. The JS scaffold now de-dupes chooser rows and live-updates RSSI/name while a scan is active. Platform snapshot Apple (CoreBluetooth) Filters run through the shared matcher before presenting devices; advertisement manufacturer data is normalised for matching. Chooser dedupe is driven by peripheral UUIDs. Timeout uses options.timeoutMs, webbluetoothtimeoutms, or defaults to 12s. Android (Kotlin + JNI + GATT) Scanner forwards advertised service UUIDs; native backend filters locally via the shared matcher and caches name/RSSI/service info for chooser resolution. RequestDevice builds ScanFilters from the union of requested service UUIDs. Notifications, reads, and writes were already implemented. On API 31+, checks android.permission.BLUETOOTHSCAN/BLUETOOTHCONNECT before scanning and triggers a runtime prompt when missing; returns NotAllowedError until granted. Windows (classic + dynamic GATT) Classic radio enumeration still backs requestDevice; name/namePrefix filters now use the shared matcher data. BLE GATT plumbing exists (BluetoothAPIs.dll) but discovery is limited to remembered devices; no manufacturer/service filtering yet. Linux (BlueZ / D\u2011Bus) Discovery filter + matcher migrated to the shared helpers (services, names, prefixes, manufacturerData masks). requestDevice emits chooser events only when the matcher passes; MAC-level dedupe remains in place. GATT connect/discovery/read/write/notify already implemented; timeout/cancel flow unchanged (default 15s). Tests test/src/bluetooth/web-bluetooth.test.js exercises JS option validation (including servicesMatch) and chooser cancellation logic. Platform E2E/device tests remain manual for now. Configuration quick reference options.timeoutMs or [userConfig] webbluetoothtimeoutms (number string) controls discovery timeout (default 15000ms on Linux, 12s on Apple fallback). options.servicesMatch: 'all' (default) requires every service listed in a filter; 'any' allows a match when any service is present. A userConfig override (webbluetoothservicesmatch=all any) sets the default mode for requests that omit the option. Linux-specific tuning: webbluetoothemitintervalms (default 1000) throttles repeated devicefound emissions, webbluetoothemitrssidelta (default 4) sets the RSSI delta required to emit early. Next steps / open items 1. Windows: switch requestDevice to WinRT BLE enumeration, honour service/manufacturer filters, and wire notifications to the shared matcher. 2. Android: add MTU negotiation, improve read/write data paths (zero-copy), audit JNI/loop hand-offs, and document the BLE permission flow. 3. Tests: add integration coverage for filter permutations and repeated notification subscriptions; document chooser override hooks for apps; automate chooser interaction for CI. 4. Configuration: surface per-platform timeout defaults and user-config overrides; ensure Linux notification backpressure can be tuned. Notes Manufacturer data matching uses optional masks when provided (shared helper); Linux obtains bytes from Device1 ManufacturerData, Android currently only matches by company ID (no payload yet). All chooser events continue to emit on the runtime dispatcher to keep window interaction thread-safe."
    },
    {
      "id": "WEB_OTP",
      "title": "Web OTP Support",
      "section": "web-platform",
      "summary": "- Include the application origin, e.g. `@example.com` or `@example.com:443`. - Provide the OTP immediately after a `#` delimiter, e.g. `123456` in `Your code is: 123456 @example.com #123456`.",
      "text": "Web OTP Support Overview The Oro Runtime implements the WICG Web OTP API via navigator.credentials.get({ otp: { ... } }). Android requests are brokered by a native OTP service backed by Google Play Services\u2019 SMS Retriever API. iOS falls back to the system WebView implementation (WKWebView). Desktop platforms currently return NotSupportedError. SMS Format Requirements Incoming SMS messages must follow the Web OTP format: Include the application origin, e.g. @example.com or @example.com:443. Provide the OTP immediately after a # delimiter, e.g. 123456 in Your code is: 123456 @example.com #123456. The runtime validates the origin in the SMS before resolving the request. Configuration Toggle runtime access via [permissions] allowotp = true false in oro.toml. When set to false, Android requests are rejected with NotAllowedError and the SMS receiver is never registered. Platform Notes Android Requires Play Services on the device or emulator. The runtime automatically registers and unregisters the SMS Retriever broadcast receiver per request. No SMS permissions are requested; the Retriever API does not require READSMS. iOS The runtime now presents an in-app one-time-code field (with UITextContentTypeOneTimeCode) so OTP suggestions surface inside the app. No additional entitlements are required; the system QuickType bar provides the SMS code consent prompt. Desktop Not supported today; requests are rejected with NotSupportedError. iOS Integration Roadmap Even with the text-field-based implementation in place, we can explore deeper integration layers: 1. Evaluate ASAuthorizationController once Apple exposes an official Web OTP API to apps, allowing fully headless retrieval. 2. Consider an entitlements helper (entitlements.ios.associateddomains) if associated domains become a requirement for SMS code autofill. 3. Provide UI affordances for users to retry or dismiss OTP prompts when no SMS suggestion is offered. 4. Add XCTests that automate the QuickType OTP suggestion flow to guard against regressions across iOS releases. JavaScript Polyfill Behavior The runtime injects navigator.credentials.get support when the platform lacks a native implementation. The polyfill accepts signal and timeout options, propagating aborts to the native layer. Responses resolve with an OTPCredential object exposing type, code, transports, and origin. Quick start const controller = new AbortController() try { const credential = await navigator.credentials.get({ otp: { transport: ['sms'], hint: 'example-app' }, signal: controller.signal, timeout: 60000, }) console.log('OTP code', credential.code) } catch (err) { console.error('Unable to retrieve OTP', err) } Error Handling Android rejects requests with DOMException names aligned to the Web OTP spec: AbortError \u2013 configuration disabled, or request cancelled. InvalidStateError \u2013 empty codes or malformed SMS payloads. NotAllowedError \u2013 permission denied by config. NotSupportedError \u2013 platform/features missing (e.g., Play Services absent). TimeoutError \u2013 no matching SMS received before the request timeout."
    },
    {
      "id": "WEB_HID_STATUS",
      "title": "WebHID Runtime Status",
      "section": "web-platform",
      "summary": "_Last updated: September 24, 2025_",
      "text": "WebHID Runtime Status Last updated: September 24, 2025 This document tracks the native runtime implementation status for the WebHID API. Use it as a checklist when extending platform coverage and as a hand-off for integration testing with real devices. Overview The JavaScript scaffold (navigator.hid) and core service plumbing are in place. The runtime currently uses: A libusb-based backend on Linux. An IOHIDManager backend on macOS. A SetupAPI/HidD backend on Windows. Additional work (Android, hardware validation, entitlements) is still required for full parity. On iOS/iPadOS, Apple does not expose public APIs for generic HID access. The runtime therefore disables WebHID on those platforms and navigator.hid calls reject with NotSupportedError. Platform Status Platform Enumeration Request / Chooser Open / Close Input Reports Feature / Output Reports Notes ----------------------- ----------- ----------------- ------------ ------------- ------------------------ ------------------------------------------------------------------------------------------------------------------------- Linux (libusb) \u2705 \u2705 \u2705 \u2705 \u2705 Uses libusb interrupt transfers. Requires udev rules for permissioning. macOS (IOHIDManager) \u2705 \u2705 \u2705 \u2705 \u2705 Backend built on IOHIDManager; pending validation on real devices and entitlement audit. Windows (SetupAPI/HidD) \u2705 \u2705 \u2705 \u2705 \u2705 Backend implemented via SetupAPI/HidD; pending hardware validation and packaging checks. Android \u23f3 \u23f3 \u23f3 \u23f3 \u23f3 Use android.hardware.usb.UsbManager with asynchronous bulk endpoints. Coordinate with permission prompts. iOS / iPadOS \u274c \u274c \u274c \u274c \u274c Unsupported: Apple does not expose public HID APIs; apps must fall back to Web Bluetooth or platform-specific frameworks. Legend: \u2705 Ready \u2502 \u23f3 Planned \u2502 \u274c Missing / blocked Implementation Roadmap 1. macOS (IOHIDManager): Initial backend complete Follow-up: validate IOHIDElement-derived report metadata with real hardware and ensure multi-collection devices map correctly. Confirm entitlement requirements for distribution builds and add build-system toggles if needed. 2. Windows (Win32 HID): Backend implemented Follow-up: validate overlapped reads/report parsing with real HID hardware and document driver/permission requirements. 3. Android (UsbManager): Kotlin service in src/runtime/hid/android/ using UsbDeviceConnection. Register broadcast receiver for ACTIONUSBDEVICEDETACHED. Forward input reports via InputStream reads on interrupt endpoints. 4. iOS: Investigate CoreHID private APIs vs. accessory support; determine viability. Prototype using IOHIDManager on macOS Catalyst as an intermediate step. 5. Common tasks: Gate runtime permissions with [permissions] allowhid. Extend chooser UI to reflect device names per platform. Add telemetry hooks for debugging (optional). Integration Testing Plan 1. Device Matrix: Keyboard (report ID 0) \u2013 verifies zero-report handling. Gamepad (multiple reports) \u2013 validates report ID routing. Vendor-specific device \u2013 exercises feature reports. 2. Test Harness: Add Oro desktop integration tests to open a HID device, listen for input, send a feature report, and assert payloads (legacy Socket suites remain available during the rename). For Android, leverage instrumentation tests that dispatch synthetic USB intents. 3. Manual Procedures: Document per-platform steps for granting OS-level permissions (e.g., udev rule snippets, Windows driver requirements). Create troubleshooting guide (common errors, log locations). 4. CI Considerations: Simulators lack HID hardware, so smoke tests should mock IPC responses. Real-device regression tests can run on dedicated lab machines using the Oro test runner (legacy Socket mode sticks around for older pipelines). Automated Coverage Strategy JavaScript scaffold: continue expanding test/src/hid/web-hid.test.js with IPC-mocked scenarios that exercise report-ID edge cases (e.g., zero vs. non-zero report IDs, feature report truncation). The Oro test runner executes these in CI today (and still accepts socket invocations). Backend-level shims: introduce lightweight native unit tests per backend that feed synthetic descriptors into parseReportDescriptor (libusb) and IOHID/HIDP helpers. We can build these as npm run test:runtime-core fixtures compiled on each desktop target. Descriptor fixtures: define JSON fixtures under test/fixtures/hid/ that represent common device classes (keyboard, gamepad, vendor-specific). The native tests and JS scaffold can both import these fixtures to ensure consistent expectations. Mock transport hook: expose a compile-time flag that swaps the platform HID APIs with a deterministic fake (e.g., a fake libusbdevicehandle). This enables continuous testing without hardware and lets us assert on report payloads and event dispatch ordering. Open Questions How should we persist user grants across sessions? (Currently tied to runtime permissions only.) Should we expose additional events (e.g., inputreporterror) for parity with Chromium? Coordination with WebUSB / Bluetooth permissions to avoid overlapping prompts. Please keep this document updated as platform backends move forward."
    },
    {
      "id": "webusb",
      "title": "WebUSB in Oro Runtime",
      "section": "web-platform",
      "summary": "Oro Runtime (formerly Socket) provides a WebUSB scaffold that exposes a `navigator.usb` API mirroring the browser specification. It bridges to the native libusb backend for enumeration, permission checks, hotplug events, and bulk/control transfers.",
      "text": "WebUSB in Oro Runtime Oro Runtime (formerly Socket) provides a WebUSB scaffold that exposes a navigator.usb API mirroring the browser specification. It bridges to the native libusb backend for enumeration, permission checks, hotplug events, and bulk/control transfers. Installing navigator.usb The scaffold initializes automatically; simply call navigator.usb.getDevices() or navigator.usb.requestDevice() from your renderer. Devices returned include descriptors (vendor/product IDs, interface metadata) and support the usual WebUSB methods like open, selectConfiguration, transferIn, and transferOut. Platform support The native WebUSB backend currently targets desktop platforms (macOS, Windows, Linux) where libusb integrations are available. Mobile builds ship the JS scaffold for API consistency, but the runtime service is disabled on iOS. Android builds expose device enumeration and permission flows through the foreground USB service (which requires POSTNOTIFICATIONS on Android 13+); data transfer APIs (open, transferIn, etc.) still return NotSupportedError until the remaining bindings land. Chooser Flow When more than one device matches requestDevice, the scaffold fires a usb.chooserequest event whose detail object exposes the candidates plus select(device) and cancel() helpers. window.addEventListener('usb.chooserequest', (event) => { const { devices, select, cancel } = event.detail renderChooser(devices, select, cancel) }) If no listener handles it, a default overlay is shown. The overlay honors prefers-color-scheme but you can override it entirely by handling the event yourself. Hotplug Events The native backend emits usb.deviceconnect and usb.devicedisconnect; the scaffold transforms them into navigator.usb events: navigator.usb.addEventListener('connect', ({ device }) => { console.log('USB connected:', device.deviceId) }) Existing devices in the cache update in place when descriptors change. Persistent grants When a device is authorized, its identifier is stored in the runtime state database. On the next launch, the backend restores the grant so navigator.usb.getDevices() immediately returns previously-approved devices and requestDevice() can skip the chooser when only one persisted match exists. Permission queries You can check the runtime's USB permission state without prompting: const status = await navigator.permissions.query({ name: 'usb' }) if (status.state === 'denied') { // surface your own UI before calling navigator.usb.requestDevice() } Transfers Control/Bulk OUT flows use binary IPC; IN transfers return USBInTransferResult with DataView payloads. clearHalt requires an explicit endpoint direction. Testing See test/src/usb/web-usb.test.js for a minimal integration test demonstrating mocked IPC and chooser resolution."
    },
    {
      "id": "MCP",
      "title": "MCP Server Configuration",
      "section": "mcp",
      "summary": "Oro Runtime ships with a lightweight MCP HTTP/SSE bridge. The bridge can be configured statically through `oro.toml` or dynamically at runtime.",
      "text": "MCP Server Configuration Oro Runtime ships with a lightweight MCP HTTP/SSE bridge. The bridge can be configured statically through oro.toml or dynamically at runtime. CLI MCP server (oroc mcp) The Oro CLI also ships with an MCP server that exposes common oroc workflows as MCP tools, alongside safe workspace/config file access helpers. Stdio transport oroc mcp defaults to JSON-RPC over stdio, which is the recommended transport for Codex and other local agent runners. oroc mcp --stdio Streamable HTTP transport Use --http to run a Streamable HTTP MCP endpoint. The CLI prints a single JSON line to stdout describing the bound host/port/endpoint/token, then continues serving requests. oroc mcp --http --host 127.0.0.1 --port 0 --endpoint /mcp Notes: The CLI follows the MCP Streamable HTTP transport (2025-06-18): JSON-RPC requests return Content-Type: application/json; notifications/responses return 202 Accepted with no body. Sessions are normally created during initialize. Subsequent requests must include Mcp-Session-Id (missing: 400). If a client supplies an unknown session id (POST or SSE), the CLI will create a new session for that id so stateless clients keep working. The CLI supports GET SSE streams for server-to-client messages, scoped to a session id. Only one active SSE stream is allowed per session (second connection returns 409 unless replace-sse-stream is used). Loopback auth defaults to disabled unless --token is provided or [mcp].token is set. endpoint normalises common variants (mcp, /mcp/) to avoid client/server mismatches. The HTTP server binds ports exclusively (no SOREUSEPORT) so multiple oroc mcp --http instances cannot share a host/port. This prevents cross-session and cross-workspace confusion. Tools and resources The CLI exposes: Tools: runcli, workspace file read/write/list helpers, oro.toml read/write/validate, and convenience wrappers for common oroc commands (e.g., buildapp, runapp). readfile reads absolute paths outside the workspace root by default. Use read-workspace-only to disable this capability. Resources: workspace:/ (root listing), workspace:/oro.toml (config), and additional resources discovered from oro.toml (build inputs/copy maps/icons) when present. oro.toml configuration Add the optional [mcp] section to your app configuration to define defaults the runtime uses whenever mcp.startServer() is invoked without overrides. ; [mcp] ; host = 127.0.0.1 ; port = 0 ; bind to an ephemeral port by default ; endpoint = /mcp ; base HTTP/SSE endpoint ; token = my-shared-secret ; static bearer token enforced by the runtime ; authtimeoutms = 5000 ; optional timeout used when awaiting dynamic auth handlers Setting port = 0 instructs the runtime to bind to a random available port, which makes it easy to spin up multiple MCP servers in the same process. When token is provided the HTTP server enforces bearer authentication. The token still participates in the Authorization callback pipeline (see below), so you can mix static and dynamic checks. Dynamic Authorization Use mcp.setAuthorizationHandler() to register a callback that approves or rejects individual HTTP requests. The handler receives all available request metadata and can return: true to accept the request. false (or throw) to reject the request with the default 401 Unauthorized. An object { allow, status, message } to customise both the decision and the HTTP response returned to clients. import mcp from 'oro:mcp' await mcp.setAuthorizationHandler(({ authorization, headers }) => { // Reject requests that do not supply an Authorization header if (!authorization) { return { allow: false, status: 401, message: 'Missing bearer token' } } // Simple shared-secret check return authorization === Bearer ${process.env.EXPECTEDTOKEN} }) Pass the same handler directly to mcp.startServer({ authorize }) to configure the server and set the callback in a single call. await mcp.startServer({ port: 0, // bind to any free port authorize: ({ headers }) => headers['x-internal-key'] === 'expected-value', }) Call mcp.setAuthorizationHandler(null) to remove the handler. Pending authorization requests automatically fail closed when a handler is cleared or the server shuts down. API Reference The oro:mcp module now provides the following helpers in addition to the existing registration functions: Function Description --------------------------------- ----------------------------------------------------------------- mcp.startServer(options) Starts the embedded server. Accepts authorize and token. mcp.setAuthorizationHandler(fn) Registers or clears the dynamic authorization handler at runtime. See the runtime TypeScript declarations in the source repository (for example api/index.d.ts) for the full schema (MCPAuthorizationRequest, MCPAuthorizationDecision, MCPStartServerOptions)."
    },
    {
      "id": "mcp/2025-06-18/INDEX",
      "title": "MCP Specification (2025-06-18)",
      "section": "mcp",
      "summary": "Canonical spec base URL: https://modelcontextprotocol.io/specification/2025-06-18/",
      "text": "MCP Specification (2025-06-18) Canonical spec base URL: https://modelcontextprotocol.io/specification/2025-06-18/ This page links to the upstream specification pages. For Oro Runtime\u2019s MCP behavior, see MCP.md. Overview Model Context Protocol Specification: https://modelcontextprotocol.io/specification/2025-06-18 Key Changes: https://modelcontextprotocol.io/specification/2025-06-18/key-changes Architecture: https://modelcontextprotocol.io/specification/2025-06-18/architecture Base Protocol Base Protocol Overview: https://modelcontextprotocol.io/specification/2025-06-18/basic Lifecycle: https://modelcontextprotocol.io/specification/2025-06-18/basic/lifecycle Transports: https://modelcontextprotocol.io/specification/2025-06-18/basic/transports Authorization: https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization Security Best Practices: https://modelcontextprotocol.io/specification/2025-06-18/basic/security-best-practices Base Protocol Utilities Cancellation Utility: https://modelcontextprotocol.io/specification/2025-06-18/basic/utilities/cancellation Ping Utility: https://modelcontextprotocol.io/specification/2025-06-18/basic/utilities/ping Progress Utility: https://modelcontextprotocol.io/specification/2025-06-18/basic/utilities/progress Client Features Roots: https://modelcontextprotocol.io/specification/2025-06-18/client/roots Sampling: https://modelcontextprotocol.io/specification/2025-06-18/client/sampling Elicitation: https://modelcontextprotocol.io/specification/2025-06-18/client/elicitation Server Features Server Features Overview: https://modelcontextprotocol.io/specification/2025-06-18/server Prompts: https://modelcontextprotocol.io/specification/2025-06-18/server/prompts Resources: https://modelcontextprotocol.io/specification/2025-06-18/server/resources Tools: https://modelcontextprotocol.io/specification/2025-06-18/server/tools Server Utilities Logging Utility: https://modelcontextprotocol.io/specification/2025-06-18/server/utilities/logging Completion Utility: https://modelcontextprotocol.io/specification/2025-06-18/server/utilities/completion Schema Schema Reference: https://modelcontextprotocol.io/specification/2025-06-18/schema"
    },
    {
      "id": "AI_SERVER",
      "title": "Embedded LLaMA Server (AI, OpenAI-compatible)",
      "section": "ai",
      "summary": "The runtime embeds a llama.cpp-based server exposed via the in-process `oro:` scheme. There is no external listening socket; endpoints are available only inside the app.",
      "text": "Embedded LLaMA Server (AI, OpenAI-compatible) The runtime embeds a llama.cpp-based server exposed via the in-process oro: scheme. There is no external listening socket; endpoints are available only inside the app. Endpoints (default prefix /ai/llama) GET /health \u2014 readiness + loaded models and basic metrics GET /v1/models \u2014 { object: \"list\", data: [{ id, object: \"model\" }] } POST/GET /v1/chat/completions \u2014 OpenAI-compatible chat SSE streaming: ?stream=true or body { stream: true } POST/GET /v1/completions \u2014 text completion SSE streaming: ?stream=true or body { stream: true } POST/GET /v1/embeddings \u2014 vector for input Utilities: POST/GET /tokenize, /detokenize Model Loading (IPC) // Load a model by file name. Searches environment/userConfig paths. await fetch('ipc://ai.llm.model.load?name=model.gguf') // or provide directory=/abs/path explicitly Search order for model files: OROAILLMMODELPATH (env var: directory) userConfig key aillmmodelpath (directory) explicit directory query parameter Request Semantics Location: oro://<bundle>/<prefix>/<endpoint> Content type: application/json supported; query params also accepted JSON body parse cap: 1 MiB (oversized bodies are not parsed) Prompt size cap: 128 KiB \u2192 413 Sampling defaults: taken from userConfig or server options when omitted Stop sequences: Non-stream: output trimmed at earliest stop Stream: rolling tail (size = longest stop) detects stop Tools/Function Calling (Stub) When a request requires a function call (tools + required toolchoice), the server returns a minimal stub response: Non-stream: choices[0].message.toolcalls[...], finishreason: \"toolcalls\" Stream: a single chunk with choices[0].delta.toolcalls[...], followed by [DONE] Applications should interpret this and run their own vetted function implementation, then send a follow-up prompt. Configuration (userConfig) aillmserverprefix (default /ai/llama) aillmdefaultmodel aillmratelimitconcurrency (default 4) aillmratelimitrps (0 = disabled) aillmratelimitburst (0 = disabled) aillmdefaultmaxtokens (default 128) aillmdefaulttemperature (default 0.8) aillmdefaulttopp (default 0.95) aillmdefaulttopk (default 40) aillmdefaultminp (default 0.05) Environment: OROAILLMMODELPATH \u2014 directory containing models Metrics GET /health returns metrics: inflight, rateRPS, rateBurst, rateLimited per-endpoint counts and average latencies (ms) for stream/non-stream chat and completions Security & Performance Internal-only exposure via oro:; no external ports Resource caps (prompt/JSON) to bound memory/CPU Concurrency and rate-limiting guards prevent overload; heavy jobs run off the UI thread SSE/chunk streams coalesce writes to reduce overhead Tool-calling does not execute arbitrary code; arguments are {} by default Testing Models in CI/Locally Optional env vars: OROAIMODELNAME (required) OROAIMODELDIR (optional directory) If set, E2E tests attempt to load the model and run basic streamed/non-stream chat checks."
    },
    {
      "id": "AI_TOOL_CALLING",
      "title": "Tool-Calling (Stub) Behavior",
      "section": "ai",
      "summary": "The embedded LLaMA server exposes OpenAI-compatible chat endpoints over the internal `oro:` scheme. For safety, when a request requires a function/tool call, the runtime does not execute arbitrary tool code. Instead, it returns a minimal, deterministic stub that applications can interpret and emulate client-side.",
      "text": "Tool-Calling (Stub) Behavior The embedded LLaMA server exposes OpenAI-compatible chat endpoints over the internal oro: scheme. For safety, when a request requires a function/tool call, the runtime does not execute arbitrary tool code. Instead, it returns a minimal, deterministic stub that applications can interpret and emulate client-side. When tool-calling stubs are used The request includes a tools array and a toolchoice that: is \"required\", or an object specifying a particular function via toolchoice.function.name. What is returned Non-stream (/v1/chat/completions): { \"choices\": [ { \"index\": 0, \"message\": { \"role\": \"assistant\", \"content\": null, \"toolcalls\": [ { \"index\": 0, \"id\": \"call...\", \"type\": \"function\", \"function\": { \"name\": \"<functionName>\", \"arguments\": \"{}\" } } ] }, \"finishreason\": \"toolcalls\" } ] } Stream (?stream=true): A single chunk with choices[0].delta.toolcalls[...], then data: [DONE]. How to use this in applications 1. Detect a tool call in the response (non-stream) or streamed chunk. 2. Look up the function name (e.g., weather.fetch) in your own registry of allowed tools. 3. Execute the tool logic in your application environment (e.g., a JS function). 4. Append a follow-up message with the tool result and send another /v1/chat/completions request. Security notes The runtime never executes external code or system commands in response to tool-call requests. Arguments are returned as an empty JSON object ({}) to avoid passing arbitrary payloads. Applications should merge in validated arguments if desired. All inputs are size-limited and validated conservatively."
    },
    {
      "id": "AI_WHISPER",
      "title": "Whisper Speech Integration",
      "section": "ai",
      "summary": "Oro Runtime vendors [`whisper.cpp`](https://github.com/ggerganov/whisper.cpp.git) for per-device speech-to-text. This document summarizes build requirements, IPC endpoints, and the JavaScript API.",
      "text": "Whisper Speech Integration Oro Runtime vendors whisper.cpp for per-device speech-to-text. This document summarizes build requirements, IPC endpoints, and the JavaScript API. capture snippet. Build & Packaging The install script builds whisper alongside libuv/llama when ./bin/install.sh (or OROHOME/PREFIX packaging) is invoked. compilewhisper currently supports: Desktop (x8664-desktop) \u2013 default path, verified. Windows \u2013 produces whisper.lib (experimental; requires MS toolchain). iOS (iPhoneOS/iPhoneSimulator) \u2013 uses xcrun clang/bitcode. Android (NDK) \u2013 static libwhisper.a per ABI. Pending: run platform-specific builds in CI to confirm toolchains and linking. IPC Routes The runtime exposes whisper control commands through ipc://: Command Description ------------------------- -------------------------------------------------------------------------------------- ai.whisper.model.load Load a model into memory (by name or id, optional directory, threading options). ai.whisper.model.list List loaded models. ai.whisper.model.unload Unload a model by id or name. ai.whisper.transcribe Transcribe PCM payload (POST body) with optional query parameters (see below). Transcribe Query Parameters id / name \u2013 identify the model (one required). format \u2013 f32 (default) or pcm16. sampleRate \u2013 source sample rate (default 16000). channels \u2013 channel count (default 1). normalize \u2013 true to scale waveform prior to inference. stream \u2013 true to stream partial segments over Conduit. language, translate, detectLanguage, timestamps, wordTimestamps, diarize, threadCount, maxSegmentLength, temperature, temperatureIncrement, entropyThreshold, logProbThreshold, noSpeechThreshold \u2013 forwarded to whisper. When stream=true and a Conduit client exists for the id, segments are pushed incrementally with payloads encoded via the Conduit binary framing. If no Conduit client is present, partial segments are emitted via ipc.write queued responses (sequence -1). Response Structure { \"text\": \"full transcription\", \"language\": \"en\", \"audioMs\": 1234.5, \"processingMs\": 456.7, \"inputSampleRate\": 44100, \"inputSamples\": 44100, \"outputSamples\": 16000, \"resampled\": true, \"normalized\": true, \"segments\": [ { \"index\": 0, \"start\": 0.0, \"end\": 1.0, \"text\": \"hello\", \"confidence\": 0.95 } ] } JavaScript API (oro:ai/whisper) import whisper from 'oro:ai/whisper' const model = new whisper.WhisperModel({ name: 'ggml-base.en.bin' }) await model.load({ directory: '/abs/path/to/models' }) const audio = new Int16Array(/ PCM16 samples /) const result = await model.transcribe(audio, { sampleRate: 44100, channels: 2, normalize: true, stream: true, onSegment(segment) { console.log(segment) }, signal: abortController.signal, }) Options (typed in the runtime TypeScript declarations): sampleRate, channels, format \u2013 audio metadata. normalize \u2013 enable RMS normalization. stream + onSegment \u2013 receive partial hypotheses (requires Conduit). signal \u2013 abort the request. Other decoding knobs mirror llama (temperature, maxSegmentLength, etc.). Helpers whisper.listModels() \u2013 fetch loaded models. whisper.unloadModel(idOrName) \u2013 unload a specific model. Testing The integration tests expect heavy fixtures and are skipped by default. Provide the following environment variables to enable them: export OROTESTWHISPERMODEL=/absolute/path/to/ggml-base.en.bin export OROTESTWHISPERAUDIO=/absolute/path/to/audio.pcm export OROTESTWHISPERAUDIOFORMAT=pcm16 # optional export OROTESTWHISPERAUDIOSAMPLERATE=44100 # optional export OROTESTWHISPERAUDIOCHANNELS=2 # optional Then run (optionally skipping native test extensions in CI): OROTESTSKIPDESKTOPEXTENSION=1 \\ OROTESTSKIPTESTEXTENSIONS=1 \\ OROTESTWHISPERMODEL=... \\ OROTESTWHISPERAUDIO=... \\ npm test whisper-streaming -- --runInBand Configuration Keys The following user-config (oro.toml) keys affect whisper: aiwhispermodelpath \u2013 directory fallback when loading models. aiwhisperqueuelimit \u2013 max queued transcription jobs (defaults to 4). Per-model keys follow the same pattern as llama (e.g. aiwhispermodel<name>). Notes & Limitations Non-16 kHz input is resampled via linear interpolation; consider higher-quality resamplers if your application demands it. Streaming currently emits full text for each partial segment; consumers may want to diff successive outputs. iOS/Android/Windows builds require platform toolchains; confirm in CI before shipping to end users."
    },
    {
      "id": "APPLICATION_UPDATE_PROTOCOL",
      "title": "Oro Application Update Protocol (OUP)",
      "section": "release",
      "summary": "This document describes a portable, transport-agnostic system for delivering signed application updates over HTTP and custom UDP/TCP transports.",
      "text": "Oro Application Update Protocol (OUP) This document describes a portable, transport-agnostic system for delivering signed application updates over HTTP and custom UDP/TCP transports. The design is inspired by existing update frameworks (for example, systems like The Update Framework and package manager repositories) but is tailored for the Oro runtime, libsodium, and environments where application developers can host their own infrastructure. Goals Protect users against tampered or replayed updates, even over untrusted networks. Make the format transport-agnostic so the same metadata works over HTTP, TCP, or UDP. Keep the server side simple enough for static hosting or small services. Allow applications to remain in control: the runtime can fetch & verify; the app decides when and how to apply an update. Provide a clear, evolvable wire format that can be implemented in other languages or runtimes. Non-goals: Full OS / installer updates. Mobile app store updates (those environments are expected to use store mechanisms). Complex multi-role key hierarchies; the initial design keeps keys simple but is compatible with future extensions. High-level architecture The update system separates metadata, artifacts, and transport: Artifacts are the update payloads (archives, binaries, bundles, etc). Manifests describe artifacts (version, platform, hashes, URLs) and are signed with an Ed25519 key. Transports (HTTP, TCP, UDP) move manifests and artifacts between publisher and client. Transport is assumed untrusted; integrity and authenticity are enforced at the metadata level with libsodium. Each application ships with a built\u2011in update public key. Only holders of the corresponding update private key can publish updates for that application. Cryptography The system uses libsodium: Signatures: cryptosigned25519 for manifest signatures. Hashes: cryptogenerichash (or SHA\u2011256 via WebCrypto) for artifact digests. Recommendations: Use one or more long\u2011lived Ed25519 root/update keys per application. Store private keys offline or in a CI secret store. Distribute the public key with the app (for example, hard\u2011coded or loaded from a trusted bundle). Public keys and signatures are represented as: Public key (pk): 32\u2011byte Ed25519 public key, encoded as lowercase hex or base64url. Signature (sig): 64\u2011byte Ed25519 signature, encoded as lowercase hex or base64url. The client treats encodings as interchangeable and normalises them back to raw bytes for verification. Manifest format The manifest is an opaque byte string from the perspective of signature verification: publishers sign the raw bytes of the manifest file, and clients verify the exact same bytes. A canonical JSON representation is recommended for portability. Top-level shape { \"schemaVersion\": 1, \"appId\": \"com.example.myapp\", \"generatedAt\": \"2025-01-01T12:34:56Z\", \"channels\": [\"stable\", \"beta\"], \"updates\": [ { \"id\": \"stable-1.2.3\", \"version\": \"1.2.3\", \"channel\": \"stable\", \"minRuntimeVersion\": \"0.6.0\", \"critical\": false, \"notesUrl\": \"https://example.com/myapp/1.2.3-notes.html\", \"targets\": [ { \"platform\": \"darwin\", \"arch\": \"x64\", \"osVersionRange\": \">=11\", \"artifactUrl\": \"https://updates.example.com/myapp/darwin-x64-1.2.3.tar.zst\", \"length\": 12345678, \"hashAlgorithm\": \"sha256\", \"hash\": \"b0f3\u2026\", // hex \"signatureAlgorithm\": \"ed25519\", \"artifactSignature\": \"cafe\u2026\" // optional per-artifact signature } ] } ] } Key points: schemaVersion gates breaking changes in the manifest layout. appId uniquely identifies the application (reverse DNS is recommended). updates may contain many versions and channels; the client filters to the relevant channel, platform, and version. The manifest is not trusted until its signature has been verified. An authoritative JSON Schema for this manifest lives at schemas/update-manifest.schema.json in the repository. Publishers and downstream tooling can use it to validate manifest.json files during CI or manual editing. Manifest signature sidecar The manifest is distributed together with a signature file: Manifest bytes: manifest.json Signature bytes: manifest.sig The signature file contains an encoded signature and metadata: { \"schemaVersion\": 1, \"algorithm\": \"ed25519\", \"keyId\": \"pk-1\", \"signature\": \"cafe\u2026\" // base64url or hex } The JSON Schema for the signature file is available at schemas/update-manifest-signature.schema.json in this repository. Clients: 1. Download manifest.json as raw bytes. 2. Download and parse manifest.sig. 3. Decode the signature field to raw bytes. 4. Verify the signature over the raw manifest.json bytes using the configured public key. 5. Only then parse manifest.json as JSON and process its contents. The same manifest and signature format is used for all transports. HTTP transport binding HTTP(S) is the primary transport for manifests and artifacts. A minimal setup can be hosted on static file storage or any simple HTTP server. Layout Publishers choose a base URL and directory structure. One suggested layout is: https://updates.example.com/myapp/ manifest.json manifest.sig artifacts/ darwin-x64-1.2.3.tar.zst win32-x64-1.2.3.zip The client is configured with: manifestUrl (for example, https://updates.example.com/myapp/manifest.json) publicKey (Ed25519 public key) Optionally a channel, currentVersion, and target platform/arch. HTTP request/response flow 1. Client sends GET manifestUrl. 2. Client sends GET manifestUrl + \".sig\" (unless overridden). 3. Client verifies the manifest signature. 4. Client selects the best update for its channel, version, and platform. 5. Client downloads artifactUrl with GET, optionally using Range requests. 6. Client verifies the artifact digest and optional per\u2011artifact signature. Transport security: HTTPS is strongly recommended. Even when HTTPS is unavailable or misconfigured, the client must reject updates whose manifest signatures or artifact hashes do not validate. UDP/TCP transport binding Some deployments may prefer a push\u2011oriented or low\u2011latency transport. The update protocol defines a simple binary framing suitable for TCP or UDP. All messages start with: struct Header { uint8 version; // protocol version, e.g., 1 uint8 msgType; // 0x01 = CHECK, 0x02 = RESPONSE, 0x03 = MANIFESTCHUNK, 0x04 = ERROR uint16 reserved; // must be zero for now uint32 length; // length of the remaining payload in bytes (big-endian) } Payloads are encoded as JSON or CBOR; implementations may choose either as long as both sides agree. For portability, JSON with UTF\u20118 is recommended initially. CHECK message Client \u2192 server: { \"schemaVersion\": 1, \"appId\": \"com.example.myapp\", \"currentVersion\": \"1.1.0\", \"channel\": \"stable\", \"platform\": \"darwin\", \"arch\": \"x64\", \"runtimeVersion\": \"0.6.0\" } RESPONSE message Server \u2192 client: { \"schemaVersion\": 1, \"hasUpdate\": true, \"selectedUpdateId\": \"stable-1.2.3\", \"manifestInline\": false, \"manifestUrl\": \"https://updates.example.com/myapp/manifest.json\" } If manifestInline is true, the server may send the manifest bytes over subsequent MANIFESTCHUNK messages: struct ManifestChunkPayload { uint32 offset; // byte offset of this chunk uint32 totalLength; // total manifest length in bytes uint8 data[]; // chunk bytes } The client reassembles the manifest bytes, then verifies the signature as in the HTTP case. Artifacts are still typically downloaded over HTTP, but a TCP or UDP stream could also carry artifact chunks, subject to deployment constraints. Client-side API (overview) The Oro runtime exposes a high\u2011level oro:application/update module that: Fetches manifest and signature over HTTP. Verifies manifest signatures using libsodium. Selects an appropriate update for the app\u2019s platform/channel/version. Downloads and verifies artifact hashes. Returns verified artifacts to the application for installation. The API is transport\u2011agnostic: advanced users can swap the HTTP transport with a custom TCP/UDP implementation that conforms to the same manifest and signature rules. Mapping to the oro:application/update module The api/application/update.js module provides a small set of primitives that map directly onto this protocol: fetchManifest(options) Inputs: manifestUrl, optional signatureUrl, publicKey, optional fetch, signal, and extra HTTP headers. Behavior: downloads manifest.json and manifest.sig, verifies the Ed25519 signature using libsodium, then parses the manifest JSON. Returns: { manifest, raw, signature }, where raw is the original manifest bytes and signature includes the decoded signature bytes and metadata. selectUpdate(manifest, options) Inputs: a verified UpdateManifest and selection hints (channel, currentVersion, platform, arch, runtimeVersion). Behavior: filters updates by channel and targets by platform/arch, enforces minRuntimeVersion and currentVersion, then chooses the highest compatible version (preferring critical when versions tie). Returns: { manifest, update, target } or null if no suitable update exists. downloadUpdate(target, options) Inputs: a UpdateTarget from the manifest and optional fetch/signal. Behavior: downloads the artifact at artifactUrl, enforces length (if provided), computes a digest using WebCrypto (SHA-256 by default), and compares it to the manifest\u2019s hash field. Returns: a Uint8Array with the verified artifact bytes. verifyArtifact(payload, target) Inputs: artifact bytes and the corresponding UpdateTarget from the manifest. Behavior: enforces length (if present) and verifies the declared hash. Use this when artifacts are obtained via a non-HTTP transport (for example, custom TCP/UDP delivery or a local cache). checkForUpdates(options) Convenience wrapper that calls fetchManifest, selectUpdate, and (if requested via download: true) downloadUpdate. Returns a discriminated result: { updateAvailable: false, manifest, signature }, or { updateAvailable: true, manifest, signature, update, target, artifact? }. openArtifactArchive(artifact) Inputs: a verified artifact payload (for example, the artifact field from checkForUpdates when download: true). Behavior: wraps the bytes in a native tar reader and returns a TarArchive backed by the runtime\u2019s tar service. This allows callers to inspect and extract entries using the same semantics as oro:tar (see TARAPI.md for details). Intended for tar-based update bundles; callers are free to ignore it for non-tar artifacts. Client code is expected to embed or otherwise obtain the Ed25519 public key and pass it in as publicKey. The runtime does not manage update keys. When calling fetchManifest or checkForUpdates, callers MAY also provide an expectedAppId option; if present, the helpers will reject manifests whose appId does not match the expected value. This is recommended for applications that support multiple products or environments. Example integration Simple HTTP-based check-and-download flow: import { checkForUpdates } from 'oro:application/update' const result = await checkForUpdates({ manifestUrl: 'https://updates.example.com/myapp/manifest.json', publicKey: '<ed25519-public-key-hex-or-base64>', channel: 'stable', currentVersion: '1.2.3', download: true, }) if (!result.updateAvailable) { console.log('No updates available') } else { const { update, target, artifact } = result console.log('Selected update', update.version, 'for', target.platform, target.arch) // TODO: apply the update bytes in a way that makes sense for your app. } CLI tooling The Oro CLI provides first-party helpers for managing update keys, manifests, and bundles: oroc update keygen Generates an Ed25519 keypair suitable for signing manifests. Outputs JSON with keyId, publicKey, and privateKey (hex). oroc update init Scaffolds a minimal manifest.json file in the current directory. Sets schemaVersion = 1, appId from your oro.toml's [meta] bundleidentifier (falling back to a placeholder), generatedAt (UTC), channels from updatechannel (or [\"stable\"] when not set), and an updates array containing a single entry for the current version/channel with an empty targets array. oroc update sign Signs a manifest file and writes a detached manifest.sig JSON sidecar. Inputs: optional --manifest=<path> (defaults to manifest.json or a custom name), and either --keys=<file> (JSON) or private-key=<hex>. Supports --key-id and --out to control metadata and output path. By default, the signature filename is derived from the manifest name by stripping the extension and appending .sig (for example, manifest.json \u2192 manifest.sig). Advanced: set OROUPDATEMANIFESTFILENAME or pass manifest-name=<name> to change the default manifest filename (and derived signature path). oroc update verify Verifies a manifest + signature pair against a public key. Inputs: optional --manifest=<path> (defaults to manifest.json or a custom name), optional --signature=<path> (defaults to the derived signature path, e.g. manifest.json \u2192 manifest.sig), and either keys=<file> (JSON) or --public-key=<hex>. Advanced: set OROUPDATEMANIFESTFILENAME or pass manifest-name=<name> to change the default manifest filename; the default signature path is derived by stripping the manifest's extension and appending .sig (for example, manifest.json \u2192 manifest.sig). oroc update validate Validates a manifest JSON file against the expected schema shape. Inputs: optional --manifest=<path> (defaults to manifest.json or a custom name), and optional --manifest-name=<name> (used when --manifest is not provided). Behavior: parses the manifest and enforces structural rules aligned with schemas/update-manifest.schema.json (required fields, types, relationships). Advanced: with --strict, additional consistency rules are applied (for example, ensuring each update\u2019s channel is present in the top\u2011level channels array and that artifactUrl values do not contain whitespace). Intended for fast local checks and CI. oroc update bundle Builds a tar archive containing the contents of a directory, suitable as an update artifact. Inputs: optional --input=<dir> (defaults to the project directory, i.e., the app source) and optional --output=<bundle.tar> (defaults to <buildname>-<version>.tar derived from oro.toml). Additional options: manifest / --manifest-name (or OROUPDATEMANIFESTFILENAME): when provided, the CLI parses the manifest, validates it against the schema shape, and updates it with a new target describing the bundle (including length, hashAlgorithm, and hash). channel, --update-id, --platform, --arch, --artifact-url: control which update entry and target are created or amended. Reasonable defaults are derived from oro.toml (updatechannel, metaversion) and the bundle filename when these flags are omitted (for source-only bundles, platform defaults to \"source\" and arch defaults to \"any\"). hash-algorithm=<sha256 sha1>: hash algorithm for the tar payload. Defaults to sha256 when libsodium is available at build time (via cryptogenerichash) and to sha1 otherwise. The resulting digest is written into the manifest\u2019s hash field for the new target. Preserves directory layout and file metadata (size, basic mode bits, and mtime) using the runtime\u2019s native tar implementation. oroc update extract Extracts a tar archive (for example, one produced by update-bundle) into a destination directory. Inputs: --bundle=<bundle.tar>, --dest=<dir>. Rejects absolute paths and .. segments inside the archive to avoid directory traversal; ignores special entries such as symlinks. oroc update server Runs an update server implementing the HTTP and binary TCP/UDP bindings of this protocol. Default mode is HTTP and is intended to be run behind a reverse proxy or load balancer in production, but TCP and UDP modes are also suitable for production deployments when a binary CHECK/RESPONSE transport is desired. Inputs: --root=<dir> (directory containing one or more manifest trees), optional --host=<host> and --port=<port> (default 0.0.0.0:8080), and optional manifest-name=<name> (defaults to manifest.json or OROUPDATEMANIFESTFILENAME). HTTP exposes: GET /health \u2014 readiness metadata for the server. POST /check \u2014 accepts a CHECK JSON payload with appId and responds with a RESPONSE JSON whose manifestUrl points at /<appId>/<manifest-name> when such a manifest exists under --root; otherwise hasUpdate: false. GET /<path> \u2014 serves static files rooted under --root, including /<appId>/<manifest-name> and the corresponding signature file (for example /<appId>/manifest.sig when manifest-name is manifest.json). TCP/UDP expose the same CHECK/RESPONSE semantics over the OUP binary framing described above: The payload inside the binary frame is the same JSON CHECK/RESPONSE body as HTTP, including schemaVersion, appId, hasUpdate, and manifestUrl. oroc update info Acts as a small client for the update protocol and for static manifest hosting. HTTP static mode: with --manifest-url=<url>, fetches a JSON manifest from an HTTP(S) origin, pretty\u2011prints it, and reports whether a companion signature file is reachable (by default derived as manifest.sig). When --keys or public-key is provided and libsodium is available, it also verifies the manifest signature before printing. HTTP server mode: with --host/--port and no --manifest-url, sends a CHECK JSON body to an HTTP update server\u2019s /check endpoint and pretty\u2011prints the RESPONSE JSON. With --follow-manifest, if the RESPONSE includes a manifestUrl pointing at a HTTP(S) resource, the CLI follows that URL, validates the referenced manifest, and when keys/--public-key are provided it also verifies the manifest signature before printing it. TCP/UDP modes: with --transport=tcp/--tcp or --transport=udp/--udp, sends a binary\u2011framed CHECK message and pretty\u2011prints the JSON RESPONSE payload returned by the server. A --timeout-ms flag can be used to bound how long the client waits for a TCP or UDP response. When --follow-manifest is provided and the RESPONSE contains a manifestUrl pointing at a HTTP(S) resource, the CLI follows that URL and applies the same manifest validation / verification flow as in the HTTP server mode. Common hints such as --app-id, --channel, --current-version, --platform, --arch, and --runtime-version are included in the CHECK payload when provided; their defaults are taken from oro.toml when available. The flags --http, --tcp, and --udp are shorthands for --transport=http, --transport=tcp, and transport=udp respectively. When --follow-manifest is used in server modes and --app-id is set, any fetched manifest must have a matching appId value or the command fails; this prevents misconfiguration where a server points to a manifest for a different app. Example end-to-end flows Basic local flow using the default manifest.json: 1) Scaffold a manifest for the current project. oroc update init 2) Generate a signing keypair (writes key.json). oroc update keygen > key.json 3) Build a source-only bundle and record it in the manifest. oroc update bundle --manifest manifest.json 4) Sign the manifest using the generated keypair. oroc update sign --keys key.json --manifest manifest.json 5) Verify the manifest + signature using the same keypair. oroc update verify --keys key.json --manifest manifest.json Serving many apps/manifests and querying them: 1) Prepare a directory of per-app trees. mkdir -p ./updates/com.example.app cp manifest.json ./updates/com.example.app/ cp manifest.sig ./updates/com.example.app/ 2) Run an HTTP update server on 0.0.0.0:8080. oroc update server --root ./updates 3) From another terminal, query for a given app and follow the manifestUrl. oroc update info --http --host 127.0.0.1 --port 8080 \\ app-id com.example.app \\ follow-manifest Static object store hosting (no custom server, just HTTP): 1) Upload manifest.json and manifest.sig to object storage/CDN. Example URLs: https://cdn.example.com/app/manifest.json https://cdn.example.com/app/manifest.sig 2) Inspect the manifest only (no verification). oroc update info \\ manifest-url https://cdn.example.com/app/manifest.json 3) Inspect and verify the manifest using a public key file. oroc update info \\ manifest-url https://cdn.example.com/app/manifest.json \\ keys app-pubkey.json Configuration defaults Applications can provide update defaults in oro.toml (or .ororc) which the native update service uses when corresponding options are not provided programmatically: updatechannel (flattened key) Default update channel when a channel option is not provided to checkForUpdates. Common values: \"stable\", \"beta\", \"nightly\". When absent, \"stable\" is used. updatemaxmanifestbytes Maximum allowed manifest size in bytes when maxManifestBytes is not passed to checkForUpdates. Manifests larger than this are rejected with ERRMANIFESTTOOLARGE. updatemaxartifactbytes Maximum allowed artifact size in bytes when maxArtifactBytes is not passed to checkForUpdates/downloadUpdate. Artifacts larger than this are rejected with ERRARTIFACTTOOLARGE. All per-call options (channel, maxManifestBytes, maxArtifactBytes, etc.) continue to take precedence over configuration defaults when explicitly provided. A UDP/TCP deployment can mirror the same flow but substitute a custom transport for the manifest/artifact fetch: 1. Use oro:dgram or oro:tcp to send the CHECK message and receive RESPONSE / MANIFESTCHUNK messages. 2. Reassemble the manifest bytes as described in the UDP/TCP section. 3. Call fetchManifest-like logic (or verifyManifestBytes/parseManifest if you are reusing the implementation) with the reassembled bytes and the configured public key. 4. Use selectUpdate, downloadUpdate, and/or verifyArtifact exactly as in the HTTP case. Server-side considerations Publishers are free to implement infrastructure however they like, subject to a few constraints: Manifests and signatures must be served as opaque byte streams (no on\u2011the\u2011fly rewriting). Artifact bytes must be stable and match the hashes declared in the manifest. Version/channel rules should stay monotonic for a given app to avoid downgrade attacks (for example, never republish an older binary with a newer version). Keys should be rotated rarely and with care; when rotation is necessary, ship a new app build that trusts the new key before publishing manifests signed solely by that key. Key management recommendations Keep update signing keys separate from other application secrets. When rotating keys: Ship a new app build that trusts both the old and new public keys. Start signing manifests with the new key while still allowing the old one for a defined window. Once a majority of clients are upgraded, stop accepting the old key. Record which key was used in the keyId field of manifest.sig so logs and tooling can easily audit past updates. Extensibility The protocol is designed to evolve without breaking existing clients: schemaVersion allows new required fields to be introduced. New hash or signature algorithms can be added as additional values. Additional metadata (for example, delta update descriptors or mirrors) can be added without affecting signature verification, as long as publishers sign the full manifest bytes. Future work can add: Multi\u2011role key hierarchies (root vs. release keys). Delta update formats and patch application helpers. Push notifications over the Oro network stack to notify clients of available updates without polling. Current implementation status and limitations The implementation in this repository provides: Full HTTP binding support (manifest + signature fetch over HTTP(S)), now implemented natively in the Oro runtime (C++ service) and exposed via IPC. Manifest verification using Ed25519 via libsodium in the native runtime (with a JS fallback for environments where the native service is unavailable). Artifact integrity checks using SHA\u20112 digests and optional length checks, performed natively when the update service is enabled. An application-facing API in oro:application/update that delegates to the native update service when available and falls back to a transport-agnostic JS implementation that can be reused with custom transports. Notable limitations and areas reserved for future work: Per-artifact signatures: the manifest format supports signatureAlgorithm/artifactSignature, but the current JS helpers only enforce hashes and lengths. Deployments that require per-artifact signatures must add verification on top or extend verifyArtifact. schemaVersion handling: manifests and signature files carry schemaVersion. The current helpers enforce schemaVersion === 1 for manifests and reject unknown values as unsupported. Future versions may allow callers to opt into accepting additional schema versions. appId enforcement: callers can provide an expectedAppId option when fetching manifests. If present, the helpers enforce an exact match between manifest.appId and this value. Deployments that reuse signing keys across multiple products SHOULD set expectedAppId to avoid configuration mistakes. UDP/TCP transport helpers: the binary framing and messages are specified, but no concrete oro:application/update UDP/TCP helpers ship yet. Deployments that require them should implement framing on top of oro:dgram / oro:tcp and then reuse the manifest/artifact verification APIs described above."
    },
    {
      "id": "release/ORO_RELEASE_AUTOMATION",
      "title": "Oro Runtime Release Automation (npm packages)",
      "section": "release",
      "summary": "This document describes how the release scripts in this repo publish Oro Runtime CLI/runtime packages to npm.",
      "text": "Oro Runtime Release Automation (npm packages) This document describes how the release scripts in this repo publish Oro Runtime CLI/runtime packages to npm. Scripts bin/version.sh Interactively bumps VERSION.txt and clib.json. When the major/minor version changes, bumps npm/packages/@orocomputer/runtime-node. bin/publish-npm-modules.sh Builds the CLI and runtime artifacts under a temporary publish root ($OROHOME). Stages and publishes the Oro npm packages (top-level + platform variants). bin/runtime-artifacts.sh Centralizes runtime artifact naming (ORORUNTIMEARTIFACTNAME=oro-runtime). Provides helpers used by bin/publish-npm-modules.sh to locate and validate platform/arch outputs. Guardrails Release tooling is Oro-only: no legacy CLI names, package scopes, or artifact aliases. test/unit/bootstrap-tooling.test.js asserts the scripts stay Oro-only."
    },
    {
      "id": "CI_MATRIX",
      "title": "Oro Runtime CI/CD Matrix",
      "section": "release",
      "summary": "This document describes the community\u2011run CI/CD validation for the Oro Runtime in this repository. The goals are:",
      "text": "Oro Runtime CI/CD Matrix This document describes the community\u2011run CI/CD validation for the Oro Runtime in this repository. The goals are: Give contributors a predictable, documented test matrix. Ensure changes are validated on at least one desktop target. Make it easy to extend coverage (extra OSes, architectures, or self\u2011hosted runners). Current GitHub Actions workflow The primary workflow lives at .github/workflows/ci.yml with the name CI. Triggers: push to dev, jwerle/, feature/, or fix/ branches. pullrequest targeting this repository. Manual workflowdispatch from the GitHub Actions UI. Jobs overview: Lint (standardjs) \u2014 runs npm run test:lint:ci on Linux. Desktop + runtime-core tests \u2014 builds the Oro Runtime CLI and runs the desktop and runtime-core test suites on Linux across a Node.js matrix. Test matrix The current matrix is intentionally conservative and can be expanded as the community exercises the pipeline: Operating systems: ubuntu-latest Node.js versions: 18.x (LTS) 20.x (LTS) Test targets: Lint: npm run test:lint:ci Desktop tests: npm test (desktop target via test/scripts/run.js) Runtime core tests: npm run test:runtime-core Runtime build settings The CI workflow builds the oroc CLI before running tests: ./bin/install.sh runs on ubuntu-latest with: NOANDROID=1 and NOIOS=1 to avoid mobile toolchain setup in CI. DEBUG=1 to produce debug builds useful for diagnosing failures. VERBOSE=1 to log build configuration and any dependency advice. Desktop tests run with: OROTESTHEADLESS=1 to prefer headless/browserless execution where supported. OROTESTSKIPDESKTOPEXTENSION=1 and OROTESTSKIPTESTEXTENSIONS=1 to avoid building heavy native test extensions in constrained CI environments while still exercising the core/runtime. Contributors should still follow the guidance in CONTRIBUTING.md for local builds (for example, running ./bin/install.sh before npm test), but the CI matrix is designed to work out of the box on GitHub\u2011hosted Linux runners. How to trigger CI for your changes Open a pull request against this repository. The CI workflow runs automatically and reports status on the PR. Push commits to an existing PR branch. CI re\u2011runs on the updated commit set. For long\u2011lived topic branches (e.g., jwerle/run-48-\u2026), push directly to the branch; CI runs on push in addition to any open PRs. To re\u2011run checks without pushing a new commit: Use the Re-run jobs button in the Actions tab, or Trigger workflowdispatch manually from the CI workflow page. Reading results and debugging failures Each job publishes logs directly in the GitHub Actions UI. Lint failures: Look for standard output in the Lint (standardjs) job; it lists file paths and rule violations that must be fixed. Desktop/runtime-core test failures: The Desktop + runtime-core tests job emits: Build output from ./bin/install.sh (including missing dependency hints). Test runner output from npm test and npm run test:runtime-core. Common issues: Missing system packages (see hints printed by bin/install.sh). Tests that assume non\u2011headless environments; consider using OROTESTHEADLESS=0 locally when reproducing. Extending the matrix The matrix is intentionally minimal to keep CI turnaround reasonable. To propose additional coverage: Open a GitHub issue in this repository describing: Desired OS/arch (e.g., macos-latest, windows-latest, self\u2011hosted label). Any additional Node.js versions or test targets to include. Whether failures on the new axis should be blocking or optional. Optionally send a pull request that: Extends matrix.os or matrix.node in .github/workflows/ci.yml. Adjusts environment variables or build steps to keep runtimes stable on the new platform. Feedback and community input Feedback on the CI/CD matrix is welcome: File issues for flaky jobs, missing coverage, or confusing failure modes. Suggest improvements to this document or the workflow in pull requests. Use GitHub Discussions (where enabled for the org) to coordinate broader changes to the test strategy before sending large matrix expansions."
    },
    {
      "id": "ORO_ARTIFACT_NAMING",
      "title": "Oro Runtime Artifact Naming",
      "section": "release",
      "summary": "This document defines the canonical naming for Oro Runtime build artifacts across platforms and packaging ecosystems.",
      "text": "Oro Runtime Artifact Naming This document defines the canonical naming for Oro Runtime build artifacts across platforms and packaging ecosystems. Native libraries and archives Primary Oro Runtime libraries use the oro-runtime stem: Static libraries (desktop/mobile toolchains) Linux/macOS: liboro-runtime.a Windows (MSVC): oro-runtime.lib Dynamic libraries / shared objects (where produced) Linux: liboro-runtime.so macOS: liboro-runtime.dylib Windows: oro-runtime.dll pkg-config files Oro Runtime ships a pkg-config file using the Oro name: Primary file: oro-runtime.pc Name: oro-runtime Version: <runtime version> CLI and configuration artifacts CLI binary: oroc Project config: oro.toml Per-developer overrides/secrets: .ororc Environment variables: ORO NPM packages and scopes Oro Runtime publishes packages under the @orocomputer scope: @orocomputer/runtime @orocomputer/runtime-{darwin,linux,win32}-{arm64,x64} @orocomputer/runtime-node Updating this policy If artifact naming changes, update this document alongside the implementation and ensure test/unit/bootstrap-tooling.test.js continues to enforce Oro-only release tooling."
    },
    {
      "id": "GOVERNANCE",
      "title": "Oro Runtime Governance Overview",
      "section": "governance",
      "summary": "This document explains how Oro Runtime is governed: who maintains the project, how decisions are made, and how to escalate when changes have broad impact (such as the Socket \u2192 Oro rebrand).",
      "text": "Oro Runtime Governance Overview This document explains how Oro Runtime is governed: who maintains the project, how decisions are made, and how to escalate when changes have broad impact (such as the Socket \u2192 Oro rebrand). It complements the contribution and security guidelines in the runtime source repository and should be read alongside RUNTIMEARCHITECTURE.md for compatibility-sensitive changes. Roles Maintainers Steer project direction and own final decisions on design, architecture, and releases. Triage issues, prioritize work, and merge pull requests. Ensure the project follows documented security, release, and compatibility policies. Reviewers Provide code review, documentation review, and test coverage feedback. Can approve most PRs; escalate controversial or cross\u2011cutting changes to maintainers. May be maintainers in related repos (CLI, website, tooling) acting as liaisons. Contributors Anyone opening issues, PRs, or participating in discussions. Follow the contribution guide, code style, and security guidelines. Can propose changes to policies, APIs, and governance via issues and discussions. Release captain (per release) Coordinates tagging, changelogs, and release announcements. Ensures the release checklist is followed (see the runtime repository\u2019s release checklist and release notes). Acts as the tie\u2011breaker when release\u2011blocking decisions need a prompt resolution. Technical steering (TSC\u2011style group) Small group of maintainers responsible for long\u2011term direction and cross\u2011repo policy. Handles escalations and approves changes to governance or rebrand\u2011affecting policy docs. Decision\u2011making model Oro Runtime uses a lazy consensus model: For most changes, one maintainer approval + passing checks is sufficient once reasonable review time has passed. If someone has significant concerns, they should: Comment directly on the PR or issue with clear, actionable feedback. Propose concrete alternatives if they are blocking a change. If consensus cannot be reached in a reasonable time: The discussion is escalated to the relevant maintainer or the TSC group. The escalated decision and rationale are recorded in the issue or PR for future reference. When to open an RFC or discussion first Use a GitHub Discussion or dedicated design issue when: A change affects documented public APIs (JS APIs, CLI commands, config fields). Backward compatibility guarantees documented in RUNTIMEARCHITECTURE.md may be impacted. Governance, security, or release policy documents need substantial edits. In these cases: Capture the problem, constraints, and proposed approach concisely. Link related Linear tickets (e.g., Socket \u2192 Oro rebrand work items). Give stakeholders time to respond before landing implementation PRs, unless the change is clearly low\u2011risk and time\u2011sensitive. Review expectations New contributors should have clear expectations about how reviews work: For most changes, one maintainer or reviewer approval plus passing checks is sufficient, provided there has been a reasonable opportunity for others to comment. Documentation-only or low-risk changes are typically merged after a single maintainer approval. Runtime, API, or policy changes that affect compatibility guarantees (for example, items documented in RUNTIMEARCHITECTURE.md) may require explicit sign-off from the relevant maintainers or the TSC group. Maintainers aim to provide an initial response to new issues and PRs within a few business days. If you have not received feedback, it is appropriate to ping the thread or ask in the Matrix/Discord #oro-runtime channels. Contributors are encouraged to keep PRs focused; large cross-cutting work should be broken into smaller pieces or preceded by a design/RFC discussion so reviews remain tractable. Escalation paths If you disagree with a proposed or merged change, or if a decision feels blocked: 1. Start with the PR/issue thread Ask clarifying questions. Provide concrete examples or data where possible. 2. Escalate to maintainers Mention a maintainer directly in the PR/issue. Summarize the points of agreement and disagreement so far. 3. Escalate to the TSC group Use a GitHub Discussion (e.g., \u201cRequest for decision: \u2026\u201d) when the change affects multiple repos or long\u2011term policy. The TSC aims to respond promptly, with a clear written decision and follow\u2011up tasks as needed. Security\u2011sensitive reports should always follow the security process in SECURITY.md rather than public escalation. Roadmap visibility and release cadence The Oro Runtime roadmap and releases are visible through a few sources: Near-term technical priorities and status are tracked in issues and project boards. Release notes and version history are tracked in the runtime repository (releases/changelog). Larger project arcs are tracked in Linear projects and via GitHub Projects/Discussions referenced from those tickets. Oro Runtime does not mandate a strict calendar-based release cadence. Instead: Runtime releases are cut when they satisfy the project\u2019s documented quality criteria (release checklist). Patch releases are issued as needed for critical bugs and security fixes. How to propose changes To propose a change to Oro Runtime (code, APIs, docs, or policy): 1. Open an issue Describe the problem, motivation, and rough proposal. Link any relevant Linear tickets if you are working off a scoped project. 2. Decide whether an RFC/discussion is needed For routine fixes or small features, a PR referencing the issue is usually enough. For cross\u2011repo work, open a Discussion and link it from the issue. 3. Open a PR Follow the coding and documentation guidelines in AGENTS.md and CODESTYLE.md (in the runtime repository). For APIs, ensure usage, parameters, return values, and examples are documented in JSDoc and the relevant docs. 4. Request review Tag maintainers or reviewers when ready. For large cross\u2011repo changes, call out which docs or policies you believe are impacted. Onboarding and where to start New contributors should: Read CONTRIBUTING.md for setup instructions and contribution workflow. Skim AGENTS.md and CODESTYLE.md for repo\u2011specific conventions. Use GOVERNANCE.md (this document) as the reference for how decisions are made and how to get help when a change needs broader agreement."
    },
    {
      "id": "ENGINEERING_SCOPING",
      "title": "Engineering Note: Scoped State, Metrics, and Limits",
      "section": "governance",
      "summary": "This note captures patterns for tracking metrics and enforcing limits across the runtime without introducing process\u2011wide behavior that can blur isolation between windows, origins, or embedded servers.",
      "text": "Engineering Note: Scoped State, Metrics, and Limits This note captures patterns for tracking metrics and enforcing limits across the runtime without introducing process\u2011wide behavior that can blur isolation between windows, origins, or embedded servers. Principles Avoid process\u2011wide global statics for counters or behavior (limits, caches) that affect runtime request handling. Scope state to a meaningful domain: Per\u2011origin (e.g., oro://com.app) + route prefix (e.g., /ai/llama). Per\u2011window when appropriate (bridge client.id) for finer attribution. Store scoped state in Services (e.g., core::services::AI) rather than in routes. Services provide getOrCreate(scopeKey) APIs to retrieve state. Scoped state should be atomic for hot paths; only the map lookup/insert needs a lock. Implementation Pattern // Example container struct ServerStats { std::atomic<int> inflight{0}; std::atomic<uint64t> reqA{0}, reqB{0}; std::atomic<long long> latASum{0}, latACount{0}; std::atomic<int> tokens{0}; std::atomic<long long> lastRefillMs{0}; bool tryConsumeToken(int rps, int burst); }; // Service state Mutex statsMutex; Map<String, SharedPointer<ServerStats>> stats; SharedPointer<ServerStats> getStats(const String &scope) { Lock lock(statsMutex); if (stats.contains(scope)) return stats.at(scope); auto s = std::makeshared<ServerStats>(); stats.insertorassign(scope, s); return s; } Routes: Build a scope key from origin + prefix (and optionally client.id). Retrieve stats once per request; update atomics in the hot path. Avoid heavy locks or per\u2011request allocations in streaming loops. Rate Limiting Use a token\u2011bucket per scope with steady\u2011clock refill (1s cadence is usually sufficient and cheap). Store tokens and lastRefillMs in the scoped stats; update atomics only. Enforce per\u2011scope concurrency (e.g., inflight >= maxConcurrent). Return a JSON error payload (e.g., 429/\"Too Many Requests\") when limits are exceeded. Metrics & /health Track counts and latency aggregates (sum + count) per scope. Report only the metrics for the scope serving the current request, not process\u2011global totals. Optionally include per\u2011window metrics alongside the aggregate origin+prefix view. Consider EWMA or percentiles if needed later; keep overhead minimal. Streaming (SSE/Chunks) Coalesce small writes to reduce syscall pressure. Track latency from start \u2192 finish for stream metrics. Respect cancellation; ensure resources (context, streams) are released. JSON Parsing & Caps Parse JSON bodies only when necessary and with a strict size cap (e.g., 1 MiB), falling back to query params. Avoid unbounded string growth; use small rolling windows for stop\u2011sequence detection. Tool\u2011Calling Do not execute arbitrary tool code in the runtime. Return a minimal toolcall stub (non\u2011stream) or a single stream chunk, then finish. Let applications resolve the tool function and post follow\u2011up prompts. Testing Add base tests that do not require external models (health/models/error paths, SSE shape, caps). Gate E2E tests that require a model behind env vars (e.g., OROAIMODELNAME / OROAIMODELDIR). Applying Broadly Where future services expose metrics/limits, follow the same scoping model (origin/prefix or window) and store the state in the appropriate Service. Keep hot paths atomic; lock only for map lookups/initialization."
    },
    {
      "id": "CDP",
      "title": "CDP (Chrome DevTools Protocol)",
      "section": "debugging",
      "summary": "This document is the source of truth for what Oro\u2019s CDP server:",
      "text": "CDP (Chrome DevTools Protocol) This document is the source of truth for what Oro\u2019s CDP server: Supports today (implemented and expected to work) Can support in the future (plausible with additional runtime/engine work) Will never support (requires Chromium/V8 internals or Chrome-specific infrastructure) Goals Connectivity-complete: stable HTTP + WebSocket endpoints, sane errors, no crashes. Tooling-complete: enough protocol coverage for real-world Playwright/Puppeteer automation flows. Safe by default: bind to loopback by default; make \u201cremote debugging\u201d clearly insecure when exposed off-machine. Non-goals: Full Chrome/Chromium CDP parity. A bundled DevTools frontend UI. Enabling CDP CLI / Desktop flag The desktop app binary supports a Chromium-style flag: remote-debugging-port=<port> <port> == 0 selects a random available port. When enabled, the runtime prints a Chrome-like line to stderr: DevTools listening on ws://127.0.0.1:<port>/devtools/browser/<browserId> If the bind address is not loopback, the runtime prints a warning. The oroc CLI forwards this flag to the app binary, so you can use the same option when launching via oroc. JavaScript API (oro:cdp) Apps can start/stop/query CDP from JS: import as cdp from 'oro:cdp' const status = await cdp.listen({ hostname: '127.0.0.1', port: 0 }) console.log(status.httpEndpoint) // http://127.0.0.1:<port> console.log(status.wsEndpoint) // ws://127.0.0.1:<port>/devtools/browser/<browserId> Server endpoints HTTP GET /json and GET /json/list: returns page targets with webSocketDebuggerUrl. GET /json/version: returns webSocketDebuggerUrl plus basic version fields. GET /json/protocol: minimal schema (many tools ship their own protocol definitions). GET /json/new?<url> (also supports ?url=<url>): creates a new window and navigates. GET /json/activate/<targetId>: attempts to focus the window for the target. GET /json/close/<targetId>: requests closing the window for the target. WebSocket ws://<host>:<port>/devtools/browser/<browserId>: browser session (root). ws://<host>:<port>/devtools/page/<targetId>: binds directly to a page target. Target model Each desktop window maps to a CDP TargetInfo with: type: \"page\" browserContextId is always present for tooling compatibility; the default context uses default-<browserId> and is not returned by Target.getBrowserContexts Non-default browser contexts are tracked for automation tooling: Target.getBrowserContexts returns IDs created via Target.createBrowserContext (does not include default) Target.disposeBrowserContext forgets the context and closes windows created in that context Note: Oro currently tracks browser contexts for protocol compatibility, but does not yet guarantee Chromium-like storage/process isolation between contexts. Supported protocol surface (today) Notes: Unknown methods in known CDP domains return code: -32000 (\"Not supported\"). Unknown domains return code: -32601 (\"Method not found\"). Any method name ending with .enable or .disable is accepted as a no-op unless explicitly implemented below. Runtime.evaluate / Runtime.callFunctionOn provide a compatibility-focused subset and do not aim to emulate Chromium/V8 evaluation semantics in full (some edge cases around multi-statement inputs may differ). Runtime.executionContextCreated includes auxData.frameId and auxData.isDefault, and isolated worlds created via Page.createIsolatedWorld surface as distinct execution contexts via context.name (required for Puppeteer/Playwright frame/world bookkeeping). DOM.describeNode includes node.frameId for iframe/frame elements (content frame id) and documentElement nodes so Puppeteer/Playwright can map handles to frames. Network instrumentation covers in-page fetch/XMLHttpRequest plus runtime-handled scheme requests (SchemeHandlers). This is still not full \u201csubresource parity\u201d with Chromium. Fetch interception (Fetch.) supports runtime-handled scheme requests and in-page fetch() requests (instrumented). It does not intercept browser-network subresources and it does not currently intercept XMLHttpRequest. Input injection is implemented via in-page event synthesis (DOM/Pointer events + element.click() for default actions), not native OS-level input; some sites may behave differently. Frame model: Page.getFrameTree includes iframe entries discovered in the DOM, but frames do not have separate CDP sessions, and iframe execution contexts are compatibility-only (treat the top-level frame as the only fully addressable context). Page.addScriptToEvaluateOnNewDocument: scripts are applied at the start of a document load (via readystatechange), but this does not guarantee true Chromium \u201cpre-page-script\u201d semantics on all platforms. CDP discovery endpoints accept a trailing slash (e.g. Playwright probes GET /json/version/). Safety limits To avoid OOMs and giant WebSocket frames, Oro applies safety caps: Network response bodies: captured for in-page fetch/XMLHttpRequest and for runtime-handled scheme responses; bounded to 5 MiB per request. A global 20 MiB total and 256 request cap is applied for stored bodies used by Network.getResponseBody. Base64 response bodies: when a response body is binary, it is returned base64-encoded; due to encoding overhead, the Network.getResponseBody payload can be larger than 5 MiB even when the decoded body is within the 5 MiB cap. Network request bodies (postData): captured for in-page fetch/XMLHttpRequest and runtime-handled scheme requests; bounded to 256 KiB per request. When caps are hit, postData may be omitted. Screenshots: Page.captureScreenshot is guarded (dimensions/pixels + payload size) and may return \"Screenshot too large\" for very large pages or clips. WebSocket messages: inbound and outbound frames are capped at 32 MiB; oversized frames will close the connection to avoid OOM. IO streams: Fetch.takeResponseBodyAsStream and Network.takeResponseBodyForInterceptionAsStream store at most 64 active streams, 20 MiB total, and serve at most 256 KiB per IO.read call. Page.addScriptToEvaluateOnNewDocument: bounded to 128 scripts per target, 1 MiB per script, and 4 MiB total per target. Runtime.addBinding: bounded to 256 bindings per target. DOM snapshots: DOM.getDocument / DOM.describeNode depth is clamped (max 3); DOM.querySelectorAll returns at most 2048 nodeIds. DOM serialization: DOM.getDocument / DOM.describeNode are additionally capped to 4096 serialized nodes per call to avoid huge payloads. Runtime.getProperties: returns at most 2048 property descriptors per call. Navigation history: bounded to 128 entries per window. Telemetry: unknown method log-dedup is bounded to 1024 unique method names per server run. Implemented methods (expected to work) Browser.getVersion Browser.getBrowserCommandLine (stub: returns empty arguments) Browser.getWindowForTarget (bounds-only) Browser.getWindowBounds (bounds-only) Browser.setContentsSize (resize; may be ignored by platform) Browser.setWindowBounds (move/resize/windowState; platform-dependent) Browser.close (closes window 0, which exits on most desktop builds) Target.setDiscoverTargets Target.getTargets Target.setAutoAttach Target.attachToBrowserTarget (returns a new sessionId) Target.attachToTarget Target.detachFromTarget Target.sendMessageToTarget (flattened sessions) Target.getTargetInfo Target.createTarget Target.closeTarget Target.activateTarget Target.getBrowserContexts Target.createBrowserContext (returns a unique id) Target.disposeBrowserContext (closes windows in that context) Page.enable (emits initial Page.frameNavigated for the attached target) Page.navigate Page.setDocumentContent Page.getFrameTree Page.getResourceTree (returns document + <script src> + <link rel=\"stylesheet\"> URLs discovered in DOM) Page.getResourceContent (returns main document HTML when url matches current page; otherwise empty content) Page.getLayoutMetrics Page.getNavigationHistory Page.navigateToHistoryEntry Page.bringToFront Page.reload Page.stopLoading Page.close Page.addScriptToEvaluateOnNewDocument Page.removeScriptToEvaluateOnNewDocument Page.createIsolatedWorld (returns an executionContextId; not true world isolation) Page.captureScreenshot (Linux/WebKitGTK only; png only; may reject huge pages) Runtime.enable (emits initial Runtime.executionContextCreated for the attached target) Runtime.evaluate Runtime.callFunctionOn Runtime.getProperties Runtime.releaseObject Runtime.releaseObjectGroup Runtime.addBinding Runtime.removeBinding Runtime.runIfWaitingForDebugger (no-op) Runtime.getIsolateId (returns a stable id for this runtime instance) Log.enable (enables Log.entryAdded events for console/errors) Log.disable Log.clear (no-op) DOM.getDocument DOM.getOuterHTML DOM.setOuterHTML DOM.querySelector DOM.querySelectorAll DOM.getAttributes DOM.requestChildNodes (emits DOM.setChildNodes) DOM.setAttributeValue DOM.removeAttribute DOM.setNodeValue DOM.describeNode DOM.resolveNode DOM.getContentQuads DOM.getNodeForLocation DOM.getBoxModel DOM.scrollIntoViewIfNeeded DOM.focus DOM.getFrameOwner DOM.setFileInputFiles CSS.getComputedStyleForNode CSS.getInlineStylesForNode (returns style attribute; no rule/source mapping) CSS.getMatchedStylesForNode (returns empty matchedCSSRules; includes inlineStyle) Input.dispatchMouseEvent Input.dispatchKeyEvent Input.insertText Emulation.setDeviceMetricsOverride (may resize the window on desktop) Emulation.clearDeviceMetricsOverride Network.getResponseBody (fetch/XHR, synthetic navigation HTML, and runtime-handled scheme responses) Network.getRequestPostData (fetch/XHR, plus runtime-handled scheme requests) Network.setExtraHTTPHeaders (applies to in-page fetch/XMLHttpRequest plus runtime-handled scheme requests) Network.getResponseBodyForInterception (delegates to Network.getResponseBody) Network.takeResponseBodyForInterceptionAsStream (IO stream; keyed by interceptionId) Network.setBlockedURLs (blocks in-page fetch/XMLHttpRequest plus runtime-handled scheme requests) Network.setRequestInterception (compat layer; enables Fetch.requestPaused + emits Network.requestIntercepted for the same requests) Network.continueInterceptedRequest (resolves requests paused via Fetch.requestPaused; supports errorReason, request overrides, and rawResponse fulfill) Performance.getMetrics (compat subset; values may be 0 on non-Chromium engines) Memory.getDOMCounters (compat subset) Memory.getBrowserCounters (compat subset) Runtime.getHeapUsage (compat subset) Fetch.enable (runtime-handled scheme requests + in-page fetch() (instrumented); request-stage only) Fetch.disable (same scope as Fetch.enable) Fetch.continueRequest (same scope as Fetch.enable) Fetch.continueResponse (accepted; treated like continue) Fetch.fulfillRequest (same scope as Fetch.enable; body treated as base64) Fetch.failRequest (same scope as Fetch.enable) Fetch.continueWithAuth (accepted; auth challenges not modeled) Fetch.getResponseBody (delegates to Network.getResponseBody) Fetch.takeResponseBodyAsStream (IO stream; keyed by requestId) IO.read IO.close IO.resolveBlob (stub: returns a UUID but does not expose blob retrieval by UUID) Implemented events (limited coverage) Target.targetCreated Target.targetDestroyed Target.targetInfoChanged Target.attachedToTarget Target.detachedFromTarget Page.frameNavigated Page.frameStartedLoading (synthesized) Page.frameStoppedLoading (synthesized) Page.lifecycleEvent Page.domContentEventFired Page.loadEventFired Page.javascriptDialogOpening (in-page wrappers) Runtime.executionContextsCleared Runtime.executionContextCreated Runtime.bindingCalled Runtime.consoleAPICalled (in-page wrappers) Runtime.exceptionThrown (in-page wrappers) Log.entryAdded (when Log.enable has been called) Network.requestWillBeSent (fetch/XHR + synthetic navigation + runtime-handled scheme requests) Network.responseReceived (fetch/XHR + synthetic navigation + runtime-handled scheme requests) Network.loadingFinished (fetch/XHR + synthetic navigation + runtime-handled scheme requests) Network.loadingFailed (fetch/XHR + runtime-handled scheme failures) Network.dataReceived (runtime-handled scheme requests only) Network.requestIntercepted (when Network.setRequestInterception is enabled; mirrors Fetch.requestPaused) Fetch.requestPaused (runtime-handled scheme requests + in-page fetch() (instrumented)) No-op stubs (accepted, but currently do nothing) Schema.getDomains (returns empty) Security.setIgnoreCertificateErrors Browser.grantPermissions / Browser.resetPermissions Browser.setDownloadBehavior Browser.cancelDownload (no-op) Animation.getPlaybackRate / Animation.setPlaybackRate (stored/returned for compatibility; does not affect engine playback) Overlay. (no-op) Network.clearBrowserCache (no-op) Network.clearBrowserCookies (no-op) Network.setCacheDisabled Network.setBypassServiceWorker Network.emulateNetworkConditions Network.getCookies (returns empty) Network.setCookies (no-op) Network.deleteCookies (no-op) Storage.getCookies (returns empty) Storage.setCookies (no-op) Storage.clearCookies (no-op) Emulation.setUserAgentOverride Emulation.setTimezoneOverride Emulation.setLocaleOverride Emulation.setTouchEmulationEnabled Emulation.setFocusEmulationEnabled Page.setLifecycleEventsEnabled Page.setBypassCSP Page.setFontFamilies (no-op) Page.setInterceptFileChooserDialog Page.handleJavaScriptDialog (no-op) Page.getAppManifest (returns empty) Page.getInstallabilityErrors (returns empty) Page.captureSnapshot (returns empty) Page.startScreencast / Page.stopScreencast / Page.screencastFrameAck (no-op) Accessibility.getFullAXTree (returns empty) Accessibility.queryAXTree (returns empty) DOMSnapshot.captureSnapshot / DOMSnapshot.getSnapshot (returns empty) DOMDebugger. (returns empty) CSS.getStyleSheetText (returns empty) CSS.getPlatformFontsForNode (returns empty) CSS.getMediaQueries (returns empty) CSS.collectClassNames (returns empty) CSS.startRuleUsageTracking (no-op) CSS.stopRuleUsageTracking (returns empty) Debugger.getScriptSource (returns empty) Debugger.setSkipAllPauses (no-op) Debugger.getPossibleBreakpoints (returns empty) Debugger.setBreakpointByUrl / Debugger.setBreakpoint (returns empty) Debugger.removeBreakpoint / Debugger.pause / Debugger.resume / Debugger.stepOver / Debugger.stepInto / Debugger.stepOut (no-op) Debugger.searchInContent (returns empty) Profiler.startPreciseCoverage (no-op) Profiler.takePreciseCoverage (returns empty) Profiler.stopPreciseCoverage (returns empty) Profiler.setSamplingInterval / Profiler.start (no-op) Profiler.stop (returns empty) Profiler.getBestEffortCoverage (returns empty) Coverage.startJSCoverage / Coverage.stopJSCoverage / Coverage.startCSSCoverage / Coverage.stopCSSCoverage (no-op) Coverage.takePreciseCoverage (returns empty) HeapProfiler.collectGarbage (no-op) HeapProfiler.startSampling (no-op) HeapProfiler.getSamplingProfile (returns empty) HeapProfiler.stopSampling (returns empty) Tracing.start (no-op) Tracing.end (no-op) Explicitly unsupported (returns -32000 Not supported) Page.printToPDF Runtime.queryObjects HeapProfiler.takeHeapSnapshot Extensions.loadUnpacked / Extensions.uninstall DeviceAccess.enable / DeviceAccess.selectPrompt / DeviceAccess.cancelPrompt Autofill.trigger ServiceWorker. / BackgroundService. / BackgroundFetch. / Audits. / Audits2. / WebAuthn. / WebAudio. / Media. / Cast. / DeviceOrientation. Playwright / Puppeteer compatibility This CDP server is intended to support: Puppeteer connecting via browserWSEndpoint or browserURL (HTTP endpoint). Playwright connecting via chromium.connectOverCDP(<httpEndpoint>). Important: Playwright\u2019s \u201cCDP mode\u201d is Chromium-oriented; Oro provides a CDP-compatible surface for automation, but it is not a Chromium engine and some features may behave differently or remain stubbed. Expectations checklist (what tools typically do) This section is a practical checklist of the CDP surface that Puppeteer/Playwright commonly expect during connect() / connectOverCDP() and basic automation flows. Connectivity / discovery HTTP endpoints used by tooling: GET /json/version, GET /json, GET /json/list. Browser WS endpoint: ws://<host>:<port>/devtools/browser/<browserId>. Page WS endpoint: ws://<host>:<port>/devtools/page/<targetId> (some tooling/debuggers use this directly). Target + session model (must not surprise clients) Target.setDiscoverTargets should emit Target.targetCreated for existing targets before responding. Target.getTargets lists current targets. Target.attachToTarget with flatten: true (the preferred mode) yields a sessionId and emits Target.attachedToTarget before resolving. Target.setAutoAttach is accepted (Oro does not model worker/serviceworker subtargets today). Target.sendMessageToTarget works for flattened sessions (messages are processed as if they were sent with that sessionId). \u201cEnable\u201d dance + initial events Automation clients typically issue many .enable calls; Oro accepts them as no-ops unless explicitly implemented. Runtime.enable returns {} and emits Runtime.executionContextCreated for the attached page/session. Page.enable returns {} and emits Page.frameNavigated for the attached page/session. Diagnostics: execution contexts Runtime.executionContextCreated.context.auxData.frameId and auxData.isDefault must be present so Puppeteer/Playwright can map contexts to frames. Page.createIsolatedWorld should surface as Runtime.executionContextCreated with context.name === <worldName> (e.g. Puppeteer\u2019s UTILITYWORLDNAME). Core automation primitives Navigation: Page.navigate, Page.reload, Page.stopLoading. DOM querying: DOM.getDocument, DOM.querySelector, DOM.querySelectorAll, DOM.describeNode, DOM.resolveNode. JS execution: Runtime.evaluate, Runtime.callFunctionOn, Runtime.getProperties, Runtime.releaseObject, Runtime.releaseObjectGroup. Input: Input.dispatchMouseEvent, Input.dispatchKeyEvent, Input.insertText. Observability (limited) Network. events and Network.getResponseBody / Network.getRequestPostData cover fetch/XMLHttpRequest, synthetic navigation events, and runtime-handled scheme requests (not full subresource parity). Console/errors may surface as Runtime.consoleAPICalled / Runtime.exceptionThrown. Known sharp edges (not Chrome parity) Frame model: one top-level frame per window (frameId == targetId); iframes are not separate frames/targets today. Request interception: Fetch. is supported for runtime-handled scheme requests (SchemeHandlers) and for in-page fetch() requests (instrumented). It ignores non-Request stages and it does not intercept browser-network subresources. Deprecated interception: Network.setRequestInterception is supported as a compatibility layer and forwards to the same underlying interception used by Fetch. (emitting Network.requestIntercepted for Fetch.requestPaused requests). It does not currently intercept XMLHttpRequest. Example: Puppeteer import puppeteer from 'puppeteer' const browser = await puppeteer.connect({ browserURL: 'http://127.0.0.1:<port>' }) const page = (await browser.pages())[0] await browser.newPage() await page.goto('https://example.com') Example: Playwright import { chromium } from 'playwright' const browser = await chromium.connectOverCDP('http://127.0.0.1:<port>') const context = browser.contexts()[0] await browser.newContext() const page = context.pages()[0] await context.newPage() await page.goto('https://example.com') Platform notes Linux (WebKitGTK) When CDP is enabled, the runtime enables WebKit automation via webkitwebcontextsetautomationallowed(...) (when supported) so external tooling can attach. Things we can support (future candidates) These are plausible, but require additional runtime/engine integration and will be implemented as needed by real tooling usage: Network observability: Network. events (request/response lifecycle, headers, timing) and cookie access. Request interception: extend Fetch. beyond SchemeHandlers to cover more request sources, if we can hook at the right layer. Screenshots / PDFs: cross-platform Page.captureScreenshot and Page.printToPDF via platform webview snapshot/print APIs. Window management: improve cross-platform parity for Browser.getWindowForTarget / Browser.setWindowBounds (positioning + window state). More DOM helpers: richer DOM. and DOMSnapshot. surfaces for robust selector/visibility tooling. Frame/iframe parity: richer Page. frame events and per-frame execution contexts (requires deeper engine integration). Things we will never support These require Chromium/V8 internals or Chrome-specific infrastructure, and are not realistic to emulate faithfully in Oro\u2019s non-Chromium engines: V8 debugging & profiling parity: Debugger., Profiler., HeapProfiler., Coverage. (breakpoints, stepping, heap snapshots, precise CPU/heap profiling) Chrome tracing infrastructure: Tracing. and Chrome\u2019s tracing model; Oro may provide small compatibility subsets (e.g. Performance.getMetrics, Memory.getDOMCounters) but does not implement Chrome\u2019s tracing/memory panels Chromium-only target/process models: Features that depend on Chromium\u2019s multi-process architecture (OOPIF/process-per-site semantics, Chrome-specific worker/service worker inspection models) Security notes Remote debugging gives full control over the app (evaluate JS, read DOM, drive input). Treat it like an admin interface: Prefer hostname: 127.0.0.1 and local-only usage. Do not bind CDP to non-loopback on untrusted networks."
    }
  ]
}
